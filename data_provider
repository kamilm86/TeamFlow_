# data_provider.py

from PySide6.QtCore import QObject, Signal
from db_connector import DatabaseConnector
from datetime import datetime, timedelta
import time
from app_settings import app_settings  # ZMIANA
from debug_utils import debug_print, log_warning, log_error
from dataclasses import dataclass, field
from typing import Dict, List, Tuple, Optional, Any, Set
from functools import lru_cache
from symbol_parser import parse_symbols_batch, parse_symbol
from config import SQL_OBJECTS


@dataclass
class MonthlyDataContainer:
    """Kontener na wszystkie dane miesiąca"""
    schedule_data: List[Any]
    events_data: List[Dict]
    processed_data_base: Dict
    events_cache: Dict[Tuple[int, str], List[Dict]]
    last_updated: float
    _icons_calculated_on_this_instance: bool = field(default=False, repr=False, compare=False)

    def __post_init__(self):
        if not hasattr(self, 'last_updated'):
            self.last_updated = time.time()


class DataProvider(QObject):
    """
    DataProvider z ograniczonym odświeżaniem ikon
    """
    data_changed = Signal(str, int, int)  # Typ danych, rok, miesiąc

    def __init__(self):
        super().__init__()
        self.db_connector = DatabaseConnector
        self.monthly_cache: Dict[Tuple[int, int, int, int], MonthlyDataContainer] = {}
        self.forecast_cache: Dict[Tuple[int, int], List[Dict]] = {}
        self.audit_cache: Dict[Tuple[int, int], List[Dict]] = {}
        self._icons_cache_by_month: Dict[Tuple[int, int], Dict[Tuple[int, str], Dict]] = {}
        self.publish_status_cache = {}  # Pamięć podręczna dla statusu publikacji
        # from column_mapper import ColumnMapper
        # self.column_mapper = ColumnMapper()
        self._current_year: Optional[int] = None
        self._current_month: Optional[int] = None

    def _fetch_suggested_off_days(self, year: int, month: int) -> Set[Tuple[str, str]]:
        """Pobiera z bazy danych sugestie dni wolnych dla nieopublikowanego grafiku."""
        suggestions = set()
        conn = None
        try:
            conn = self.db_connector.get_connection()
            cursor = conn.cursor()
            query = f"EXEC {SQL_OBJECTS['p_sugestiewolne']} ?, ?"
            cursor.execute(query, (year, month))
            
            # Procedura zwraca nr_kadrowy i datę
            results = cursor.fetchall()
            for row in results:
                if len(row) >= 2 and row[0] and row[1]:
                    nr_kadrowy = str(row[0])
                    # Data może być obiektem datetime, konwertujemy ją do stringa YYYY-MM-DD
                    date_obj = row[1]
                    if hasattr(date_obj, 'strftime'):
                        date_str = date_obj.strftime('%Y-%m-%d')
                        suggestions.add((nr_kadrowy, date_str))

            debug_print(f"DataProvider: Pobrano {len(suggestions)} sugestii wolnego dla {year}-{month}.")
            return suggestions
        except Exception as e:
            log_error(f"Błąd podczas pobierania sugestii wolnego: {e}", exception=e)
            return set()
        finally:
            if conn:
                conn.close()

    def is_schedule_published(self, year: int, month: int) -> bool:
        """Sprawdza, czy grafik na dany miesiąc jest opublikowany. Używa prostej pamięci podręcznej."""
        cache_key = (year, month)
        if cache_key in self.publish_status_cache:
            return self.publish_status_cache[cache_key]

        conn = None
        try:
            conn = self.db_connector.get_connection()
            cursor = conn.cursor()
            query = f"SELECT TOP 1 1 FROM {SQL_OBJECTS['datypublikacjigrafiku']} WHERE Rok=? AND Miesiac=? AND Status=1"
            cursor.execute(query, (year, month))
            result = cursor.fetchone()

            is_published = result is not None
            self.publish_status_cache[cache_key] = is_published
            debug_print(f"Sprawdzono status publikacji dla {year}-{month}: {is_published}")
            return is_published
        except Exception as e:
            log_error(f"Błąd podczas sprawdzania statusu publikacji dla {year}-{month}: {e}", exception=e)
            # W przypadku błędu, dla bezpieczeństwa załóż, że jest opublikowany (wymagaj potwierdzeń)
            return True
        finally:
            if conn:
                conn.close()

    def clear_publish_status_cache(self, year: int, month: int):
        """Czyści pamięć podręczną statusu publikacji dla konkretnego miesiąca."""
        cache_key = (year, month)
        if cache_key in self.publish_status_cache:
            del self.publish_status_cache[cache_key]
            debug_print(f"Wyczyszczono cache statusu publikacji dla {year}-{month}")

    def get_schedule_audit_data(self, year: int, month: int, limit: Optional[int] = None) -> List[Dict]:
        """
        Pobiera historię zmian grafiku, z opcjonalnym limitem TOP N.
        Cache jest używany tylko wtedy, gdy pobierane są wszystkie dane (limit=None).
        """
        cache_key = (year, month)
        # Użyj cache'a tylko, jeśli prosimy o pełny zestaw danych
        if limit is None and cache_key in self.audit_cache:
            debug_print(f"DataProvider: Używam cache dla danych audytowych dla {year}-{month}")
            return self.audit_cache[cache_key]

        conn = None
        try:
            conn = self.db_connector.get_connection()
            cursor = conn.cursor()

            # Dynamiczne budowanie zapytania w zależności od limitu
            if limit:
                query = f"SELECT TOP (?) * FROM {SQL_OBJECTS['fn_getscheduleauditdata']}(?, ?) ORDER BY DataModyfikacji DESC"
                params = (limit, year, month)
            else:
                # Zawsze sortuj, aby zachować spójność
                query = f"SELECT * FROM {SQL_OBJECTS['fn_getscheduleauditdata']}(?, ?) ORDER BY DataModyfikacji DESC"
                params = (year, month)

            cursor.execute(query, params)
            columns = [column[0] for column in cursor.description]
            data = [dict(zip(columns, row)) for row in cursor.fetchall()]

            debug_print(f"Pobrano {len(data)} wierszy historii zmian dla {year}-{month} (limit: {limit})")

            # Zapisz w cache'u tylko pełny wynik
            if limit is None:
                self.audit_cache[cache_key] = data

            return data
        except Exception as e:
            log_error(f"Błąd podczas pobierania danych audytowych: {e}", exception=e)
            return []
        finally:
            if conn:
                conn.close()

    def clear_audit_cache(self, year: int, month: int):
        """Czyści cache dla danych audytowych dla konkretnego miesiąca."""
        cache_key = (year, month)
        if cache_key in self.audit_cache:
            del self.audit_cache[cache_key]
            debug_print(f"DataProvider: Usunięto cache danych audytowych dla {year}-{month}")

    def clear_monthly_cache(self, year: int, month: int):
        """Czyści główny cache danych miesięcznych dla danego miesiąca."""
        # Klucz dla `monthly_cache` to teraz (rok, miesiąc)
        cache_key = (year, month)
        if cache_key in self.monthly_cache:
            del self.monthly_cache[cache_key]
            debug_print(f"DataProvider: Usunięto z monthly_cache dla {year}-{month}")

        # Klucz dla cache ikon również jest (rok, miesiąc)
        if cache_key in self._icons_cache_by_month:
            del self._icons_cache_by_month[cache_key]
            debug_print(f"DataProvider: Usunięto z _icons_cache_by_month dla {year}-{month}")

    def get_dynamic_icons_for_cell(self, user_id: int, date_str: str) -> Dict:
        """
        Zwraca ikony z cache lub oblicza je na podstawie zdarzeń.
        WERSJA ZMODYFIKOWANA: Ikona spotkania/szkolenia (koło) jest pokazywana
        tylko dla zdarzeń w statusie 'Delegowany'.
        """
        try:
            year, month, _ = date_str.split('-')
            year, month = int(year), int(month)
        except:
            return {'spotkania': 0, 'szkolenia': 0, 'nadgodziny': 0}

        month_key = (year, month)
        cell_key = (user_id, date_str)

        # Sprawdź cache ikon
        if month_key in self._icons_cache_by_month:
            month_icons_cache = self._icons_cache_by_month[month_key]
            if cell_key in month_icons_cache:
                return month_icons_cache[cell_key]

        # Oblicz ikony na podstawie zdarzeń (jeśli nie ma w cache)
        container = self.monthly_cache.get(month_key)
        events = []
        if container and container.events_cache:
            events = container.events_cache.get(cell_key, [])
        else:
            events = self.get_events_for_user_date(user_id, date_str)

        # NOWA LOGIKA: Ikona koła tylko dla statusu 'Delegowany'
        has_spotkania = any(e.get('type') == 'Spotkanie' and e.get('status') == 'Delegowany' for e in events)
        has_szkolenia = any(e.get('type') == 'Szkolenie' and e.get('status') == 'Delegowany' for e in events)

        # Logika dla nadgodzin pozostaje bez zmian (bazuje na ogólnie aktywnych zdarzeniach)
        has_nadgodziny = any(e.get('type') == 'Nadgodziny' and str(e.get('status', '1')) != '0' for e in events)

        result = {
            'spotkania': 1 if has_spotkania else 0,
            'szkolenia': 1 if has_szkolenia else 0,
            'nadgodziny': 1 if has_nadgodziny else 0
        }

        # Zapisz w cache ikon
        if month_key not in self._icons_cache_by_month:
            self._icons_cache_by_month[month_key] = {}
        self._icons_cache_by_month[month_key][cell_key] = result

        return result

    def invalidate_specific_icons(self, user_date_pairs: List[Tuple[int, str]]):
        """
        Wyczyszczenie cache ikon dla konkretnych par użytkownik-data.
        Nie powinno już być potrzebne pełne czyszczenie cache miesiąca tutaj.
        """
        if not user_date_pairs:
            return

        affected_months = set()
        for user_id, date_str in user_date_pairs:
            try:
                year, month, _ = date_str.split('-')
                month_key = (int(year), int(month))
                affected_months.add(month_key)

                if month_key in self._icons_cache_by_month:
                    cell_key = (user_id, date_str)
                    if cell_key in self._icons_cache_by_month[month_key]:
                        del self._icons_cache_by_month[month_key][cell_key]

                # Zresetuj flagę obliczonych ikon dla kontenera, jeśli istnieje
                if month_key in self.monthly_cache:
                    self.monthly_cache[month_key]._icons_calculated_on_this_instance = False

            except ValueError:
                log_warning(f"Nieprawidłowy format daty w invalidate_specific_icons: {date_str}")
                continue

        for year, month in affected_months:
            debug_print(f"Invalidate specific icons: Zresetowano cache ikon dla komórek w {year}-{month}")
            self.data_changed.emit("icons", year, month)

    def invalidate_icons_cache(self, year: int, month: int):
        """
        Czyści *tylko* cache ikon dla danego miesiąca.
        Używane, gdy wiemy, że zdarzenia mogły się zmienić, ale dane grafiku nie.
        """
        month_key = (year, month)

        if month_key in self._icons_cache_by_month:
            del self._icons_cache_by_month[month_key]
            debug_print(f"DataProvider: Wyczyścił _icons_cache_by_month dla {year}-{month}")

        if month_key in self.monthly_cache:
            # Ważne: zresetuj flagę, aby ikony zostały przeliczone przy następnym żądaniu get_processed_data
            self.monthly_cache[month_key]._icons_calculated_on_this_instance = False
            debug_print(f"DataProvider: Zresetował flagę _icons_calculated_on_this_instance dla {year}-{month}")

            # Można też rozważyć odświeżenie events_data i events_cache w kontenerze, jeśli to konieczne
            # np. container = self.monthly_cache[month_key]
            # container.events_data = self._fetch_events_data(year, month)
            # container.events_cache = self._build_events_cache(container.events_data)
            # container.last_updated = time.time()

        self.data_changed.emit("icons", year, month)

    def get_forecast_data(self, year, month):
        """Pobiera dane prognozy dla danego miesiąca."""
        cache_key = (year, month)
        if cache_key in self.forecast_cache:
            debug_print(f"Używam cache dla prognozy dla {year}-{month}")
            return self.forecast_cache[cache_key]

        conn = None
        try:
            conn = self.db_connector.get_connection()
            cursor = conn.cursor()
            query = f"SELECT * FROM {SQL_OBJECTS['fn_getforecastdata']} (?, ?)"
            cursor.execute(query, (year, month))

            # Mapowanie na podstawie nazw kolumn zwróconych przez bazę
            columns = [column[0] for column in cursor.description]
            data = [dict(zip(columns, row)) for row in cursor.fetchall()]

            debug_print(f"Pobrano {len(data)} wierszy prognozy dla {year}-{month}")
            self.forecast_cache[cache_key] = data
            return data
        except Exception as e:
            log_error(f"Błąd podczas pobierania danych prognozy: {e}", exception=e)
            return []
        finally:
            if conn:
                conn.close()

    def _get_or_load_monthly_data(self, year: int, month: int, grupa: int, funkcja: int, use_cache: bool = True) -> \
            Optional[MonthlyDataContainer]:
        self._current_year = year
        self._current_month = month

        # ZMIANA: Klucz cache jest teraz prosty - zależy tylko od roku i miesiąca.
        cache_key = (year, month)

        if use_cache and cache_key in self.monthly_cache:
            # Jeśli dane dla tego miesiąca są w cache, po prostu je zwróć.
            return self.monthly_cache[cache_key]

        debug_print(
            f"DataProvider: Tworzę nowy/nadpisuję kontener dla {year}-{month} (z filtrem grupa={grupa}, funkcja={funkcja})")

        try:
            # Parametry 'grupa' i 'funkcja' są używane TYLKO tutaj, do jednorazowego pobrania danych.
            schedule_data = self._fetch_schedule_data(year, month, grupa, funkcja)

            # Dane o zdarzeniach pobieramy zawsze w całości dla danego miesiąca.
            events_data = self._fetch_events_data(year, month)

            events_cache = self._build_events_cache(events_data)
            processed_data_base = self._build_processed_data_without_icons(schedule_data)

            container = MonthlyDataContainer(
                schedule_data=schedule_data,
                events_data=events_data,
                processed_data_base=processed_data_base,
                events_cache=events_cache,
                last_updated=time.time()
            )

            # Zapisz kontener pod prostym kluczem. Każde nowe ładowanie nadpisze stary.
            self.monthly_cache[cache_key] = container
            debug_print(f"DataProvider: Stworzono i zapisano w cache nowy kontener dla {year}-{month}.")
            return container

        except Exception as e:
            log_error(f"DataProvider: Błąd podczas ładowania danych dla {year}-{month}: {e}", exception=e)
            if cache_key in self.monthly_cache:
                del self.monthly_cache[cache_key]
            return None

    def get_schedule_data(self, year: int, month: int, grupa: int, funkcja: int, use_cache: bool = True) -> List[Any]:
        container = self._get_or_load_monthly_data(year, month, grupa, funkcja, use_cache)
        return container.schedule_data if container else []

    def get_events_data(self, year: int, month: int, grupa: int, funkcja: int, use_cache: bool = True) -> List[Dict]:
        """Pobiera dane zdarzeń, używając poprawnego kontekstu filtra do załadowania kontenera."""
        container = self._get_or_load_monthly_data(year, month, grupa, funkcja, use_cache)
        return container.events_data if container else []

    def get_processed_data(self, year: int, month: int, grupa: int, funkcja: int) -> Dict:
        """
        Zwraca processed_data z dynamicznie obliczonymi ikonami i sugestiami wolnego.
        """
        container = self._get_or_load_monthly_data(year, month, grupa, funkcja, use_cache=True)
        if not container:
            return {}

        # --- NOWA, POPRAWIONA LOGIKA: Sugestie wolnego ---
        # Sprawdzamy, czy sugestie zostały już zaaplikowane dla tego kontenera
        if not getattr(container, '_suggestions_applied', False):
            is_published = self.is_schedule_published(year, month)
            debug_print(f"DataProvider: Status publikacji dla {year}-{month} to: {is_published}")
            if not is_published:
                debug_print(f"DataProvider: Grafik dla {year}-{month} nieopublikowany. Sprawdzam sugestie wolnego.")
                suggested_off_days = self._fetch_suggested_off_days(year, month)
                if suggested_off_days:
                    debug_print(f"DataProvider: Znaleziono {len(suggested_off_days)} sugestii. Aplikuję do danych.")
                    nr_kadrowy_to_key_map = {
                        data.get('nr_kadrowy'): key
                        for key, data in container.processed_data_base.items()
                        if data.get('nr_kadrowy')
                    }
                    for nr_kadrowy, date_str in suggested_off_days:
                        user_key = nr_kadrowy_to_key_map.get(nr_kadrowy)
                        if user_key:
                            try:
                                day = int(date_str.split('-')[2])
                                day_data = container.processed_data_base[user_key].setdefault('days', {}).setdefault(day, {})
                                day_data['is_suggested_off'] = True
                                debug_print(f"DataProvider: Ustawiono is_suggested_off=True dla {nr_kadrowy} w dniu {day}")
                            except (ValueError, IndexError, KeyError) as e:
                                log_warning(f"Nie udało się zastosować sugestii dla {nr_kadrowy} w dniu {date_str}: {e}")
                else:
                    debug_print(f"DataProvider: Brak sugestii wolnego dla {year}-{month}.")
            # Oznacz, że sugestie zostały przetworzone dla tego kontenera
            container._suggestions_applied = True

        # Sprawdź, czy ikony zostały już obliczone w tej sesji dla tego kontenera
        if not container._icons_calculated_on_this_instance:
            debug_print(f"DataProvider: Obliczam ikony dla {year}-{month} na żądanie w get_processed_data")
            self._update_dynamic_icons(container.processed_data_base, container.events_cache)
            container._icons_calculated_on_this_instance = True

        return container.processed_data_base


    def get_department_to_group_mapping(self):
        """
        Zwraca słownik mapujący zagregowane grupy na zbiory wydziałów (WydzialGrafik).
        """
        # ZMIANA: Logika została przeniesiona do centralnego obiektu app_settings
        return app_settings.get_group_mapping()

    def refresh_data(self, year: int, month: int, grupa: int, funkcja: int):
        """
        Wymusza pełne odświeżenie danych dla miesiąca (np. po kliknięciu przycisku "Odśwież").
        """
        # ZMIANA 1: Klucz cache musi teraz uwzględniać grupę i funkcję
        cache_key = (year, month, grupa, funkcja)

        debug_print(f"DataProvider: Wymuszone odświeżenie danych dla {year}-{month} (grupa={grupa}, funkcja={funkcja})")

        if cache_key in self.monthly_cache:
            del self.monthly_cache[cache_key]
            debug_print(f"DataProvider: Usunięto stary kontener z monthly_cache dla klucza {cache_key}")

        # Klucz dla cache ikon jest niezależny od grupy/funkcji
        icons_cache_key = (year, month)
        if icons_cache_key in self._icons_cache_by_month:
            del self._icons_cache_by_month[icons_cache_key]
            debug_print(f"DataProvider: Usunięto _icons_cache_by_month dla {year}-{month}")

        # ZMIANA 2: Przekaż 'grupa' i 'funkcja' do wywołania poniżej
        container = self._get_or_load_monthly_data(year, month, grupa, funkcja, use_cache=False)

        if container:
            # Po świeżym załadowaniu, get_processed_data obliczy ikony, jeśli będzie to konieczne.
            self.data_changed.emit("schedule", year, month)
            self.data_changed.emit("events", year, month)
            self.data_changed.emit("icons", year, month)
        else:
            log_error(f"DataProvider: Nie udało się odświeżyć danych dla {year}-{month}")

    def refresh_events_data(self, year: int, month: int):
        """
        Wymusza odświeżenie tylko danych o zdarzeniach (events) dla danego miesiąca,
        zachowując resztę cache'u.
        """
        cache_key = (year, month)
        container = self.monthly_cache.get(cache_key)

        if not container:
            debug_print(f"DataProvider: Brak kontenera dla {year}-{month} do odświeżenia zdarzeń. Pomijam.")
            return

        debug_print(f"DataProvider: Wymuszone odświeżenie ZDARZEŃ dla {year}-{month}.")

        # Pobierz świeże dane o zdarzeniach i przebuduj ich cache
        fresh_events_data = self._fetch_events_data(year, month)
        container.events_data = fresh_events_data
        container.events_cache = self._build_events_cache(fresh_events_data)
        container.last_updated = time.time()
        container._icons_calculated_on_this_instance = False
        self.data_changed.emit("events", year, month)

    def _update_dynamic_icons(self, processed_data_target: Dict, events_cache: Dict):
        """
        Nakłada informacje o ikonach na dostarczony słownik `processed_data_target`.
        WERSJA ZMODYFIKOWANA: Ikona spotkania/szkolenia (koło) jest pokazywana
        tylko dla zdarzeń w statusie 'Delegowany'.
        """
        if not self._current_year or not self._current_month:
            log_error("DataProvider: _current_year lub _current_month nie jest ustawione w _update_dynamic_icons")
            return

        debug_print(
            f"DataProvider (ZMODYFIKOWANA WERSJA): Rozpoczynam _update_dynamic_icons dla {self._current_year}-{self._current_month}...")

        user_id_to_key_map = {key[3]: key for key in processed_data_target.keys()}

        for key, user_data in processed_data_target.items():
            user_id = key[3]
            days_data = user_data.get('days', {})

            for day, day_data_dict in days_data.items():
                date_str = f"{self._current_year}-{self._current_month:02d}-{day:02d}"
                events_for_cell = events_cache.get((user_id, date_str), [])

                # Utrzymujemy listę wszystkich aktywnych zdarzeń dla celów ogólnych (np. tooltip)
                active_events = [e for e in events_for_cell if str(e.get('status', '1')) != '0']

                # NOWA LOGIKA DLA IKONY KOŁA: Sprawdzamy status 'Delegowany'
                has_spotkania = any(
                    e.get('type') == 'Spotkanie' and e.get('status') == 'Delegowany' for e in events_for_cell)
                has_szkolenia = any(
                    e.get('type') == 'Szkolenie' and e.get('status') == 'Delegowany' for e in events_for_cell)

                # Logika dla nadgodzin pozostaje bez zmian (bazuje na ogólnie aktywnych zdarzeniach)
                has_nadgodziny = any(e.get('type') == 'Nadgodziny' for e in active_events)

                day_data_dict['spotkania'] = 1 if has_spotkania else 0
                day_data_dict['szkolenia'] = 1 if has_szkolenia else 0
                day_data_dict['nadgodziny'] = 1 if has_nadgodziny else 0
                day_data_dict['events'] = active_events

        # Pętla dla nadgodzin w dni wolne - również wymaga aktualizacji logiki dla spotkań/szkoleń
        for (user_id, date_str), events_for_cell in events_cache.items():
            try:
                # Sprawdzamy tylko aktywne nadgodziny (bez zmian)
                active_overtime = any(
                    e.get('type') == 'Nadgodziny' and str(e.get('status', '1')) != '0' for e in events_for_cell)
                if not active_overtime:
                    continue

                user_key = user_id_to_key_map.get(user_id)
                if not user_key:
                    continue

                user_data = processed_data_target[user_key]
                day = int(date_str.split('-')[2])

                # Dodajemy ikonę tylko, jeśli nie ma jeszcze wpisu dla tego dnia w grafiku
                if day not in user_data.get('days', {}):
                    day_data_dict = user_data.setdefault('days', {}).setdefault(day, {})
                    day_data_dict['nadgodziny'] = 1

                    # Utrzymujemy listę wszystkich aktywnych zdarzeń
                    active_events = [e for e in events_for_cell if str(e.get('status', '1')) != '0']

                    # NOWA LOGIKA DLA IKONY KOŁA (dla dni wolnych)
                    day_data_dict['spotkania'] = 1 if any(
                        e.get('type') == 'Spotkanie' and e.get('status') == 'Delegowany' for e in
                        events_for_cell) else 0
                    day_data_dict['szkolenia'] = 1 if any(
                        e.get('type') == 'Szkolenie' and e.get('status') == 'Delegowany' for e in
                        events_for_cell) else 0
                    day_data_dict['events'] = active_events
                    debug_print(f"Dodano ikonę nadgodzin w dniu wolnym dla user_id: {user_id}, dzień: {day}")

            except (ValueError, IndexError) as e:
                log_warning(f"Błąd przetwarzania zdarzenia dla dnia wolnego ({user_id}, {date_str}): {e}")
                continue

        debug_print(f"DataProvider (ZMODYFIKOWANA WERSJA): Zakończono _update_dynamic_icons.")

    def _build_processed_data_without_icons(self, schedule_data: List[Dict]) -> Dict:
        """
        Przetwarza dane z już spivotowanego zapytania SQL.
        WERSJA POPRAWIONA: Oblicza sumę godzin po stronie aplikacji, ignorując
        kolumny SumaRBH i BilansRBH z bazy danych.
        """
        if not self._current_year or not self._current_month or not schedule_data:
            return {}

        processed_data = {}
        for row_dict in schedule_data:
            uzytkownik_id = row_dict.get('Uzytkownik', 0)

            key = (
                row_dict.get('WydzialGrafik', ''),
                row_dict.get('PrzelozonyDane', ''),
                row_dict.get('UzytkownikDane', ''),
                uzytkownik_id
            )

            # Inicjalizujemy słownik z danymi pracownika, bez sumy godzin
            processed_data[key] = {
                'days': {},
                'total_hours': 0,  # Inicjalizujemy sumę jako 0
                'rola_nazwa': row_dict.get('RolaNazwa', ''),
                'pod_rola_nazwa': row_dict.get('PodRolaNazwa', ''),
                'etat': row_dict.get('Etat', 8.0),
                'jezyk': row_dict.get('Język', ''),
                'korekta': row_dict.get('Korekta', 0),
                'dtn': row_dict.get('DTN', 0),
                'przelozony_imie_nazwisko': row_dict.get('PrzelozonyImieNazwisko', ''),
                'nr_kadrowy': row_dict.get('NumerKadrowy', ''),
                'lokalizacja_domyslna': row_dict.get('LokalizacjaDomyslna', 'h'),
                'komentarz_grafik': row_dict.get('KomentarzGrafik', ''),
                'system_czasu_pracy': row_dict.get('SystemCzasuPracy', ''),
                'login_windows': row_dict.get('LoginWindows', ''),
                'rka': row_dict.get('Rka', ''),
                'email': row_dict.get('Email', '')
            }

            calculated_total_hours = 0
            for day in range(1, 32):
                symbol = row_dict.get(str(day))
                if symbol is not None:
                    parsed_symbol = parse_symbol(symbol)

                    # Używamy `or 0`, aby obsłużyć None zwracane przez parser
                    work_h = parsed_symbol.get('work_hours', 0) or 0
                    calculated_total_hours += work_h

                    # Zapisujemy dane dnia do słownika
                    processed_data[key]['days'][day] = {
                        'symbol': symbol,
                        'hours': work_h,
                        'start_hour': parsed_symbol.get('start_hour'),
                    }

            # Po przejściu przez wszystkie dni, przypisujemy obliczoną sumę
            processed_data[key]['total_hours'] = calculated_total_hours
            # --- KONIEC NOWEJ LOGIKI ---

        debug_print(
            f"DataProvider: Zakończono budowanie danych dla {len(processed_data)} użytkowników z sumą godzin obliczoną w aplikacji.")
        return processed_data

    @lru_cache(maxsize=100)  # Cache dla kluczy miesięcy
    def _get_month_cache_key(self, year: int, month: int) -> tuple:
        """Cache key dla miesiąca"""
        return (year, month)

    def get_events_for_user_date(self, user_id: int, date_str: str, active_only: bool = True) -> List[Dict]:
        """
        Zwraca listę zdarzeń dla danego użytkownika i daty.
        Jeśli active_only=True, zwraca tylko zdarzenia ze statusem innym niż '0'.
        """
        if not date_str or not user_id or date_str.count('-') != 2:
            return []

        try:
            year, month, _ = date_str.split('-')
            year, month = int(year), int(month)
        except (ValueError, TypeError):
            return []

        cache_key = (year, month)
        container = self.monthly_cache.get(cache_key)

        if not container:
            log_warning(f"DataProvider: Brak kontenera w cache dla klucza {cache_key} w get_events_for_user_date.")
            return []

        standardized_date = self._standardize_date(date_str)
        cache_key_event = (user_id, standardized_date)

        events_for_cell = container.events_cache.get(cache_key_event, [])

        if not active_only:
            return events_for_cell

        active_events = [e for e in events_for_cell if str(e.get('status', '1')) != '0']
        return active_events

    def _fetch_schedule_data(self, year: int, month: int, grupa: int, funkcja: int) -> List[Dict]:
        """Pobiera dane grafiku z bazy z dodatkowymi parametrami."""
        conn = None
        try:
            query = f"SELECT * FROM {SQL_OBJECTS['fn_getscheduledata']}(?, ?, ?, ?)"  # ZAPYTANIE Z 4 PARAMETRAMI
            conn = self.db_connector.get_connection()
            cursor = conn.cursor()
            cursor.execute(query, (year, month, grupa, funkcja))  # PRZEKAZANIE PARAMETRÓW
            columns = [column[0] for column in cursor.description]
            schedule_data = [dict(zip(columns, row)) for row in cursor.fetchall()]
            debug_print(f"DataProvider: Pobrane dane grafiku (nowy format): {len(schedule_data)} wierszy.")
            return schedule_data
        finally:
            if conn:
                conn.close()

    def _fetch_events_data(self, year: int, month: int) -> List[Dict]:
        """Pobiera i mapuje zdarzenia, używając jawnego tłumaczenia nazw kolumn."""
        conn = None
        try:
            query = f"SELECT * FROM {SQL_OBJECTS['fn_geteventsdata']}(?, ?)"
            conn = self.db_connector.get_connection()
            cursor = conn.cursor()
            cursor.execute(query, (year, month))

            columns = [column[0] for column in cursor.description]
            raw_events_as_dicts = [dict(zip(columns, row)) for row in cursor.fetchall()]

            debug_print(f"DataProvider: Pobrane surowe zdarzenia: {len(raw_events_as_dicts)} wierszy.")

            processed_events = []
            for raw_event in raw_events_as_dicts:
                try:
                    # --- KLUCZOWA POPRAWKA: Jawne mapowanie nazw kolumn z bazy na klucze aplikacji ---
                    event = {
                        'type': raw_event.get('EventType'),
                        'id': raw_event.get('Id'),
                        'topic': raw_event.get('Temat'),
                        'name': raw_event.get('Nazwa'),
                        'user_id': raw_event.get('Uzytkownik'),
                        'UzytkownikDane': raw_event.get('UzytkownikDane'),
                        'date': raw_event.get('Data'),
                        'time_from': raw_event.get('DataOd'),
                        'time_to': raw_event.get('DataDo'),
                        'status': raw_event.get('StatusNazwa'),
                        'DataModyfikacji': raw_event.get('DataModyfikacji')
                    }

                    # Ujednolicenie klucza daty do sortowania i filtrowania
                    if event.get('date'):
                        event['date_key'] = self._standardize_date(event['date'])

                    # Formatowanie dat i czasów do spójnego formatu tekstowego
                    for key in ['time_from', 'time_to', 'DataModyfikacji']:
                        value = event.get(key)
                        if hasattr(value, 'strftime'):
                            event[key] = value.strftime('%Y-%m-%d %H:%M')

                    processed_events.append(event)
                except Exception as e:
                    log_error(f"DataProvider: Błąd przetwarzania pojedynczego zdarzenia: {raw_event}. Błąd: {e}")
                    continue  # Przejdź do następnego rekordu w razie błędu

            debug_print(f"DataProvider: Poprawnie przetworzono {len(processed_events)} zdarzeń.")
            return processed_events

        except Exception as e:
            log_error(f"Krytyczny błąd w _fetch_events_data: {e}", exception=e)
            return []
        finally:
            if conn:
                conn.close()

    def _build_events_cache(self, events_data: List[Dict]) -> Dict[Tuple[int, str], List[Dict]]:
        """Buduje cache zdarzeń (user_id, date_key) -> [list_of_events]"""
        events_cache = {}
        for event in events_data:
            user_id = event.get('user_id')
            date_key = self._standardize_date(event.get('date_key', ''))  # Użyj znormalizowanej daty

            if user_id and date_key:
                cache_key_event = (user_id, date_key)  # Poprawiono nazwę zmiennej
                if cache_key_event not in events_cache:
                    events_cache[cache_key_event] = []
                events_cache[cache_key_event].append(event)
        debug_print(f"DataProvider: Zbudowano events_cache z {len(events_cache)} wpisami.")
        return events_cache

    def clear_cache(self):
        """
        Czyści cały cache danych miesięcznych i ikon.
        Wywoływane przy starcie aplikacji lub gdy jest to absolutnie konieczne.
        """
        cache_count = len(self.monthly_cache)
        icons_count = len(self._icons_cache_by_month)

        self.monthly_cache.clear()
        self._icons_cache_by_month.clear()

        debug_print(
            f"DataProvider: Wyczyszczono CAŁY cache: {cache_count} kontenerów, {icons_count} wpisów cache ikon")

    def _standardize_date(self, date_obj) -> str:
        """Standaryzuje format daty do 'YYYY-MM-DD'"""
        if not date_obj: return ''
        if isinstance(date_obj, str):
            date_part = date_obj.split(' ')[0].split('T')[0]  # Weź część daty przed czasem
            if len(date_part) == 10:
                if date_part.count('-') == 2:  # Format YYYY-MM-DD
                    try:  # Sprawdź czy to poprawna data
                        datetime.strptime(date_part, '%Y-%m-%d')
                        return date_part
                    except ValueError:
                        pass
                elif date_part.count('.') == 2:  # Format DD.MM.YYYY
                    try:
                        d, m, y = date_part.split('.')
                        if len(y) == 4 and len(m) == 2 and len(d) == 2:
                            datetime.strptime(date_part, '%d.%m.%Y')  # Sprawdź poprawność
                            return f"{y}-{m}-{d}"
                    except ValueError:
                        pass
            # Jeśli nie udało się sparsować, zaloguj i zwróć pusty string lub oryginalną wartość
            log_warning(f"DataProvider: Nie udało się znormalizować daty: '{date_obj}'")
            return date_obj  # Lub '' jeśli preferowane jest czyszczenie niepoprawnych dat

        if hasattr(date_obj, 'strftime'):  # Dla obiektów date/datetime
            return date_obj.strftime('%Y-%m-%d')

        log_warning(f"DataProvider: Nieznany typ daty do standaryzacji: {type(date_obj)}, wartość: {date_obj}")
        return ''

    def invalidate_complete_cache_for_pairs(self, user_date_pairs: List[Tuple[int, str]]):
        """
        Kompleksowe unieważnienie cache dla określonych par (user_id, date_str).
        Wymusza ponowne załadowanie danych o zdarzeniach dla dotkniętych miesięcy.
        """
        if not user_date_pairs:
            return

        affected_months_to_refresh_events = set()
        affected_months_for_icons_signal = set()

        for user_id, date_str in user_date_pairs:
            try:
                std_date_str = self._standardize_date(date_str)
                if not std_date_str or std_date_str.count('-') != 2:
                    log_warning(
                        f"DataProvider: Nieprawidłowy format daty w invalidate_complete_cache_for_pairs: '{date_str}'")
                    continue

                year, month, day = map(int, std_date_str.split('-'))
                month_key = (year, month)

                affected_months_to_refresh_events.add(
                    month_key)  # Zawsze oznaczamy miesiąc do odświeżenia danych zdarzeń
                affected_months_for_icons_signal.add(month_key)

                # Unieważnij cache ikon dla konkretnej komórki
                if month_key in self._icons_cache_by_month:
                    cell_key = (user_id, std_date_str)
                    if cell_key in self._icons_cache_by_month[month_key]:
                        del self._icons_cache_by_month[month_key][cell_key]
                        # debug_print(f"DataProvider: Usunięto z _icons_cache_by_month dla {cell_key}")

                # Zresetuj flagę obliczonych ikon dla kontenera
                if month_key in self.monthly_cache:
                    self.monthly_cache[month_key]._icons_calculated_on_this_instance = False
                    # debug_print(f"DataProvider: Zresetowano _icons_calculated_on_this_instance dla {month_key}")

            except (ValueError, TypeError) as e:
                log_warning(
                    f"DataProvider: Błąd w invalidate_complete_cache_for_pairs przy przetwarzaniu ({user_id}, {date_str}): {e}")
                continue

        # Kluczowa zmiana: Ponownie załaduj dane o zdarzeniach dla wszystkich dotkniętych miesięcy
        for year, month in affected_months_to_refresh_events:
            month_key_tuple = (year, month)
            if month_key_tuple in self.monthly_cache:
                debug_print(
                    f"DataProvider: Wymuszone ponowne ładowanie events_data dla kontenera {year}-{month} w invalidate_complete_cache_for_pairs.")
                container = self.monthly_cache[month_key_tuple]

                # Pobierz świeże dane o zdarzeniach z bazy
                fresh_events_data = self._fetch_events_data(year, month)
                container.events_data = fresh_events_data

                # Przebuduj cache zdarzeń na podstawie świeżych danych
                container.events_cache = self._build_events_cache(fresh_events_data)

                container.last_updated = time.time()
                container._icons_calculated_on_this_instance = False  # Ikony również będą wymagały ponownego przeliczenia

                debug_print(
                    f"DataProvider: Zakończono odświeżanie events_data i events_cache dla {year}-{month}. Nowych zdarzeń: {len(fresh_events_data)}")
                self.data_changed.emit("events", year, month)  # Sygnalizuj zmianę danych zdarzeń
            else:
                # Jeśli kontenera nie ma w cache, zostanie załadowany przy następnym żądaniu
                debug_print(
                    f"DataProvider: Kontener dla {year}-{month} nie istnieje w cache, zostanie załadowany przy potrzebie.")

        for year, month in affected_months_for_icons_signal:
            debug_print(
                f"DataProvider: Sygnalizowanie zmiany ikon dla miesiąca {year}-{month} po invalidate_complete_cache_for_pairs.")
            self.data_changed.emit("icons", year, month)
