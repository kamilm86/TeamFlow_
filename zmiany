Oczywi≈õcie. Rozszerzenie analizy o dodatkowy rok w przesz≈Ço≈õƒá to ≈õwietny pomys≈Ç, kt√≥ry pozwala na g≈Çƒôbsze zrozumienie trend√≥w i odr√≥≈ºnienie jednorazowych waha≈Ñ od d≈Çugofalowych zmian.
Poni≈ºej znajduje siƒô zaktualizowany, kompletny kod do notatnika Jupyter, kt√≥ry por√≥wnuje dane z bie≈ºƒÖcego roku (YTD) z adekwatnymi okresami w dw√≥ch poprzednich latach.
# ==============================================================================
# KROK 1: IMPORT BIBLIOTEK I USTAWIENIA WIZUALIZACJI
# ==============================================================================
import pandas as pd
import sqlalchemy as sa
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# Ustawienia dla wykres√≥w, aby by≈Çy czytelne i estetyczne
sns.set_theme(style="whitegrid")
plt.rcParams['figure.figsize'] = (14, 7)
plt.rcParams['axes.titlesize'] = 18
plt.rcParams['axes.labelsize'] = 14
plt.rcParams['xtick.labelsize'] = 12
plt.rcParams['ytick.labelsize'] = 12
print("‚úÖ Biblioteki za≈Çadowane, styl wykres√≥w ustawiony.")


# ==============================================================================
# KROK 2: WCZYTANIE DANYCH Z BAZY MS SQL SERVER
# ==============================================================================
# Wype≈Çnij poni≈ºsze zmienne swoimi danymi dostƒôpowymi
server_name = "TWOJ_SERWER"
database_name = "TWOJA_BAZA_DANYCH"
table_name = "NAZWA_TWOJEJ_TABELI_RAW"  # Tabela z danymi granularnymi (niezagregowanymi)

try:
    # Tworzenie connection stringa dla uwierzytelniania Windows
    connection_string = f"mssql+pyodbc://{server_name}/{database_name}?driver=ODBC+Driver+17+for+SQL+Server&trusted_connection=yes"
    engine = sa.create_engine(connection_string)
    
    query = f"SELECT * FROM {table_name}"
    df_raw = pd.read_sql(query, engine)
    
    print(f"‚úÖ Pomy≈õlnie po≈ÇƒÖczono i wczytano {len(df_raw)} rekord√≥w z tabeli {table_name}.")

except Exception as e:
    print(f"‚ùå B≈ÇƒÖd podczas po≈ÇƒÖczenia z bazƒÖ danych: {e}")
    print("‚ö†Ô∏è Tworzƒô przyk≈Çadowy, granularny zbi√≥r danych, aby kontynuowaƒá analizƒô.")
    # Generowanie danych przyk≈Çadowych dla TRZECH lat
    date_rng_2025 = pd.to_datetime(pd.date_range(start='2025-01-01', end='2025-09-17', freq='10min'))
    date_rng_2024 = pd.to_datetime(pd.date_range(start='2024-01-01', end='2024-12-31', freq='9min'))
    date_rng_2023 = pd.to_datetime(pd.date_range(start='2023-01-01', end='2023-12-31', freq='11min'))
    all_dates = date_rng_2025.union(date_rng_2024).union(date_rng_2023)
    
    data = {
        'callid': range(len(all_dates)),
        'Data': all_dates,
        'Kanal_kontakt': np.random.choice(['voice', 'czat', 'wideo'], len(all_dates), p=[0.7, 0.25, 0.05]),
        'czy_odebrane': np.random.choice([1, 0], len(all_dates), p=[0.85, 0.15]),
        'wejscie': np.random.choice(['ivr', 'bot', 'vendor'], len(all_dates), p=[0.5, 0.4, 0.1]),
        'gdzie_koniec': np.random.choice(['konsultant', 'bot', 'transfer', 'ivr'], len(all_dates), p=[0.7, 0.15, 0.1, 0.05]),
        'czas_rozmowy': np.random.gamma(2, 150, len(all_dates)).astype(int)
    }
    df_raw = pd.DataFrame(data)
    df_raw.loc[df_raw['czy_odebrane'] == 0, 'czas_rozmowy'] = 0

print("\n--- Pr√≥bka danych (5 pierwszych wierszy) ---")
display(df_raw.head())


# ==============================================================================
# KROK 3: PRZYGOTOWANIE DANYCH I IMPLEMENTACJA LOGIKI YTD DLA 3 LAT
# ==============================================================================
print("\n--- Rozpoczƒôto przygotowanie danych ---")
# Konwersja kolumny 'Data' i tworzenie cech
df_raw['Data'] = pd.to_datetime(df_raw['Data'])
df_raw['Rok'] = df_raw['Data'].dt.year
df_raw['Dzien_Roku'] = df_raw['Data'].dt.dayofyear # Klucz do por√≥wna≈Ñ YTD

# --- Implementacja logiki Year-to-Date (YTD) dla 3 lat ---
# 1. Zdefiniuj lata do analizy
current_year = df_raw['Rok'].max()
previous_year = current_year - 1
two_years_ago = current_year - 2

# 2. Znajd≈∫ ostatni dzie≈Ñ roku w bie≈ºƒÖcym roku
latest_date_cy = df_raw[df_raw['Rok'] == current_year]['Data'].max()
latest_day_of_year = latest_date_cy.dayofyear

print(f"Lata w analizie: {current_year}, {previous_year}, {two_years_ago}")
print(f"Najnowsze dane pochodzƒÖ z: {latest_date_cy.strftime('%Y-%m-%d')} (to {latest_day_of_year}. dzie≈Ñ roku)")

# 3. Odfiltruj dane, aby obejmowa≈Çy ten sam okres we wszystkich latach
years_to_analyze = [current_year, previous_year, two_years_ago]
df_ytd = df_raw[(df_raw['Dzien_Roku'] <= latest_day_of_year) & (df_raw['Rok'].isin(years_to_analyze))].copy()

# Dodatkowe kolumny czasowe (po filtrowaniu dla wydajno≈õci)
df_ytd['Miesiac'] = df_ytd['Data'].dt.month
df_ytd['Godzina'] = df_ytd['Data'].dt.hour

print(f"‚úÖ Dane odfiltrowane. Analiza zostanie przeprowadzona dla okresu od 1 stycznia do {latest_day_of_year}. dnia roku dla lat {years_to_analyze}.")

# ==============================================================================
# KROK 4: ANALIZA POR√ìWNAWCZA I WIZUALIZACJA DANYCH (YTD dla 3 lat)
# ==============================================================================
print("\n--- Rozpoczƒôto g≈Ç√≥wnƒÖ analizƒô por√≥wnawczƒÖ (YTD) ---")

# --- 4.1. Og√≥lny Wolumen Interakcji (YTD) --- [WERSJA POPRAWIONA]

# Agregacja pozostaje bez zmian
total_volume_ytd = df_ytd.groupby('Rok')['callid'].count().reset_index().rename(columns={'callid': 'liczba_polaczen'})

# --- BEZPIECZNE POBIERANIE DANYCH ---
# Tworzymy s≈Çownik z wynikami, np. {2025: 15000, 2024: 12000}
volume_dict = pd.Series(total_volume_ytd.liczba_polaczen.values, index=total_volume_ytd.Rok).to_dict()

# U≈ºywamy metody .get(rok, 0), kt√≥ra zwr√≥ci 0, je≈õli dany rok nie istnieje w s≈Çowniku
vol_cy = volume_dict.get(current_year, 0)
vol_py = volume_dict.get(previous_year, 0)
vol_2ya = volume_dict.get(two_years_ago, 0)

# --- BEZPIECZNE OBLICZANIE PROCENT√ìW (unikamy dzielenia przez zero) ---
yoy_change_1 = ((vol_cy - vol_py) / vol_py) * 100 if vol_py > 0 else float('inf')
yoy_change_2 = ((vol_py - vol_2ya) / vol_2ya) * 100 if vol_2ya > 0 else float('inf')

# Wizualizacja
plt.figure(figsize=(12, 7))
ax = sns.barplot(data=total_volume_ytd, x='Rok', y='liczba_polaczen', palette='viridis', order=years_to_analyze)

# Tworzymy dynamiczny tytu≈Ç, kt√≥ry poka≈ºe zmiany tylko je≈õli mia≈Çy sens
title_cy_vs_py = f'{current_year} vs {previous_year}: {yoy_change_1:.2f}%' if vol_py > 0 else f'{current_year} vs {previous_year}: Brak danych z {previous_year}'
title_py_vs_2ya = f'{previous_year} vs {two_years_ago}: {yoy_change_2:.2f}%' if vol_2ya > 0 else f'{previous_year} vs {two_years_ago}: Brak danych z {two_years_ago}'

ax.set_title(f'Ca≈Çkowity Wolumen Interakcji (YTD)\n{title_cy_vs_py} | {title_py_vs_2ya}', fontsize=18)

for p in ax.patches:
    ax.annotate(f'{int(p.get_height()):,}', (p.get_x() + p.get_width() / 2., p.get_height()),
                ha='center', va='center', fontsize=14, color='black', xytext=(0, 10),
                textcoords='offset points')
plt.ylabel('Liczba Po≈ÇƒÖcze≈Ñ')
plt.xlabel('Rok')
plt.show()



# --- 4.2. Analiza Wolumenu w Podziale na Kana≈Çy (YTD) ---
channel_volume_ytd = df_ytd.groupby(['Rok', 'Kanal_kontakt'])['callid'].count().reset_index().rename(columns={'callid': 'liczba_polaczen'})
sns.barplot(data=channel_volume_ytd, x='Kanal_kontakt', y='liczba_polaczen', hue='Rok', palette='mako', hue_order=years_to_analyze)
plt.title('Wolumen Interakcji w Podziale na Kana≈Çy (YTD)')
plt.ylabel('Liczba Po≈ÇƒÖcze≈Ñ')
plt.xlabel('Kana≈Ç Kontaktu')
plt.legend(title='Rok')
plt.show()

# --- 4.3. Analiza ≈öredniego Czasu Obs≈Çugi (AHT) (YTD) ---
df_answered_ytd = df_ytd[df_ytd['czy_odebrane'] == 1]
aht_ytd = df_answered_ytd.groupby('Rok')['czas_rozmowy'].mean().reset_index().rename(columns={'czas_rozmowy': 'Sredni_AHT_s'})
plt.figure(figsize=(12, 7))
ax = sns.barplot(data=aht_ytd, x='Rok', y='Sredni_AHT_s', palette='coolwarm', order=years_to_analyze)
ax.set_title('≈öredni Czas Obs≈Çugi - AHT (YTD)')
for p in ax.patches:
    ax.annotate(f'{p.get_height():.1f}s', (p.get_x() + p.get_width() / 2., p.get_height()),
                ha='center', va='center', fontsize=14, color='black', xytext=(0, 10),
                textcoords='offset points')
plt.ylabel('AHT (w sekundach)')
plt.xlabel('Rok')
plt.show()

# --- 4.4. Analiza ≈öcie≈ºki Klienta: Wej≈õcie i Zako≈Ñczenie (YTD) ---
fig, axes = plt.subplots(1, 2, figsize=(22, 8))
entry_points_ytd = df_ytd.groupby(['Rok', 'wejscie'])['callid'].count().reset_index()
exit_points_ytd = df_ytd.groupby(['Rok', 'gdzie_koniec'])['callid'].count().reset_index()

sns.barplot(ax=axes[0], data=entry_points_ytd, x='wejscie', y='callid', hue='Rok', palette='viridis', hue_order=years_to_analyze)
axes[0].set_title('Punkty Wej≈õcia Interakcji (YTD)')
axes[0].set_ylabel('Liczba Po≈ÇƒÖcze≈Ñ')

sns.barplot(ax=axes[1], data=exit_points_ytd, x='gdzie_koniec', y='callid', hue='Rok', palette='plasma', hue_order=years_to_analyze)
axes[1].set_title('Punkty Zako≈Ñczenia Interakcji (YTD)')
axes[1].set_ylabel('Liczba Po≈ÇƒÖcze≈Ñ')
plt.tight_layout()
plt.show()

# --- 4.5. Analiza Sezonowo≈õci i Trend√≥w Miesiƒôcznych (YTD) ---
monthly_trends_ytd = df_ytd.groupby(['Rok', 'Miesiac'])['callid'].count().reset_index()
sns.lineplot(data=monthly_trends_ytd, x='Miesiac', y='callid', hue='Rok', palette='Set1', marker='o', linewidth=2.5, hue_order=years_to_analyze)
plt.title('Miesiƒôczne Trendy Wolumenu Po≈ÇƒÖcze≈Ñ (YTD)')
plt.xlabel('MiesiƒÖc')
plt.ylabel('Liczba Po≈ÇƒÖcze≈Ñ')
plt.xticks(ticks=range(1, 13))
plt.legend(title='Rok')
plt.grid(True, which='both', linestyle='--')
plt.show()

# ==============================================================================
# KROK 5: G≈ÅƒòBSZA ANALIZA DZIƒòKI DANYM GRANULARNYM (BONUS)
# ==============================================================================
print("\n--- Rozpoczƒôto analizy dodatkowe (bonus) ---")

# --- 5.1. Analiza obciƒÖ≈ºenia w ciƒÖgu dnia (Peak Hour Analysis) ---
hourly_volume_ytd = df_ytd.groupby(['Rok', 'Godzina'])['callid'].count().reset_index()
g = sns.FacetGrid(hourly_volume_ytd, col="Rok", col_order=years_to_analyze, height=6, aspect=1.2)
g.map(sns.barplot, "Godzina", "callid", order=range(24), palette='rocket')
g.set_axis_labels("Godzina Dnia", "Liczba Po≈ÇƒÖcze≈Ñ")
g.set_titles(col_template="Rok {col_name}")
g.fig.suptitle('Rozk≈Çad Po≈ÇƒÖcze≈Ñ w CiƒÖgu Dnia (YTD)', y=1.03, fontsize=20)
plt.show()

# ==============================================================================
# KROK 6: PODSUMOWANIE I REKOMENDACJE BIZNESOWE
# ==============================================================================
print("\n\n" + "="*80)
print("üí° PODSUMOWANIE WNIOSK√ìW I REKOMENDACJE BIZNESOWE (ANALIZA 3-LETNIA) üí°")
print("="*80)
print(f"""
Analiza por√≥wnawcza okresu od 1 stycznia do {latest_date_cy.strftime('%d %B')} dla lat {two_years_ago}, {previous_year} i {current_year} dostarcza bogatego kontekstu historycznego:

1.  **D≈Çugofalowy Trend Wolumenu:**
    - Zmiana {previous_year} vs {two_years_ago}: Wolumen {'wzr√≥s≈Ç' if yoy_change_2 > 0 else 'spad≈Ç'} o {yoy_change_2:.2f}%.
    - Zmiana {current_year} vs {previous_year}: Wolumen {'wzr√≥s≈Ç' if yoy_change_1 > 0 else 'spad≈Ç'} o {yoy_change_1:.2f}%.
    - Wniosek: Por√≥wnujƒÖc obie zmiany, widzimy, ≈ºe trend [np. wzrostowy] [np. przyspiesza / zwalnia / odwraca siƒô]. To pozwala lepiej prognozowaƒá przysz≈Çe zapotrzebowanie.

2.  **Ewolucja Preferencji Kana≈Ç√≥w:** Analiza trzech lat wyra≈∫nie pokazuje, kt√≥re kana≈Çy [np. czat i wideo] systematycznie zyskujƒÖ na popularno≈õci kosztem [np. kana≈Çu voice].
    Rekomendacja: Ten d≈Çugofalowy trend to silny sygna≈Ç, aby strategicznie inwestowaƒá w rozw√≥j i skalowanie kana≈Ç√≥w cyfrowych.

3.  **Efektywno≈õƒá Operacyjna (AHT):** Obserwujemy trend AHT na przestrzeni trzech lat:
    - AHT w {two_years_ago}: {aht_ytd.loc[aht_ytd['Rok'] == two_years_ago, 'Sredni_AHT_s'].iloc[0]:.1f}s
    - AHT w {previous_year}: {aht_ytd.loc[aht_ytd['Rok'] == previous_year, 'Sredni_AHT_s'].iloc[0]:.1f}s
    - AHT w {current_year}: {aht_ytd.loc[aht_ytd['Rok'] == current_year, 'Sredni_AHT_s'].iloc[0]:.1f}s
    - Wniosek: Trend ten mo≈ºe wskazywaƒá na [np. rosnƒÖcƒÖ z≈Ço≈ºono≈õƒá problem√≥w klient√≥w] lub [np. efekty wdro≈ºonych usprawnie≈Ñ systemowych].
    
4.  **Dojrza≈Ço≈õƒá Automatyzacji:** Por√≥wnanie ≈õcie≈ºki klienta w trzech okresach pozwala oceniƒá, czy nasze inwestycje w bota i IVR przynoszƒÖ d≈Çugofalowe rezultaty w postaci wiƒôkszej liczby interakcji rozwiƒÖzywanych bez udzia≈Çu konsultanta.

5.  **Stabilno≈õƒá Wzorc√≥w Godzinowych:** Analiza rozk≈Çadu po≈ÇƒÖcze≈Ñ w ciƒÖgu dnia dla trzech lat pozwala sprawdziƒá, czy godziny szczytu sƒÖ stabilne, czy te≈º ulegajƒÖ przesuniƒôciu.
    Rekomendacja: Je≈õli wzorce sƒÖ stabilne, mo≈ºemy z du≈ºƒÖ pewno≈õciƒÖ planowaƒá grafiki. Je≈õli siƒô zmieniajƒÖ, nale≈ºy dostosowaƒá modele prognozowania Workforce Management.

Dodanie trzeciego roku do analizy pozwala odr√≥≈ºniƒá kr√≥tkoterminowe anomalie od trwa≈Çych, strategicznych zmian w zachowaniu klient√≥w i wydajno≈õci operacyjnej.
""")
print("="*80)


