Absolutnie. WidzÄ™, Å¼e masz dobrze zorganizowanÄ… klasÄ™ DatabaseManager i uÅ¼ywasz zaawansowanych technik takich jak batching, dynamiczne mapowanie typÃ³w danych (map_data_types), obsÅ‚ugÄ™ poÅ‚Ä…czeÅ„ i rÃ³Å¼ne strategie wstawiania (Oracle, SQL Server, Impala).
PoniÅ¼ej przedstawiam peÅ‚ny kod metody insert_data, Å‚Ä…czÄ…cy TwojÄ… oryginalnÄ… logikÄ™ z proponowanym mechanizmem lookup/MERGE i korzystajÄ…cy z Twoich istniejÄ…cych pomocniczych metod (jak te, ktÃ³re widaÄ‡ na zdjÄ™ciach).
Ze wzglÄ™du na to, Å¼e nie mam dostÄ™pu do peÅ‚nej klasy i wszystkich Twoich metod, zaÅ‚oÅ¼yÅ‚em istnienie i poprawnoÅ›Ä‡ Twoich wewnÄ™trznych metod:
 * _get_engine
 * self.handle_nulls
 * self.standardize_column_names
 * self.map_data_types
 * self.check_column_size
 * self.create_table_if_not_exists
 * self._custom_merge_insert (wklejona w poprzedniej odpowiedzi)
ðŸ§© PeÅ‚ny kod metody insert_data (z Lookup/Merge)
import pandas as pd
import numpy as np
import gc
from typing import List, Optional

# ZaÅ‚oÅ¼enie: PoniÅ¼sza funkcja znajduje siÄ™ w klasie DatabaseManager
def insert_data(self, df: pd.DataFrame, target_db: str, table_name: str, 
                schema: str, if_exists: str = 'append', batch_size: int = 1000000, 
                verbose: bool = True, use_fast_executemany: bool = True, 
                lookup_keys: Optional[List[str]] = None) -> None:
    
    """
    Wstawia dane z DataFrame do bazy docelowej (target_db).
    ObsÅ‚uguje batching, czyszczenie danych, mapowanie typÃ³w oraz opcjonalny lookup (MERGE/NOT EXISTS).
    
    Args:
        df (pd.DataFrame): DataFrame do wstawienia.
        target_db (str): Nazwa bazy docelowej (np. 'Oracle', 'SQLServer', 'Impala').
        table_name (str): Nazwa tabeli docelowej.
        schema (str): Nazwa schematu docelowego.
        if_exists (str): Jak obsÅ‚uÅ¼yÄ‡ istniejÄ…cÄ… tabelÄ™ ('append', 'replace').
        batch_size (int): Liczba rekordÃ³w w pojedynczej partii.
        verbose (bool): Czy logowaÄ‡ postÄ™p.
        use_fast_executemany (bool): UÅ¼ycie optymalizacji dla SQL Server.
        lookup_keys (Optional[List[str]]): Lista kluczy kolumn do uÅ¼ycia w lookup (INSERT WHERE NOT EXISTS).
                                           JeÅ›li None, uÅ¼ywa standardowego INSERT/APPEND.
    """

    self.logger.info(f"Rozpoczynanie wstawiania do {target_db}.{schema}.{table_name} (Liczba wierszy: {len(df)})")

    # 1. Przygotowanie: Pobranie Engine i PoÅ‚Ä…czenie
    engine = self._get_engine(target_db) # ZakÅ‚adam, Å¼e ta metoda dziaÅ‚a
    
    try:
        with engine.connect() as connection:
            self.logger.info("PomyÅ›lnie utworzone poÅ‚Ä…czenie z bazÄ… docelowÄ….")
            
            # Ustawienia transakcyjne (jak widaÄ‡ na Twoim zdjÄ™ciu)
            # W SQL Server, te ustawienia mogÄ… byÄ‡ waÅ¼ne
            if target_db == 'SQLServer':
                connection.execute("SET LOCK_TIMEOUT 1200000")
                connection.execute("SET TEXTSIZE 66000000")
                connection.execute("SET TRANSACTION ISOLATION LEVEL READ COMMITTED")
                connection.execute("SET XACT_ABORT ON") # WaÅ¼ne dla transakcji

            # 2. Czyszczenie i transformacje DataFrame
            df_to_load = df.copy() # Pracujemy na kopii

            # Czyszczenie nazw kolumn i typÃ³w (jak na zdjÄ™ciach)
            df_to_load = self.standardize_column_names(df_to_load) 
            df_to_load = self.handle_nulls(df_to_load)
            df_to_load = df_to_load.astype(str).replace({pd.NaT: None, 'nan': None}) # Typowe czyszczenie przed konwersjÄ…
            
            # Mapowanie typÃ³w i pobranie kolumn_def dla CREATE TABLE
            dtype_dict = self.map_data_types(df_to_load, target_db) 
            df_to_load = df_to_load.astype(dtype_dict)
            
            # 3. ZarzÄ…dzanie schematem i tabelÄ…
            if not self.create_table_if_not_exists(self, engine, df_to_load, table_name, schema, target_db):
                 # MoÅ¼liwoÅ›Ä‡ obsÅ‚ugi 'replace' lub 'append' przez drop/truncate jeÅ›li if_exists != 'append'
                 if if_exists == 'replace':
                     connection.execute(f'DROP TABLE "{schema}"."{table_name}"')
                     self.create_table_if_not_exists(self, engine, df_to_load, table_name, schema, target_db)
                 elif if_exists == 'truncate':
                     connection.execute(f'TRUNCATE TABLE "{schema}"."{table_name}"')
            
            # Upewnienie siÄ™, Å¼e rozmiary kolumn VARCHAR sÄ… wystarczajÄ…ce
            self.check_column_size(engine, df_to_load, table_name, schema, target_db)
            
            # 4. Åadowanie partii (Batching)
            total_rows = len(df_to_load)
            if total_rows == 0:
                self.logger.warning("DataFrame jest pusty. ZakoÅ„czenie wstawiania.")
                return

            full_batches = total_rows // batch_size
            last_batch_size = total_rows % batch_size
            last_batch = None
            
            loaded_rows = 0
            
            # Przetwarzanie peÅ‚nych partii
            for batch_num in range(full_batches):
                start = batch_num * batch_size
                end = start + batch_size
                batch = df_to_load.iloc[start:end].copy()
                
                # Opcjonalne zbieranie Å›mieci
                if verbose and batch_num % 10 == 0:
                    gc.collect()

                if verbose:
                    current_progress = (end / total_rows) * 100
                    self.logger.info(f"Wstawianie partii {batch_num+1}/{full_batches+1} ({len(batch)} wierszy) do {schema}.{table_name}. PostÄ™p: {current_progress:.2f}%")
                
                # --- WÅAÅšCIWE WSTAWIANIE PARTII Z UÅ»YCIEM NOWEJ METODY ---
                # UÅ¼ywamy metody merge/insert, ktÃ³ra obsÅ‚uÅ¼y zarÃ³wno standardowy INSERT, jak i INSERT WHERE NOT EXISTS (lookup)
                self._custom_merge_insert(
                    target_db=target_db,
                    batch=batch,
                    table=table_name,
                    schema=schema,
                    lookup_keys=lookup_keys, # Klucze lookup sÄ… tu przekazywane
                    conn=connection
                )
                
                loaded_rows += len(batch)
                del batch
                gc.collect()


            # 5. Przetwarzanie ostatniej partii (jeÅ›li istnieje)
            if last_batch_size > 0:
                start = full_batches * batch_size
                last_batch = df_to_load.iloc[start:total_rows].copy()

                self.logger.info(f"Rozpoczynam przetwarzanie ostatniej partii (Liczba wierszy: {len(last_batch)})")
                gc.collect()
                
                # --- WÅAÅšCIWE WSTAWIANIE OSTATNIEJ PARTII Z UÅ»YCIEM NOWEJ METODY ---
                self._custom_merge_insert(
                    target_db=target_db,
                    batch=last_batch,
                    table=table_name,
                    schema=schema,
                    lookup_keys=lookup_keys, # Klucze lookup sÄ… tu przekazywane
                    conn=connection
                )
                
                loaded_rows += len(last_batch)
                del last_batch
                gc.collect()
            
            # 6. Kontrola i Logowanie Sukcesu
            self.logger.info(f"ZaÅ‚adowano {loaded_rows} z {total_rows} wierszy.")
            if loaded_rows != total_rows:
                self.logger.warning(f"RÃ³Å¼nica w zaÅ‚adowanej liczbie wierszy: {total_rows - loaded_rows} wierszy.")
            else:
                self.logger.info(f"PomyÅ›lnie zaÅ‚adowano wszystkie {loaded_rows} wierszy do {schema}.{table_name}.")

    except Exception as e:
        self.logger.error(f"Krytyczny bÅ‚Ä…d w metodzie insert_data: {e}")
        # MoÅ¼esz dodaÄ‡ rollback, jeÅ›li uÅ¼ywasz rÄ™cznych transakcji, ale przy with engine.connect() jest to czÄ™sto automatyczne.
        raise
    finally:
        if 'engine' in locals():
            self.logger.info("Zamykanie puli poÅ‚Ä…czeÅ„ dla bazy docelowej.")
            # engine.dispose() - zaleÅ¼y od Twojej implementacji get_engine

ðŸ“‹ Implementacja _custom_merge_insert
PamiÄ™taj, aby wkleiÄ‡ rÃ³wnieÅ¼ kod funkcji _custom_merge_insert, ktÃ³rÄ… przedstawiÅ‚em wczeÅ›niej, poniewaÅ¼ jest ona kluczowa dla obsÅ‚ugi klucza lookup_keys:
# --- Implementacja funkcji z poprzedniej odpowiedzi (skrÃ³t) ---
def _custom_merge_insert(self, target_db: str, batch: pd.DataFrame, table: str, schema: str,
                         lookup_keys: List[str], conn) -> None:
    # ... (kod, ktÃ³ry tworzy tabelÄ™ tymczasowÄ…, wykonuje MERGE/NOT EXISTS INSERT i usuwa tabelÄ™)
    pass # PamiÄ™taj, aby wkleiÄ‡ tu faktycznÄ… implementacjÄ™

OczywiÅ›cie, oto peÅ‚ny kod dla funkcji _custom_merge_insert, ktÃ³ry implementuje logikÄ™ INSERT WHERE NOT EXISTS (lookup) z uÅ¼yciem tabeli tymczasowej.
Funkcja ta dynamicznie generuje i wykonuje kwerendy SQL (MERGE dla Oracle, INSERT INTO ... NOT EXISTS dla innych) po wczytaniu partii danych do tymczasowej tabeli w bazie docelowej.
import pandas as pd
import uuid
from typing import List

# --- Funkcja _custom_merge_insert (w klasie DatabaseManager) ---

def _custom_merge_insert(self, target_db: str, batch: pd.DataFrame, table: str, schema: str,
                         lookup_keys: List[str], conn) -> None:
    
    """
    Realizuje wstawienie rekordÃ³w, ktÃ³re nie istniejÄ… (lookup)
    z uÅ¼yciem tabeli tymczasowej i kwerendy MERGE/NOT EXISTS.
    JeÅ›li lookup_keys jest puste, uÅ¼ywa standardowego INSERT (poprzez to_sql).
    
    Args:
        target_db (str): Nazwa bazy docelowej (np. 'Oracle', 'SQLServer', 'Impala').
        batch (pd.DataFrame): Partia danych do wstawienia.
        table (str): Nazwa tabeli docelowej.
        schema (str): Nazwa schematu docelowego.
        lookup_keys (List[str]): Lista kluczy kolumn do uÅ¼ycia w lookup.
        conn: Aktywne poÅ‚Ä…czenie SQLAlchemy (z engine.connect()).
    """
    
    # 1. Sprawdzenie, czy ma byÄ‡ uÅ¼yty lookup
    if not lookup_keys:
        self.logger.info("Brak kluczy lookup. UÅ¼ycie standardowego wstawiania (to_sql).")
        # MoÅ¼esz tutaj zastÄ…piÄ‡ to_sql swoimi niestandardowymi funkcjami insertujÄ…cymi,
        # np. self._custom_insert_oracle(...)
        batch.to_sql(table, conn, schema=schema, if_exists='append', index=False)
        return

    # 2. Przygotowanie: Tabela tymczasowa
    # UÅ¼ycie UUID gwarantuje unikalnoÅ›Ä‡ nazwy tymczasowej tabeli
    temp_table_name = f"TEMP_{uuid.uuid4().hex}"
    
    self.logger.info(f"Tworzenie tymczasowej tabeli {temp_table_name} dla partii ({len(batch)} rekordÃ³w).")
    
    try:
        # UÅ¼ycie to_sql do szybkiego utworzenia tabeli tymczasowej z danymi
        batch.to_sql(temp_table_name, conn, schema=schema, if_exists='replace', index=False)
        
        # Przygotowanie listy kolumn i nazw tabel w formacie SQL z cudzysÅ‚owami
        # ZakÅ‚adamy, Å¼e uÅ¼ywasz cudzysÅ‚owÃ³w dla nazw kolumn generowanych przez to_sql i w bazie
        all_cols_quoted = [f'"{col}"' for col in batch.columns]
        all_cols_str = ", ".join(all_cols_quoted)
        
        # Przygotowanie warunku poÅ‚Ä…czenia (JOIN)
        join_conditions = " AND ".join([f"T.\"{key}\" = S.\"{key}\"" for key in lookup_keys])
        
        sql_query = ""
        
        if target_db == 'Oracle':
            # --- Oracle: UÅ¼ycie MERGE ---
            
            # W MERGE VALUES musimy odwoÅ‚aÄ‡ siÄ™ do kolumn w tabeli ÅºrÃ³dÅ‚owej (S)
            values_cols = ', '.join([f"S.{col}" for col in all_cols_quoted])
            
            sql_query = f"""
            MERGE INTO "{schema}"."{table}" T
            USING "{schema}"."{temp_table_name}" S
            ON ({join_conditions})
            WHEN NOT MATCHED THEN
                INSERT ({all_cols_str})
                VALUES ({values_cols})
            """
            
        elif target_db in ['SQLServer', 'Impala']:
            # --- SQL Server / Impala: UÅ¼ycie NOT EXISTS (bezpieczna alternatywa) ---
            
            # Warunek NOT EXISTS
            where_not_exists = " AND ".join([f"T.\"{key}\" = S.\"{key}\"" for key in lookup_keys])
            
            # WybÃ³r kolumn z tabeli ÅºrÃ³dÅ‚owej (S)
            select_cols = ', '.join([f"S.{col}" for col in all_cols_quoted])
            
            sql_query = f"""
            INSERT INTO "{schema}"."{table}" ({all_cols_str})
            SELECT
                {select_cols}
            FROM
                "{schema}"."{temp_table_name}" S
            WHERE NOT EXISTS (
                SELECT 1
                FROM "{schema}"."{table}" T
                WHERE {where_not_exists}
            )
            """
        else:
            raise NotImplementedError(f"Lookup/MERGE nie jest zaimplementowany dla bazy danych: {target_db}")

        self.logger.info("Wykonanie operacji MERGE/NOT EXISTS INSERT.")
        conn.execute(sql_query)
        
    finally:
        # 3. Czyszczenie: UsuniÄ™cie tabeli tymczasowej (ZAWSZE musi siÄ™ wykonaÄ‡)
        self.logger.info(f"Usuwanie tymczasowej tabeli {temp_table_name}.")
        
        try:
            # UÅ¼ycie parametru 'schema' jest waÅ¼ne
            conn.execute(f'DROP TABLE "{schema}"."{temp_table_name}"')
        except Exception as e:
            self.logger.error(f"Nie udaÅ‚o siÄ™ usunÄ…Ä‡ tabeli tymczasowej {temp_table_name}: {e}")

PamiÄ™taj, aby tÄ™ funkcjÄ™ umieÅ›ciÄ‡ wewnÄ…trz Twojej klasy DatabaseManager i upewniÄ‡ siÄ™, Å¼e ma dostÄ™p do:
 * self.logger (do logowania).
 * Bibliotek pandas, uuid oraz typing.
 * Aktywnego poÅ‚Ä…czenia conn przekazanego z funkcji insert_data.
