# data_provider.py

from PySide6.QtCore import QObject, Signal
from db_connector import DatabaseConnector
from datetime import datetime, timedelta
import time
from app_settings import app_settings # ZMIANA
from debug_utils import debug_print, log_warning, log_error
from dataclasses import dataclass, field
from typing import Dict, List, Tuple, Optional, Any
from functools import lru_cache
from symbol_parser import parse_symbols_batch,parse_symbol
from config import SQL_OBJECTS

@dataclass
class MonthlyDataContainer:
    """Kontener na wszystkie dane miesiąca"""
    schedule_data: List[Any]
    events_data: List[Dict]
    processed_data_base: Dict
    events_cache: Dict[Tuple[int, str], List[Dict]]
    last_updated: float
    _icons_calculated_on_this_instance: bool = field(default=False, repr=False, compare=False)

    def __post_init__(self):
        if not hasattr(self, 'last_updated'):
            self.last_updated = time.time()


class DataProvider(QObject):
    """
    DataProvider z ograniczonym odświeżaniem ikon
    """
    data_changed = Signal(str, int, int)  # Typ danych, rok, miesiąc

    def __init__(self):
        super().__init__()
        self.db_connector = DatabaseConnector
        self.monthly_cache: Dict[Tuple[int, int, int, int], MonthlyDataContainer] = {}
        self.forecast_cache: Dict[Tuple[int, int], List[Dict]] = {}
        self.audit_cache: Dict[Tuple[int, int], List[Dict]] = {}
        self._icons_cache_by_month: Dict[Tuple[int, int], Dict[Tuple[int, str], Dict]] = {}
        self.publish_status_cache = {}  # Pamięć podręczna dla statusu publikacji
        from column_mapper import ColumnMapper
        self.column_mapper = ColumnMapper()
        self._current_year: Optional[int] = None
        self._current_month: Optional[int] = None

    def is_schedule_published(self, year: int, month: int) -> bool:
        """Sprawdza, czy grafik na dany miesiąc jest opublikowany. Używa prostej pamięci podręcznej."""
        cache_key = (year, month)
        if cache_key in self.publish_status_cache:
            return self.publish_status_cache[cache_key]

        try:
            conn = self.db_connector.get_connection()
            cursor = conn.cursor()
            query = f"SELECT TOP 1 1 FROM {SQL_OBJECTS['datypublikacjigrafiku']} WHERE Rok=? AND Miesiac=? AND Status=1"
            cursor.execute(query, (year, month))
            result = cursor.fetchone()
            conn.close()

            is_published = result is not None
            self.publish_status_cache[cache_key] = is_published
            debug_print(f"Sprawdzono status publikacji dla {year}-{month}: {is_published}")
            return is_published
        except Exception as e:
            log_error(f"Błąd podczas sprawdzania statusu publikacji dla {year}-{month}: {e}", exception=e)
            # W przypadku błędu, dla bezpieczeństwa załóż, że jest opublikowany (wymagaj potwierdzeń)
            return True

    def clear_publish_status_cache(self, year: int, month: int):
        """Czyści pamięć podręczną statusu publikacji dla konkretnego miesiąca."""
        cache_key = (year, month)
        if cache_key in self.publish_status_cache:
            del self.publish_status_cache[cache_key]
            debug_print(f"Wyczyszczono cache statusu publikacji dla {year}-{month}")

    def get_schedule_audit_data(self, year: int, month: int, limit: Optional[int] = None) -> List[Dict]:
        """
        Pobiera historię zmian grafiku, z opcjonalnym limitem TOP N.
        Cache jest używany tylko wtedy, gdy pobierane są wszystkie dane (limit=None).
        """
        cache_key = (year, month)
        # Użyj cache'a tylko, jeśli prosimy o pełny zestaw danych
        if limit is None and cache_key in self.audit_cache:
            debug_print(f"DataProvider: Używam cache dla danych audytowych dla {year}-{month}")
            return self.audit_cache[cache_key]

        try:
            conn = self.db_connector.get_connection()
            cursor = conn.cursor()

            # Dynamiczne budowanie zapytania w zależności od limitu
            if limit:
                query = f"SELECT TOP (?) * FROM {SQL_OBJECTS['fn_getscheduleauditdata']}(?, ?) ORDER BY DataModyfikacji DESC"
                params = (limit, year, month)
            else:
                # Zawsze sortuj, aby zachować spójność
                query = f"SELECT * FROM {SQL_OBJECTS['fn_getscheduleauditdata']}(?, ?) ORDER BY DataModyfikacji DESC"
                params = (year, month)

            cursor.execute(query, params)
            columns = [column[0] for column in cursor.description]
            data = [dict(zip(columns, row)) for row in cursor.fetchall()]
            conn.close()

            debug_print(f"Pobrano {len(data)} wierszy historii zmian dla {year}-{month} (limit: {limit})")

            # Zapisz w cache'u tylko pełny wynik
            if limit is None:
                self.audit_cache[cache_key] = data

            return data
        except Exception as e:
            log_error(f"Błąd podczas pobierania danych audytowych: {e}", exception=e)
            return []

    def clear_audit_cache(self, year: int, month: int):
        """Czyści cache dla danych audytowych dla konkretnego miesiąca."""
        cache_key = (year, month)
        if cache_key in self.audit_cache:
            del self.audit_cache[cache_key]
            debug_print(f"DataProvider: Usunięto cache danych audytowych dla {year}-{month}")

    def clear_monthly_cache(self, year: int, month: int):
        """Czyści główny cache danych miesięcznych dla danego miesiąca."""
        # Klucz dla `monthly_cache` to teraz (rok, miesiąc)
        cache_key = (year, month)
        if cache_key in self.monthly_cache:
            del self.monthly_cache[cache_key]
            debug_print(f"DataProvider: Usunięto z monthly_cache dla {year}-{month}")

        # Klucz dla cache ikon również jest (rok, miesiąc)
        if cache_key in self._icons_cache_by_month:
            del self._icons_cache_by_month[cache_key]
            debug_print(f"DataProvider: Usunięto z _icons_cache_by_month dla {year}-{month}")

    def get_dynamic_icons_for_cell(self, user_id: int, date_str: str) -> Dict:
        """
        POPRAWIONA WERSJA: Zwraca ikony z cache lub oblicza je na podstawie aktywnych zdarzeń
        """
        try:
            year, month, _ = date_str.split('-')
            year, month = int(year), int(month)
        except:
            return {'spotkania': 0, 'szkolenia': 0, 'nadgodziny': 0}

        month_key = (year, month)
        cell_key = (user_id, date_str)

        # Sprawdź cache ikon
        if month_key in self._icons_cache_by_month:
            month_icons_cache = self._icons_cache_by_month[month_key]
            if cell_key in month_icons_cache:
                return month_icons_cache[cell_key]

        # Oblicz ikony na podstawie aktywnych zdarzeń (jeśli nie ma w cache)
        # Ta metoda powinna korzystać z events_cache w odpowiednim kontenerze miesięcznym
        container = self.monthly_cache.get(month_key)
        events = []
        if container and container.events_cache:
            events = container.events_cache.get(cell_key, [])
        else:  # Fallback jeśli kontenera lub events_cache nie ma (nie powinno się zdarzyć przy poprawnym przepływie)
            events = self.get_events_for_user_date(user_id, date_str)

        active_events = [e for e in events if str(e.get('status', '1')) != '0']

        has_spotkania = any(e.get('type') == 'Spotkanie' for e in active_events)
        has_szkolenia = any(e.get('type') == 'Szkolenie' for e in active_events)
        has_nadgodziny = any(e.get('type') == 'Nadgodziny' for e in active_events)

        result = {
            'spotkania': 1 if has_spotkania else 0,
            'szkolenia': 1 if has_szkolenia else 0,
            'nadgodziny': 1 if has_nadgodziny else 0
        }

        # Zapisz w cache ikon
        if month_key not in self._icons_cache_by_month:
            self._icons_cache_by_month[month_key] = {}
        self._icons_cache_by_month[month_key][cell_key] = result

        return result

    def invalidate_specific_icons(self, user_date_pairs: List[Tuple[int, str]]):
        """
        Wyczyszczenie cache ikon dla konkretnych par użytkownik-data.
        Nie powinno już być potrzebne pełne czyszczenie cache miesiąca tutaj.
        """
        if not user_date_pairs:
            return

        affected_months = set()
        for user_id, date_str in user_date_pairs:
            try:
                year, month, _ = date_str.split('-')
                month_key = (int(year), int(month))
                affected_months.add(month_key)

                if month_key in self._icons_cache_by_month:
                    cell_key = (user_id, date_str)
                    if cell_key in self._icons_cache_by_month[month_key]:
                        del self._icons_cache_by_month[month_key][cell_key]

                # Zresetuj flagę obliczonych ikon dla kontenera, jeśli istnieje
                if month_key in self.monthly_cache:
                    self.monthly_cache[month_key]._icons_calculated_on_this_instance = False

            except ValueError:
                log_warning(f"Nieprawidłowy format daty w invalidate_specific_icons: {date_str}")
                continue

        for year, month in affected_months:
            debug_print(f"Invalidate specific icons: Zresetowano cache ikon dla komórek w {year}-{month}")
            self.data_changed.emit("icons", year, month)

    def invalidate_icons_cache(self, year: int, month: int):
        """
        Czyści *tylko* cache ikon dla danego miesiąca.
        Używane, gdy wiemy, że zdarzenia mogły się zmienić, ale dane grafiku nie.
        """
        month_key = (year, month)

        if month_key in self._icons_cache_by_month:
            del self._icons_cache_by_month[month_key]
            debug_print(f"DataProvider: Wyczyścił _icons_cache_by_month dla {year}-{month}")

        if month_key in self.monthly_cache:
            # Ważne: zresetuj flagę, aby ikony zostały przeliczone przy następnym żądaniu get_processed_data
            self.monthly_cache[month_key]._icons_calculated_on_this_instance = False
            debug_print(f"DataProvider: Zresetował flagę _icons_calculated_on_this_instance dla {year}-{month}")

            # Można też rozważyć odświeżenie events_data i events_cache w kontenerze, jeśli to konieczne
            # np. container = self.monthly_cache[month_key]
            # container.events_data = self._fetch_events_data(year, month)
            # container.events_cache = self._build_events_cache(container.events_data)
            # container.last_updated = time.time()

        self.data_changed.emit("icons", year, month)

    def get_forecast_data(self, year, month):
        """Pobiera dane prognozy dla danego miesiąca."""
        cache_key = (year, month)
        if cache_key in self.forecast_cache:
            debug_print(f"Używam cache dla prognozy dla {year}-{month}")
            return self.forecast_cache[cache_key]

        try:
            conn = self.db_connector.get_connection()
            cursor = conn.cursor()
            query = f"SELECT * FROM {SQL_OBJECTS['fn_getforecastdata']} (?, ?)"
            cursor.execute(query, (year, month))

            # Mapowanie na podstawie nazw kolumn zwróconych przez bazę
            columns = [column[0] for column in cursor.description]
            data = [dict(zip(columns, row)) for row in cursor.fetchall()]

            conn.close()
            debug_print(f"Pobrano {len(data)} wierszy prognozy dla {year}-{month}")
            self.forecast_cache[cache_key] = data
            return data
        except Exception as e:
            log_error(f"Błąd podczas pobierania danych prognozy: {e}", exception=e)
            return []

    def _get_or_load_monthly_data(self, year: int, month: int, grupa: int, funkcja: int, use_cache: bool = True) -> \
    Optional[MonthlyDataContainer]:
        self._current_year = year
        self._current_month = month

        # ZMIANA: Klucz cache jest teraz prosty - zależy tylko od roku i miesiąca.
        cache_key = (year, month)

        if use_cache and cache_key in self.monthly_cache:
            # Jeśli dane dla tego miesiąca są w cache, po prostu je zwróć.
            return self.monthly_cache[cache_key]

        debug_print(
            f"DataProvider: Tworzę nowy/nadpisuję kontener dla {year}-{month} (z filtrem grupa={grupa}, funkcja={funkcja})")

        try:
            # Parametry 'grupa' i 'funkcja' są używane TYLKO tutaj, do jednorazowego pobrania danych.
            schedule_data = self._fetch_schedule_data(year, month, grupa, funkcja)

            # Dane o zdarzeniach pobieramy zawsze w całości dla danego miesiąca.
            events_data = self._fetch_events_data(year, month)

            events_cache = self._build_events_cache(events_data)
            processed_data_base = self._build_processed_data_without_icons(schedule_data)

            container = MonthlyDataContainer(
                schedule_data=schedule_data,
                events_data=events_data,
                processed_data_base=processed_data_base,
                events_cache=events_cache,
                last_updated=time.time()
            )

            # Zapisz kontener pod prostym kluczem. Każde nowe ładowanie nadpisze stary.
            self.monthly_cache[cache_key] = container
            debug_print(f"DataProvider: Stworzono i zapisano w cache nowy kontener dla {year}-{month}.")
            return container

        except Exception as e:
            log_error(f"DataProvider: Błąd podczas ładowania danych dla {year}-{month}: {e}", exception=e)
            if cache_key in self.monthly_cache:
                del self.monthly_cache[cache_key]
            return None

    def get_schedule_data(self, year: int, month: int, grupa: int, funkcja: int, use_cache: bool = True) -> List[Any]:
        container = self._get_or_load_monthly_data(year, month, grupa, funkcja, use_cache)
        return container.schedule_data if container else []

    def get_events_data(self, year: int, month: int, grupa: int, funkcja: int, use_cache: bool = True) -> List[Dict]:
        """Pobiera dane zdarzeń, używając poprawnego kontekstu filtra do załadowania kontenera."""
        container = self._get_or_load_monthly_data(year, month, grupa, funkcja, use_cache)
        return container.events_data if container else []

    def get_processed_data(self, year: int, month: int, grupa: int, funkcja: int) -> Dict:
        """
        Zwraca processed_data z dynamicznie obliczonymi ikonami.
        """
        container = self._get_or_load_monthly_data(year, month, grupa, funkcja, use_cache=True)
        if not container:
            return {}

        # Sprawdź, czy ikony zostały już obliczone w tej sesji dla tego kontenera
        if not container._icons_calculated_on_this_instance:
            debug_print(f"DataProvider: Obliczam ikony dla {year}-{month} na żądanie w get_processed_data")

            # --- KLUCZOWA ZMIANA ---
            # Zawsze przekazuj do obliczeń aktualny events_cache z kontenera
            self._update_dynamic_icons(container.processed_data_base, container.events_cache)
            # --- KONIEC ZMIANY ---

            container._icons_calculated_on_this_instance = True

        return container.processed_data_base

    def get_department_to_group_mapping(self):
        """
        Zwraca słownik mapujący zagregowane grupy na zbiory wydziałów (WydzialGrafik).
        """
        # ZMIANA: Logika została przeniesiona do centralnego obiektu app_settings
        return app_settings.get_group_mapping()

    def refresh_data(self, year: int, month: int, grupa: int, funkcja: int):
        """
        Wymusza pełne odświeżenie danych dla miesiąca (np. po kliknięciu przycisku "Odśwież").
        """
        # ZMIANA 1: Klucz cache musi teraz uwzględniać grupę i funkcję
        cache_key = (year, month, grupa, funkcja)

        debug_print(f"DataProvider: Wymuszone odświeżenie danych dla {year}-{month} (grupa={grupa}, funkcja={funkcja})")

        if cache_key in self.monthly_cache:
            del self.monthly_cache[cache_key]
            debug_print(f"DataProvider: Usunięto stary kontener z monthly_cache dla klucza {cache_key}")

        # Klucz dla cache ikon jest niezależny od grupy/funkcji
        icons_cache_key = (year, month)
        if icons_cache_key in self._icons_cache_by_month:
            del self._icons_cache_by_month[icons_cache_key]
            debug_print(f"DataProvider: Usunięto _icons_cache_by_month dla {year}-{month}")

        # ZMIANA 2: Przekaż 'grupa' i 'funkcja' do wywołania poniżej
        container = self._get_or_load_monthly_data(year, month, grupa, funkcja, use_cache=False)

        if container:
            # Po świeżym załadowaniu, get_processed_data obliczy ikony, jeśli będzie to konieczne.
            self.data_changed.emit("schedule", year, month)
            self.data_changed.emit("events", year, month)
            self.data_changed.emit("icons", year, month)
        else:
            log_error(f"DataProvider: Nie udało się odświeżyć danych dla {year}-{month}")

    def _update_dynamic_icons(self, processed_data_target: Dict, events_cache: Dict):
        """
        Nakłada informacje o ikonach na dostarczony słownik `processed_data_target`.
        Modyfikuje `processed_data_target` w miejscu.
        Używa events_cache jako JEDYNEGO źródła informacji o zdarzeniach.
        """
        if not self._current_year or not self._current_month:
            log_error("DataProvider: _current_year lub _current_month nie jest ustawione w _update_dynamic_icons")
            return

        debug_print(
            f"DataProvider (POPRAWIONA WERSJA): Rozpoczynam _update_dynamic_icons dla {self._current_year}-{self._current_month}...")

        # Iterujemy po wszystkich użytkownikach i dniach w danych grafiku
        for key, user_data in processed_data_target.items():
            user_id = key[3]
            days_data = user_data.get('days', {})

            for day, day_data_dict in days_data.items():
                date_str = f"{self._current_year}-{self._current_month:02d}-{day:02d}"

                # Klucz do przeszukania pamięci podręcznej zdarzeń
                cache_key_event = (user_id, date_str)

                # Pobierz listę zdarzeń dla tej komórki z pamięci podręcznej
                events_for_cell = events_cache.get(cache_key_event, [])

                # Sprawdź, czy którekolwiek z tych zdarzeń są aktywne (status inny niż '0')
                active_events = [e for e in events_for_cell if str(e.get('status', '1')) != '0']

                # Ustaw flagi ikon na podstawie AKTYWNYCH zdarzeń
                has_spotkania = any(e.get('type') == 'Spotkanie' for e in active_events)
                has_szkolenia = any(e.get('type') == 'Szkolenie' for e in active_events)
                has_nadgodziny = any(e.get('type') == 'Nadgodziny' for e in active_events)

                # Zaktualizuj słownik dla dnia o informacje o ikonach
                day_data_dict['spotkania'] = 1 if has_spotkania else 0
                day_data_dict['szkolenia'] = 1 if has_szkolenia else 0
                day_data_dict['nadgodziny'] = 1 if has_nadgodziny else 0
                day_data_dict['events'] = active_events  # Zapisz listę aktywnych zdarzeń

        debug_print(f"DataProvider (POPRAWIONA WERSJA): Zakończono _update_dynamic_icons.")

    def get_performance_stats(self):
        """
        NOWA METODA: Zwraca statystyki wydajności
        """
        stats = {
            'monthly_cache_size': len(self.monthly_cache),
            'icons_cache_size': len(self._icons_cache_by_month),
            'total_memory_mb': 0  # Można dodać rzeczywiste pomiary pamięci
        }

        # Dodaj statystyki cache symboli
        try:
            # Zmieniono import na zgodny z plikiem symbol_parser.py
            from symbol_parser import get_cache_stats
            stats['symbol_cache'] = get_cache_stats()
        except ImportError:
            log_warning("Nie można zaimportować get_cache_stats z symbol_parser.py")
            stats['symbol_cache'] = "Niedostępne (ImportError)"
        except Exception as e:
            log_error(f"Błąd podczas pobierania statystyk cache symboli: {e}")
            stats['symbol_cache'] = f"Niedostępne ({type(e).__name__})"

        return stats

    def _build_processed_data_without_icons(self, schedule_data: List[Dict]) -> Dict:
        """
        Przetwarza dane z już spivotowanego zapytania SQL.
        WERSJA POPRAWIONA: Oblicza sumę godzin po stronie aplikacji, ignorując
        kolumny SumaRBH i BilansRBH z bazy danych.
        """
        if not self._current_year or not self._current_month or not schedule_data:
            return {}

        processed_data = {}
        for row_dict in schedule_data:
            uzytkownik_id = row_dict.get('Uzytkownik', 0)

            key = (
                row_dict.get('WydzialGrafik', ''),
                row_dict.get('PrzelozonyDane', ''),
                row_dict.get('UzytkownikDane', ''),
                uzytkownik_id
            )

            # Inicjalizujemy słownik z danymi pracownika, bez sumy godzin
            processed_data[key] = {
                'days': {},
                'total_hours': 0,  # Inicjalizujemy sumę jako 0
                'rola_nazwa': row_dict.get('RolaNazwa', ''),
                'pod_rola_nazwa': row_dict.get('PodRolaNazwa', ''),
                'etat': row_dict.get('Etat', 8.0),
                'jezyk': row_dict.get('Język', ''),
                'korekta': row_dict.get('Korekta', 0),
                'dtn': row_dict.get('DTN', 0),
                'przelozony_imie_nazwisko': row_dict.get('PrzelozonyImieNazwisko', ''),
                'nr_kadrowy': row_dict.get('NumerKadrowy', ''),
                'lokalizacja_domyslna': row_dict.get('LokalizacjaDomyslna', 'h'),
                'komentarz_grafik': row_dict.get('KomentarzGrafik', ''),
                'system_czasu_pracy': row_dict.get('SystemCzasuPracy', '')
            }

            # --- NOWA LOGIKA: Obliczanie sumy godzin po stronie aplikacji ---
            calculated_total_hours = 0
            for day in range(1, 32):
                symbol = row_dict.get(str(day))
                if symbol is not None:
                    parsed_symbol = parse_symbol(symbol)

                    # Używamy `or 0`, aby obsłużyć None zwracane przez parser
                    work_h = parsed_symbol.get('work_hours', 0) or 0
                    calculated_total_hours += work_h

                    # Zapisujemy dane dnia do słownika
                    processed_data[key]['days'][day] = {
                        'symbol': symbol,
                        'hours': work_h,
                        'start_hour': parsed_symbol.get('start_hour'),
                    }

            # Po przejściu przez wszystkie dni, przypisujemy obliczoną sumę
            processed_data[key]['total_hours'] = calculated_total_hours
            # --- KONIEC NOWEJ LOGIKI ---

        debug_print(
            f"DataProvider: Zakończono budowanie danych dla {len(processed_data)} użytkowników z sumą godzin obliczoną w aplikacji.")
        return processed_data

    @lru_cache(maxsize=100)  # Cache dla kluczy miesięcy
    def _get_month_cache_key(self, year: int, month: int) -> tuple:
        """Cache key dla miesiąca"""
        return (year, month)

    def clear_symbol_cache(self):
        """
        Czyści cache symboli, jeśli jest taka potrzeba.
        """
        try:
            from symbol_parser import clear_cache as clear_symbol_parser_cache, \
                get_cache_stats  # Zmieniono nazwę importu

            cache_stats = get_cache_stats()  # Użyj nowej nazwy funkcji
            debug_print(f"DataProvider: Cache symboli przed czyszczeniem: {cache_stats}")

            # Dostosuj warunki czyszczenia cache, jeśli potrzebne
            # Np. jeśli parse_cache_size jest większe niż pewien próg
            if cache_stats.get('parse_cache_size', 0) > 1500:
                clear_symbol_parser_cache()  # Użyj nowej nazwy funkcji
                debug_print("DataProvider: Wyczyszczono cache symboli (był za duży)")

        except ImportError:
            log_warning("DataProvider: Nie można zaimportować funkcji z symbol_parser.py do zarządzania cache.")
        except Exception as e:
            log_error(f"DataProvider: Błąd czyszczenia cache symboli: {e}")

    def get_events_for_user_date(self, user_id: int, date_str: str) -> List[Dict]:
        """
        Zwraca listę *aktywnych* zdarzeń dla danego użytkownika i daty.
        """
        if not date_str or not user_id or date_str.count('-') != 2:
            return []

        try:
            year, month, _ = date_str.split('-')
            year, month = int(year), int(month)
        except (ValueError, TypeError):
            return []

        # Używamy prostego klucza, aby znaleźć kontener w pamięci podręcznej.
        cache_key = (year, month)
        container = self.monthly_cache.get(cache_key)

        if not container:
            log_warning(f"DataProvider: Brak kontenera w cache dla klucza {cache_key} w get_events_for_user_date.")
            return []

        standardized_date = self._standardize_date(date_str)
        cache_key_event = (user_id, standardized_date)

        events_for_cell = container.events_cache.get(cache_key_event, [])
        active_events = [e for e in events_for_cell if str(e.get('status', '1')) != '0']

        return active_events

    def _fetch_schedule_data(self, year: int, month: int, grupa: int, funkcja: int) -> List[Dict]:
        """Pobiera dane grafiku z bazy z dodatkowymi parametrami."""
        query = f"SELECT * FROM {SQL_OBJECTS['fn_getscheduledata']}(?, ?, ?, ?)"  # ZAPYTANIE Z 4 PARAMETRAMI
        conn = self.db_connector.get_connection()
        cursor = conn.cursor()
        cursor.execute(query, (year, month, grupa, funkcja))  # PRZEKAZANIE PARAMETRÓW

        # Pobierz nazwy kolumn z kursora
        columns = [column[0] for column in cursor.description]

        # Zmapuj każdy wiersz na słownik
        schedule_data = [dict(zip(columns, row)) for row in cursor.fetchall()]

        conn.close()
        debug_print(f"DataProvider: Pobrane dane grafiku (nowy format): {len(schedule_data)} wierszy.")
        return schedule_data

    def _fetch_events_data(self, year: int, month: int) -> List[Dict]:
        """Pobiera wszystkie zdarzenia miesiąca"""
        query = f"""
        SELECT * FROM {SQL_OBJECTS['fn_geteventsdata']}(?, ?) 
        """
        conn = self.db_connector.get_connection()
        cursor = conn.cursor()
        debug_print(f"DataProvider: Wykonuję SQL fn_GetEventsData dla {year}-{month}")

        sql_exec_start_time = time.time()
        cursor.execute(query, (year, month))
        sql_exec_end_time = time.time()
        debug_print(f"DataProvider: SQL fn_GetEventsData wykonane w {sql_exec_end_time - sql_exec_start_time:.4f}s")

        fetchall_start_time = time.time()
        raw_events = cursor.fetchall()
        fetchall_end_time = time.time()
        debug_print(
            f"DataProvider: cursor.fetchall() dla raw_events zajęło {fetchall_end_time - fetchall_start_time:.4f}s dla {len(raw_events)} wierszy.")

        conn.close()
        debug_print(
            f"DataProvider: Pobrane surowe zdarzenia: {len(raw_events)} wierszy (całkowity czas fetch: {fetchall_end_time - sql_exec_start_time:.4f}s).")

        events_dicts = []
        mapping_start_time = time.time()
        for row_idx, row_data in enumerate(raw_events):
            try:
                event = self.column_mapper.map_events_row_to_dict(row_data)

                if 'event_type' in event: event['type'] = event['event_type']
                if 'event_id' in event: event['id'] = event['event_id']

                raw_date = event.get('date', '')
                if hasattr(raw_date, 'strftime'):
                    event['date_display'] = raw_date.strftime('%d.%m.%Y')
                    event['date_key'] = raw_date.strftime('%Y-%m-%d')
                elif isinstance(raw_date, str) and raw_date:
                    event['date_display'] = self._format_date_display(raw_date)
                    event['date_key'] = self._standardize_date(raw_date)

                for time_key in ['time_from', 'time_to']:
                    time_val = event.get(time_key)
                    if hasattr(time_val, 'strftime'):
                        event[time_key] = time_val.strftime('%H:%M')
                    elif isinstance(time_val, str):
                        if 'T' in time_val:
                            event[time_key] = time_val.split('T')[1][:5]
                        elif ' ' in time_val and ':' in time_val:
                            event[time_key] = time_val.split(' ')[1][:5]

                if event.get('type') and event.get('id') is not None:
                    events_dicts.append(event)
                else:
                    log_warning(
                        f"DataProvider: Pominięto zdarzenie z brakiem typu lub ID: {event} (wiersz {row_idx})")
            except Exception as e:
                log_error(
                    f"DataProvider: Błąd mapowania wiersza zdarzenia w _fetch_events_data: {e}, wiersz: {row_data} (indeks: {row_idx})")
                continue
        mapping_end_time = time.time()
        debug_print(
            f"DataProvider: Mapowanie {len(raw_events)} zdarzeń zajęło {mapping_end_time - mapping_start_time:.4f}s.")
        debug_print(f"DataProvider: Przetworzone zdarzenia: {len(events_dicts)} słowników.")
        return events_dicts

    def _build_events_cache(self, events_data: List[Dict]) -> Dict[Tuple[int, str], List[Dict]]:
        """Buduje cache zdarzeń (user_id, date_key) -> [list_of_events]"""
        events_cache = {}
        for event in events_data:
            user_id = event.get('user_id')
            date_key = self._standardize_date(event.get('date_key', ''))  # Użyj znormalizowanej daty

            if user_id and date_key:
                cache_key_event = (user_id, date_key)  # Poprawiono nazwę zmiennej
                if cache_key_event not in events_cache:
                    events_cache[cache_key_event] = []
                events_cache[cache_key_event].append(event)
        debug_print(f"DataProvider: Zbudowano events_cache z {len(events_cache)} wpisami.")
        return events_cache

    def clear_cache(self):
        """
        Czyści cały cache danych miesięcznych i ikon.
        Wywoływane przy starcie aplikacji lub gdy jest to absolutnie konieczne.
        """
        cache_count = len(self.monthly_cache)
        icons_count = len(self._icons_cache_by_month)

        self.monthly_cache.clear()
        self._icons_cache_by_month.clear()

        debug_print(
            f"DataProvider: Wyczyszczono CAŁY cache: {cache_count} kontenerów, {icons_count} wpisów cache ikon")

    def on_month_change(self, new_year: int, new_month: int):
        """
        Wywoływane przy zmianie miesiąca w interfejsie.
        Czyści cache dla *innych* miesięcy, aby oszczędzać pamięć.
        """
        debug_print(f"DataProvider: ZMIANA MIESIĄCA na {new_year}-{new_month}")

        current_key_tuple = (new_year, new_month)  # Poprawiono nazwę zmiennej

        # Stwórz listę kluczy do usunięcia, aby uniknąć modyfikacji słownika podczas iteracji
        keys_to_remove_monthly = [k for k in self.monthly_cache if k != current_key_tuple]
        keys_to_remove_icons = [k for k in self._icons_cache_by_month if k != current_key_tuple]

        for key in keys_to_remove_monthly:
            del self.monthly_cache[key]
        for key in keys_to_remove_icons:
            del self._icons_cache_by_month[key]

        if keys_to_remove_monthly or keys_to_remove_icons:
            debug_print(
                f"DataProvider: Wyczyszczono cache dla poprzednich miesięcy, pozostawiono dla {new_year}-{new_month} (jeśli istniał).")
        else:
            debug_print(f"DataProvider: Cache był pusty lub zawierał tylko dane dla {new_year}-{new_month}.")

        # Ustaw aktualny miesiąc/rok dla _build_processed_data_without_icons
        self._current_year = new_year
        self._current_month = new_month

    def _format_date_display(self, date_str: str) -> str:
        """Formatuje datę z YYYY-MM-DD na DD.MM.YYYY"""
        if not date_str: return ""
        try:
            if isinstance(date_str, str) and '-' in date_str and len(date_str.split('-')) == 3:
                year, month, day_part = date_str.split('-')
                day = day_part.split(' ')[0].split('T')[0]  # Dodatkowe czyszczenie dla formatów z czasem
                return f"{day}.{month}.{year}"
        except Exception as e:
            log_warning(f"DataProvider: Błąd formatowania daty '{date_str}': {e}")
        return date_str  # Zwróć oryginał w razie problemu

    def _standardize_date(self, date_obj) -> str:
        """Standaryzuje format daty do 'YYYY-MM-DD'"""
        if not date_obj: return ''
        if isinstance(date_obj, str):
            date_part = date_obj.split(' ')[0].split('T')[0]  # Weź część daty przed czasem
            if len(date_part) == 10:
                if date_part.count('-') == 2:  # Format YYYY-MM-DD
                    try:  # Sprawdź czy to poprawna data
                        datetime.strptime(date_part, '%Y-%m-%d')
                        return date_part
                    except ValueError:
                        pass
                elif date_part.count('.') == 2:  # Format DD.MM.YYYY
                    try:
                        d, m, y = date_part.split('.')
                        if len(y) == 4 and len(m) == 2 and len(d) == 2:
                            datetime.strptime(date_part, '%d.%m.%Y')  # Sprawdź poprawność
                            return f"{y}-{m}-{d}"
                    except ValueError:
                        pass
            # Jeśli nie udało się sparsować, zaloguj i zwróć pusty string lub oryginalną wartość
            log_warning(f"DataProvider: Nie udało się znormalizować daty: '{date_obj}'")
            return date_obj  # Lub '' jeśli preferowane jest czyszczenie niepoprawnych dat

        if hasattr(date_obj, 'strftime'):  # Dla obiektów date/datetime
            return date_obj.strftime('%Y-%m-%d')

        log_warning(f"DataProvider: Nieznany typ daty do standaryzacji: {type(date_obj)}, wartość: {date_obj}")
        return ''

    def invalidate_complete_cache_for_pairs(self, user_date_pairs: List[Tuple[int, str]]):
        """
        Kompleksowe unieważnienie cache dla określonych par (user_id, date_str).
        Wymusza ponowne załadowanie danych o zdarzeniach dla dotkniętych miesięcy.
        """
        if not user_date_pairs:
            return

        affected_months_to_refresh_events = set()
        affected_months_for_icons_signal = set()

        for user_id, date_str in user_date_pairs:
            try:
                std_date_str = self._standardize_date(date_str)
                if not std_date_str or std_date_str.count('-') != 2:
                    log_warning(
                        f"DataProvider: Nieprawidłowy format daty w invalidate_complete_cache_for_pairs: '{date_str}'")
                    continue

                year, month, day = map(int, std_date_str.split('-'))
                month_key = (year, month)

                affected_months_to_refresh_events.add(
                    month_key)  # Zawsze oznaczamy miesiąc do odświeżenia danych zdarzeń
                affected_months_for_icons_signal.add(month_key)

                # Unieważnij cache ikon dla konkretnej komórki
                if month_key in self._icons_cache_by_month:
                    cell_key = (user_id, std_date_str)
                    if cell_key in self._icons_cache_by_month[month_key]:
                        del self._icons_cache_by_month[month_key][cell_key]
                        # debug_print(f"DataProvider: Usunięto z _icons_cache_by_month dla {cell_key}")

                # Zresetuj flagę obliczonych ikon dla kontenera
                if month_key in self.monthly_cache:
                    self.monthly_cache[month_key]._icons_calculated_on_this_instance = False
                    # debug_print(f"DataProvider: Zresetowano _icons_calculated_on_this_instance dla {month_key}")

            except (ValueError, TypeError) as e:
                log_warning(
                    f"DataProvider: Błąd w invalidate_complete_cache_for_pairs przy przetwarzaniu ({user_id}, {date_str}): {e}")
                continue

        # Kluczowa zmiana: Ponownie załaduj dane o zdarzeniach dla wszystkich dotkniętych miesięcy
        for year, month in affected_months_to_refresh_events:
            month_key_tuple = (year, month)
            if month_key_tuple in self.monthly_cache:
                debug_print(
                    f"DataProvider: Wymuszone ponowne ładowanie events_data dla kontenera {year}-{month} w invalidate_complete_cache_for_pairs.")
                container = self.monthly_cache[month_key_tuple]

                # Pobierz świeże dane o zdarzeniach z bazy
                fresh_events_data = self._fetch_events_data(year, month)
                container.events_data = fresh_events_data

                # Przebuduj cache zdarzeń na podstawie świeżych danych
                container.events_cache = self._build_events_cache(fresh_events_data)

                container.last_updated = time.time()
                container._icons_calculated_on_this_instance = False  # Ikony również będą wymagały ponownego przeliczenia

                debug_print(
                    f"DataProvider: Zakończono odświeżanie events_data i events_cache dla {year}-{month}. Nowych zdarzeń: {len(fresh_events_data)}")
                self.data_changed.emit("events", year, month)  # Sygnalizuj zmianę danych zdarzeń
            else:
                # Jeśli kontenera nie ma w cache, zostanie załadowany przy następnym żądaniu
                debug_print(
                    f"DataProvider: Kontener dla {year}-{month} nie istnieje w cache, zostanie załadowany przy potrzebie.")

        for year, month in affected_months_for_icons_signal:
            debug_print(
                f"DataProvider: Sygnalizowanie zmiany ikon dla miesiąca {year}-{month} po invalidate_complete_cache_for_pairs.")
            self.data_changed.emit("icons", year, month)
