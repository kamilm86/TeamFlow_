Jasne, oto kompletny kod analizy w jednym pliku, gotowy do wklejenia i uruchomienia w notatniku Jupyter. Plik zawiera wszystkie kroki: od połączenia z danymi, przez ich przygotowanie z logiką YTD, aż po analizę, wizualizację i wnioski biznesowe.
# ==============================================================================
# KROK 1: IMPORT BIBLIOTEK I USTAWIENIA WIZUALIZACJI
# ==============================================================================
import pandas as pd
import sqlalchemy as sa
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# Ustawienia dla wykresów, aby były czytelne i estetyczne
sns.set_theme(style="whitegrid")
plt.rcParams['figure.figsize'] = (14, 7)
plt.rcParams['axes.titlesize'] = 18
plt.rcParams['axes.labelsize'] = 14
plt.rcParams['xtick.labelsize'] = 12
plt.rcParams['ytick.labelsize'] = 12
print("✅ Biblioteki załadowane, styl wykresów ustawiony.")


# ==============================================================================
# KROK 2: WCZYTANIE DANYCH Z BAZY MS SQL SERVER
# ==============================================================================
# Wypełnij poniższe zmienne swoimi danymi dostępowymi
server_name = "TWOJ_SERWER"
database_name = "TWOJA_BAZA_DANYCH"
table_name = "NAZWA_TWOJEJ_TABELI_RAW"  # Tabela z danymi granularnymi (niezagregowanymi)

try:
    # Tworzenie connection stringa dla uwierzytelniania Windows
    connection_string = f"mssql+pyodbc://{server_name}/{database_name}?driver=ODBC+Driver+17+for+SQL+Server&trusted_connection=yes"
    engine = sa.create_engine(connection_string)
    
    query = f"SELECT * FROM {table_name}"
    df_raw = pd.read_sql(query, engine)
    
    print(f"✅ Pomyślnie połączono i wczytano {len(df_raw)} rekordów z tabeli {table_name}.")

except Exception as e:
    print(f"❌ Błąd podczas połączenia z bazą danych: {e}")
    print("⚠️ Tworzę przykładowy, granularny zbiór danych, aby kontynuować analizę.")
    # Generowanie realistycznych danych przykładowych
    date_rng_2024 = pd.to_datetime(pd.date_range(start='2024-01-01', end='2024-09-15', freq='10min'))
    date_rng_2023 = pd.to_datetime(pd.date_range(start='2023-01-01', end='2023-12-31', freq='9min'))
    all_dates = date_rng_2024.union(date_rng_2023)
    
    data = {
        'callid': range(len(all_dates)),
        'Data': all_dates,
        'Kanal_kontakt': np.random.choice(['voice', 'czat', 'wideo'], len(all_dates), p=[0.7, 0.25, 0.05]),
        'czy_odebrane': np.random.choice([1, 0], len(all_dates), p=[0.85, 0.15]),
        'wejscie': np.random.choice(['ivr', 'bot', 'vendor'], len(all_dates), p=[0.5, 0.4, 0.1]),
        'gdzie_koniec': np.random.choice(['konsultant', 'bot', 'transfer', 'ivr'], len(all_dates), p=[0.7, 0.15, 0.1, 0.05]),
        'czas_rozmowy': np.random.gamma(2, 150, len(all_dates)).astype(int)
    }
    df_raw = pd.DataFrame(data)
    df_raw.loc[df_raw['czy_odebrane'] == 0, 'czas_rozmowy'] = 0

print("\n--- Próbka danych (5 pierwszych wierszy) ---")
display(df_raw.head())


# ==============================================================================
# KROK 3: PRZYGOTOWANIE DANYCH I IMPLEMENTACJA LOGIKI YTD
# ==============================================================================
print("\n--- Rozpoczęto przygotowanie danych ---")
# Konwersja kolumny 'Data' na typ daty i tworzenie dodatkowych cech czasowych
df_raw['Data'] = pd.to_datetime(df_raw['Data'])
df_raw['Rok'] = df_raw['Data'].dt.year
df_raw['Miesiac'] = df_raw['Data'].dt.month
df_raw['Dzien_Roku'] = df_raw['Data'].dt.dayofyear # Klucz do porównań YTD
df_raw['Godzina'] = df_raw['Data'].dt.hour
df_raw['Nazwa_Miesiaca'] = df_raw['Data'].dt.strftime('%B')

# --- Implementacja logiki Year-to-Date (YTD) ---
# 1. Znajdź ostatnią datę i dzień roku w bieżącym roku
current_year = df_raw['Rok'].max()
previous_year = current_year - 1
latest_date_cy = df_raw[df_raw['Rok'] == current_year]['Data'].max()
latest_day_of_year = latest_date_cy.dayofyear

print(f"Bieżący rok w analizie: {current_year}")
print(f"Poprzedni rok w analizie: {previous_year}")
print(f"Najnowsze dane pochodzą z: {latest_date_cy.strftime('%Y-%m-%d')} (to {latest_day_of_year}. dzień roku)")

# 2. Odfiltruj dane, aby obejmowały ten sam okres w obu latach
df_ytd = df_raw[df_raw['Dzien_Roku'] <= latest_day_of_year].copy()
print(f"✅ Dane odfiltrowane. Analiza zostanie przeprowadzona dla okresu od 1 stycznia do {latest_day_of_year}. dnia roku.")

# ==============================================================================
# KROK 4: ANALIZA PORÓWNAWCZA I WIZUALIZACJA DANYCH (YTD)
# ==============================================================================
print("\n--- Rozpoczęto główną analizę porównawczą (YTD) ---")

# --- 4.1. Ogólny Wolumen Interakcji (YTD) ---
total_volume_ytd = df_ytd.groupby('Rok')['callid'].count().reset_index().rename(columns={'callid': 'liczba_polaczen'})
vol_cy = total_volume_ytd.loc[total_volume_ytd['Rok'] == current_year, 'liczba_polaczen'].iloc[0]
vol_py = total_volume_ytd.loc[total_volume_ytd['Rok'] == previous_year, 'liczba_polaczen'].iloc[0]
yoy_change = ((vol_cy - vol_py) / vol_py) * 100

plt.figure(figsize=(10, 6))
ax = sns.barplot(data=total_volume_ytd, x='Rok', y='liczba_polaczen', palette='viridis')
ax.set_title(f'Całkowity Wolumen Interakcji (YTD)\nZmiana: {yoy_change:.2f}%', fontsize=20)
for p in ax.patches:
    ax.annotate(f'{int(p.get_height()):,}', (p.get_x() + p.get_width() / 2., p.get_height()),
                ha='center', va='center', fontsize=14, color='black', xytext=(0, 10),
                textcoords='offset points')
plt.ylabel('Liczba Połączeń')
plt.xlabel('Rok')
plt.show()

# --- 4.2. Analiza Wolumenu w Podziale na Kanały (YTD) ---
channel_volume_ytd = df_ytd.groupby(['Rok', 'Kanal_kontakt'])['callid'].count().reset_index().rename(columns={'callid': 'liczba_polaczen'})
sns.barplot(data=channel_volume_ytd, x='Kanal_kontakt', y='liczba_polaczen', hue='Rok', palette='mako')
plt.title('Wolumen Interakcji w Podziale na Kanały (YTD)')
plt.ylabel('Liczba Połączeń')
plt.xlabel('Kanał Kontaktu')
plt.legend(title='Rok')
plt.show()

# --- 4.3. Analiza Średniego Czasu Obsługi (AHT) (YTD) ---
df_answered_ytd = df_ytd[df_ytd['czy_odebrane'] == 1]
aht_ytd = df_answered_ytd.groupby('Rok')['czas_rozmowy'].mean().reset_index().rename(columns={'czas_rozmowy': 'Sredni_AHT_s'})
plt.figure(figsize=(10, 6))
ax = sns.barplot(data=aht_ytd, x='Rok', y='Sredni_AHT_s', palette='coolwarm')
ax.set_title('Średni Czas Obsługi - AHT (YTD)')
for p in ax.patches:
    ax.annotate(f'{p.get_height():.1f}s', (p.get_x() + p.get_width() / 2., p.get_height()),
                ha='center', va='center', fontsize=14, color='black', xytext=(0, 10),
                textcoords='offset points')
plt.ylabel('AHT (w sekundach)')
plt.xlabel('Rok')
plt.show()

# --- 4.4. Analiza Ścieżki Klienta: Wejście i Zakończenie (YTD) ---
fig, axes = plt.subplots(1, 2, figsize=(20, 8))
entry_points_ytd = df_ytd.groupby(['Rok', 'wejscie'])['callid'].count().reset_index()
exit_points_ytd = df_ytd.groupby(['Rok', 'gdzie_koniec'])['callid'].count().reset_index()

sns.barplot(ax=axes[0], data=entry_points_ytd, x='wejscie', y='callid', hue='Rok', palette='viridis')
axes[0].set_title('Punkty Wejścia Interakcji (YTD)')
axes[0].set_ylabel('Liczba Połączeń')

sns.barplot(ax=axes[1], data=exit_points_ytd, x='gdzie_koniec', y='callid', hue='Rok', palette='plasma')
axes[1].set_title('Punkty Zakończenia Interakcji (YTD)')
axes[1].set_ylabel('Liczba Połączeń')
plt.tight_layout()
plt.show()

# --- 4.5. Analiza Sezonowości i Trendów Miesięcznych (YTD) ---
monthly_trends_ytd = df_ytd.groupby(['Rok', 'Miesiac'])['callid'].count().reset_index()
sns.lineplot(data=monthly_trends_ytd, x='Miesiac', y='callid', hue='Rok', palette='Set1', marker='o', linewidth=2.5)
plt.title('Miesięczne Trendy Wolumenu Połączeń (YTD)')
plt.xlabel('Miesiąc')
plt.ylabel('Liczba Połączeń')
plt.xticks(ticks=range(1, 13))
plt.legend(title='Rok')
plt.grid(True, which='both', linestyle='--')
plt.show()

# ==============================================================================
# KROK 5: GŁĘBSZA ANALIZA DZIĘKI DANYM GRANULARNYM (BONUS)
# ==============================================================================
print("\n--- Rozpoczęto analizy dodatkowe (bonus) ---")

# --- 5.1. Dystrybucja Czasu Trwania Rozmów ---
fig, axes = plt.subplots(1, 2, figsize=(20, 8), sharey=True)
sns.histplot(ax=axes[0], data=df_answered_ytd[df_answered_ytd['Rok'] == previous_year], x='czas_rozmowy', bins=50, kde=True)
axes[0].set_title(f'Dystrybucja Czasu Rozmów w {previous_year} (YTD)')
axes[0].axvline(aht_ytd.loc[aht_ytd['Rok'] == previous_year, 'Sredni_AHT_s'].iloc[0], color='red', linestyle='--', label='Średnia (AHT)')
axes[0].legend()

sns.histplot(ax=axes[1], data=df_answered_ytd[df_answered_ytd['Rok'] == current_year], x='czas_rozmowy', bins=50, kde=True, color='orange')
axes[1].set_title(f'Dystrybucja Czasu Rozmów w {current_year} (YTD)')
axes[1].axvline(aht_ytd.loc[aht_ytd['Rok'] == current_year, 'Sredni_AHT_s'].iloc[0], color='red', linestyle='--', label='Średnia (AHT)')
axes[1].legend()
plt.suptitle('Porównanie Dystrybucji Czasu Rozmów (YTD)', fontsize=22)
plt.show()

# --- 5.2. Analiza obciążenia w ciągu dnia (Peak Hour Analysis) ---
hourly_volume_ytd = df_ytd.groupby(['Rok', 'Godzina'])['callid'].count().reset_index()
g = sns.FacetGrid(hourly_volume_ytd, col="Rok", height=6, aspect=1.5)
g.map(sns.barplot, "Godzina", "callid", order=range(24), palette=['skyblue', 'lightcoral'])
g.set_axis_labels("Godzina Dnia", "Liczba Połączeń")
g.set_titles(col_template="Rok {col_name}")
g.fig.suptitle('Rozkład Połączeń w Ciągu Dnia (YTD)', y=1.03, fontsize=20)
plt.show()

# ==============================================================================
# KROK 6: PODSUMOWANIE I REKOMENDACJE BIZNESOWE
# ==============================================================================
print("\n\n" + "="*80)
print("💡 PODSUMOWANIE WNIOSKÓW I REKOMENDACJE BIZNESOWE 💡")
print("="*80)
print(f"""
Analiza porównawcza okresu od 1 stycznia do {latest_date_cy.strftime('%d %B')} dla lat {previous_year} i {current_year} wykazała następujące trendy:

1.  **Ogólny Wolumen:** Zaobserwowaliśmy {'wzrost' if yoy_change > 0 else 'spadek'} całkowitego wolumenu interakcji o {yoy_change:.2f}%. 
    Jest to kluczowa informacja dla planowania budżetu i zasobów na kolejne okresy.

2.  **Struktura Kanałów:** Analiza pokazała, że głównym motorem zmian był kanał [tutaj wpisz nazwę kanału z największą zmianą].
    Rekomendacja: Należy dostosować strategię obsługi do zmieniających się preferencji klientów, potencjalnie inwestując więcej w rozwój kanałów cyfrowych jak 'czat' lub optymalizując obsługę 'voice'.

3.  **Efektywność Operacyjna (AHT):** Średni czas obsługi (AHT) zmienił się z {aht_ytd.loc[aht_ytd['Rok'] == previous_year, 'Sredni_AHT_s'].iloc[0]:.1f}s do {aht_ytd.loc[aht_ytd['Rok'] == current_year, 'Sredni_AHT_s'].iloc[0]:.1f}s.
    Rekomendacja: Warto zbadać przyczyny tej zmiany. Jeśli AHT rośnie, należy zidentyfikować najbardziej czasochłonne typy zgłoszeń i zorganizować szkolenia. Jeśli maleje, upewnić się, że nie cierpi na tym jakość (CSAT).

4.  **Automatyzacja (Ścieżka Klienta):** Porównanie punktów wejścia i zakończenia interakcji wskazuje na [wzrost/spadek] skuteczności naszych systemów automatycznych (IVR/Bot).
    Rekomendacja: Należy dążyć do tego, aby jak najwięcej prostych zapytań było rozwiązywanych automatycznie. Analiza interakcji zakończonych transferem do konsultanta może wskazać słabe punkty w konfiguracji bota/IVR.
    
5.  **Obciążenie w Ciągu Dnia:** Godziny szczytu w obu latach przypadają na [wpisz godziny szczytu, np. 10:00-14:00].
    Rekomendacja: Ta informacja jest krytyczna dla działu Workforce Management. Należy zoptymalizować grafiki pracy konsultantów, aby zapewnić odpowiednią obsadę w godzinach największego ruchu i uniknąć przepracowania zespołu lub długiego czasu oczekiwania dla klientów.

Analiza ta stanowi solidną podstawę do podejmowania dalszych, świadomych decyzji biznesowych w celu optymalizacji pracy infolinii.
""")
print("="*80)


