Rozumiem. Ostatecznym rozwiÄ…zaniem, ktÃ³re naprawi bÅ‚Ä…d Cannot interpret 'VARCHAR(length=19)' i pozwoli Twojemu procesowi ETL dziaÅ‚aÄ‡, jest rozdzielenie logiki typÃ³w w metodzie insert_data. Musisz uÅ¼yÄ‡ typÃ³w Pandasa/NumPy w df.astype() i obiektÃ³w typÃ³w SQLAlchemy do tworzenia tabeli.
PoniÅ¼ej przedstawiam peÅ‚ny kod funkcji insert_data z uwzglÄ™dnieniem tej krytycznej poprawki (wokÃ³Å‚ linii 1153) i logikÄ… lookup_keys.
Ze wzglÄ™du na brak peÅ‚nej definicji, zaÅ‚oÅ¼yÅ‚em istnienie wewnÄ™trznych mapowaÅ„ typÃ³w Pandas/NumPy w sÅ‚owniku self.type_mappings.
ğŸ› ï¸ Poprawiona funkcja insert_data (Z podziaÅ‚em typÃ³w i Lookup)
import pandas as pd
import numpy as np
import gc
from typing import List, Optional

# --- Klasa DatabaseManager (fragment) ---

def insert_data(self, df: pd.DataFrame, target_db: str, table_name: str, 
                schema: str, if_exists: str = 'append', batch_size: int = 1000000, 
                verbose: bool = True, use_fast_executemany: bool = True, 
                lookup_keys: Optional[List[str]] = None) -> None:
    
    self.logger.info(f"Rozpoczynanie wstawiania do {target_db}.{schema}.{table_name} (Liczba wierszy: {len(df)})")

    engine = self._get_engine(target_db) 
    
    try:
        with engine.connect() as connection:
            self.logger.info("PomyÅ›lnie utworzone poÅ‚Ä…czenie z bazÄ… docelowÄ….")
            
            # Ustawienia transakcyjne (jak widaÄ‡ na Twoim zdjÄ™ciu)
            if target_db == 'SQLServer':
                connection.execute("SET LOCK_TIMEOUT 1200000")
                connection.execute("SET TEXTSIZE 66000000")
                connection.execute("SET TRANSACTION ISOLATION LEVEL READ COMMITTED")
                connection.execute("SET XACT_ABORT ON") 

            # # 1. Czyszczenie i transformacje DataFrame
            df_to_load = df.copy() 

            df_to_load = self.standardize_column_names(df_to_load) 
            df_to_load = self.handle_nulls(df_to_load)
            df_to_load = df_to_load.astype(str).replace({pd.NaT: None, 'nan': None}) 
            
            # ğŸ’¥ KRYTYCZNA POPRAWKA: Rozdzielenie sÅ‚ownikÃ³w typÃ³w
            
            # SÅ‚ownik 1: Typy SQL Alchemy dla CREATE TABLE
            # Ta funkcja zwraca obiekty CLOB, VARCHAR(length=...), ktÃ³re sÄ… NIEZGODNE z df.astype()
            sqlalchemy_dtype_dict = self.map_data_types(df_to_load, target_db) 
            
            # SÅ‚ownik 2: Typy Pandasa/NumPy dla df.astype()
            # Musimy uÅ¼yÄ‡ typÃ³w, ktÃ³re rozumie Pandas (np. 'int64', 'str', 'float64')
            numpy_dtype_dict = {}
            # Pobieramy bazowe mapowanie typÃ³w Pandas/NumPy z Twojej klasy (Linia 334)
            numpy_type_mappings = self.type_mappings.get(target_db) 
            
            for col_name in df_to_load.columns:
                # W Pandas, jeÅ›li kolumna jest typu 'object', to zazwyczaj jest to ciÄ…g lub data/czas
                dtype = df_to_load[col_name].dtype.name
                
                # UÅ¼ywamy mapowania z type_mappings (Linia 334)
                if dtype in numpy_type_mappings:
                    numpy_dtype_dict[col_name] = numpy_type_mappings[dtype]
                elif 'datetime' in dtype:
                     numpy_dtype_dict[col_name] = 'datetime64[ns]'
                else:
                    # Dla bezpieczeÅ„stwa, resztÄ™ stringÃ³w mapujemy na 'str' (co jest aliasem do 'object')
                    numpy_dtype_dict[col_name] = 'str' 
            
            self.logger.info(f"Wykonanie df_to_load.astype(numpy_dtype_dict)") 
            # ğŸ’¥ UÅ¼ywamy sÅ‚ownika typÃ³w Pandasa/NumPy (np. {'KOL1': 'int64', 'KOL2': 'str'})
            df_to_load = df_to_load.astype(numpy_dtype_dict) 
            self.logger.info(f"df_to_load.astype(numpy_dtype_dict) - done") 
            
            # 2. ZarzÄ…dzanie schematem i tabelÄ… (uÅ¼ywamy typÃ³w SQL Alchemy!)
            
            # UÅ¼ywamy typÃ³w SQL Alchemy dla tworzenia tabeli
            if not self.create_table_if_not_exists(engine, sqlalchemy_dtype_dict, df_to_load, table_name, schema, target_db):
                 if if_exists == 'replace':
                     connection.execute(f'DROP TABLE "{schema}"."{table_name}"')
                     self.create_table_if_not_exists(engine, sqlalchemy_dtype_dict, df_to_load, table_name, schema, target_db)
                 elif if_exists == 'truncate':
                     connection.execute(f'TRUNCATE TABLE "{schema}"."{table_name}"')
            
            self.check_column_size(engine, df_to_load, table_name, schema, target_db)
            
            # 3. Åadowanie partii (Batching)
            total_rows = len(df_to_load)
            # ... (TwÃ³j kod do obsÅ‚ugi pustego DataFrame)
            
            full_batches = total_rows // batch_size
            last_batch_size = total_rows % batch_size
            last_batch = None
            
            loaded_rows = 0
            
            # Przetwarzanie peÅ‚nych partii
            for batch_num in range(full_batches):
                # ... (TwÃ³j kod wycinajÄ…cy batch i logujÄ…cy postÄ™p)
                start = batch_num * batch_size
                end = start + batch_size
                batch = df_to_load.iloc[start:end].copy()

                # --- WÅAÅšCIWE WSTAWIANIE PARTII Z UÅ»YCIEM NOWEJ METODY (LOOKUP) ---
                self._custom_merge_insert(
                    target_db=target_db,
                    batch=batch,
                    table=table_name,
                    schema=schema,
                    lookup_keys=lookup_keys, 
                    conn=connection 
                )
                
                loaded_rows += len(batch)
                del batch
                gc.collect()

            # 4. Przetwarzanie ostatniej partii (jeÅ›li istnieje)
            if last_batch_size > 0:
                start = full_batches * batch_size
                last_batch = df_to_load.iloc[start:total_rows].copy()

                self.logger.info(f"Rozpoczynam przetwarzanie ostatniej partii...")
                gc.collect()
                
                self._custom_merge_insert(
                    target_db=target_db,
                    batch=last_batch,
                    table=table_name,
                    schema=schema,
                    lookup_keys=lookup_keys, 
                    conn=connection
                )
                
                loaded_rows += len(last_batch)
                del last_batch
                gc.collect()
            
            # 5. Kontrola i Logowanie Sukcesu
            # ... (TwÃ³j kod do logowania sukcesu)
            self.logger.info(f"ZaÅ‚adowano {loaded_rows} z {total_rows} wierszy.")

    except Exception as e:
        self.logger.error(f"Krytyczny bÅ‚Ä…d w metodzie insert_data: {e}")
        raise
    finally:
        # ... (TwÃ³j kod do czyszczenia engine)
        if 'engine' in locals():
            self.logger.info("Zamykanie puli poÅ‚Ä…czeÅ„ dla bazy docelowej.")



Oto peÅ‚ny, poprawny kod funkcji map_data_types.
ZostaÅ‚a ona przygotowana tak, aby zwracaÄ‡ obiekty typÃ³w SQLAlchemy (takie jak VARCHAR, CLOB, Integer). Jest to niezbÄ™dne, aby Twoja funkcja create_table_if_not_exists mogÅ‚a poprawnie odczytaÄ‡ wÅ‚aÅ›ciwoÅ›ci (np. dÅ‚ugoÅ›Ä‡ kolumny) i wygenerowaÄ‡ odpowiedni kod SQL (np. VARCHAR2(500)).
> WaÅ¼ne: PamiÄ™taj, Å¼e wynik tej funkcji przekazujemy do create_table..., ale NIE uÅ¼ywamy go juÅ¼ w df.astype() (zgodnie z poprawkÄ… w poprzednim kroku).
> 
ğŸ“„ Kod do wklejenia (w klasie DatabaseManager)
Musisz upewniÄ‡ siÄ™, Å¼e na poczÄ…tku pliku masz odpowiednie importy z biblioteki sqlalchemy.
from sqlalchemy.types import Integer, Float, String, Date, DateTime, Boolean, BigInteger, Text
from sqlalchemy.dialects.oracle import VARCHAR2, CLOB, NUMBER
from sqlalchemy.dialects.mssql import NVARCHAR, DATETIME2

# ... wewnÄ…trz klasy DatabaseManager ...

def map_data_types(self, df: pd.DataFrame, target_db: str) -> dict:
    """
    Mapuje typy danych Pandas na obiekty typÃ³w SQLAlchemy.
    SÅ‚uÅ¼y do generowania struktury tabeli (CREATE TABLE).
    """
    
    # Pomocnicza funkcja do obliczania dÅ‚ugoÅ›ci stringÃ³w
    def get_varchar_length(series):
        if series.empty:
            return 100 # DomyÅ›lna dÅ‚ugoÅ›Ä‡ dla pustych kolumn
            
        # Obliczamy maksymalnÄ… dÅ‚ugoÅ›Ä‡ w kolumnie
        max_len = series.astype(str).map(len).max()
        
        if pd.isna(max_len):
            return 100
            
        # Dodajemy margines bezpieczeÅ„stwa (np. 20%), ale nie przekraczamy limitÃ³w
        # Integery w Pythonie nie majÄ… limitu, ale bazy tak
        safe_length = int(max_len * 1.2) 
        return safe_length

    dtype_dict = {}
    target_db_lower = target_db.lower()

    for column in df.columns:
        # Pobieramy typ pandasowy
        pandas_dtype = df[column].dtype.name
        
        # --- Logika dla ORACLE ---
        if target_db_lower == 'oracle':
            if 'int' in pandas_dtype:
                dtype_dict[column] = Integer() # Lub NUMBER(38) w definicji SQL
            elif 'float' in pandas_dtype:
                dtype_dict[column] = Float()
            elif 'datetime' in pandas_dtype:
                dtype_dict[column] = DateTime() # Mapuje na TIMESTAMP/DATE
            elif 'bool' in pandas_dtype:
                dtype_dict[column] = Integer() # Oracle nie ma BOOLEAN, uÅ¼ywamy NUMBER(1)
            else:
                # String / Object
                length = get_varchar_length(df[column])
                if length > 4000:
                    dtype_dict[column] = CLOB()
                else:
                    # Minimum 1, maksimum 4000 dla VARCHAR2 w SQL (chyba Å¼e MAX_STRING_SIZE=EXTENDED)
                    final_len = max(1, min(length, 4000))
                    dtype_dict[column] = VARCHAR2(final_len)

        # --- Logika dla SQL SERVER ---
        elif target_db_lower == 'sqlserver':
            if 'int' in pandas_dtype:
                dtype_dict[column] = BigInteger()
            elif 'float' in pandas_dtype:
                dtype_dict[column] = Float()
            elif 'datetime' in pandas_dtype:
                dtype_dict[column] = DATETIME2()
            elif 'bool' in pandas_dtype:
                dtype_dict[column] = Boolean() # SQL Server ma BIT
            else:
                # String / Object
                length = get_varchar_length(df[column])
                if length > 4000:
                    dtype_dict[column] = NVARCHAR(None) # NVARCHAR(MAX)
                else:
                    dtype_dict[column] = NVARCHAR(max(1, length))

        # --- Logika dla IMPALA ---
        elif target_db_lower == 'impala':
            if 'int' in pandas_dtype:
                dtype_dict[column] = BigInteger()
            elif 'float' in pandas_dtype:
                dtype_dict[column] = Float()
            elif 'datetime' in pandas_dtype:
                dtype_dict[column] = String(None) # Impala czÄ™sto woli String dla timestampÃ³w przy insercie, lub TIMESTAMP
            elif 'bool' in pandas_dtype:
                dtype_dict[column] = Boolean()
            else:
                # Impala STRING (bez dÅ‚ugoÅ›ci) lub VARCHAR(n)
                # CzÄ™sto bezpieczniej uÅ¼yÄ‡ String, chyba Å¼e zaleÅ¼y Ci na limitach
                dtype_dict[column] = String(None)

        # --- DomyÅ›lna logika (fallback) ---
        else:
            # DomyÅ›lne mapowanie SQLAlchemy
            if 'int' in pandas_dtype:
                dtype_dict[column] = Integer()
            elif 'float' in pandas_dtype:
                dtype_dict[column] = Float()
            elif 'datetime' in pandas_dtype:
                dtype_dict[column] = DateTime()
            else:
                length = get_varchar_length(df[column])
                dtype_dict[column] = String(length)

    return dtype_dict

ğŸ” Co ulepszyÅ‚em wzglÄ™dem Twojej wersji ze zdjÄ™cia?
 * Dynamiczne obliczanie dÅ‚ugoÅ›ci: DodaÅ‚em wewnÄ™trznÄ… funkcjÄ™ get_varchar_length, ktÃ³ra oblicza rzeczywistÄ… dÅ‚ugoÅ›Ä‡ danych w kolumnie i dodaje margines. DziÄ™ki temu nie tworzysz wszÄ™dzie VARCHAR(4000) ani nie ucinasz danych.
 * Poprawne obiekty SQLAlchemy: Funkcja zwraca instancje klas (np. VARCHAR2(50)), a nie stringi. To kluczowe dla dziaÅ‚ania poprawionej funkcji create_table_if_not_exists.
 * ObsÅ‚uga specyficzna dla baz:
   * Oracle: RozrÃ³Å¼nia VARCHAR2 (do 4000 znakÃ³w) i CLOB (powyÅ¼ej).
   * SQL Server: UÅ¼ywa NVARCHAR (dla polskich znakÃ³w) i NVARCHAR(MAX) (oznaczone jako None) dla dÅ‚ugich tekstÃ³w.
Teraz, majÄ…c tÄ™ funkcjÄ™ oraz poprawionÄ… insert_data (gdzie rozdzieliliÅ›my typy SQL od typÃ³w Pandas), TwÃ³j kod powinien dziaÅ‚aÄ‡ stabilnie.
