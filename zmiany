
Jasne, rozumiem zadanie. DziaÅ‚am jako doÅ›wiadczony analityk danych. PoniÅ¼ej przedstawiam kompletnÄ… analizÄ™ w formacie notatnika Jupyter. ZawarÅ‚em w niej kod, wizualizacje, a co najwaÅ¼niejsze â€“ interpretacjÄ™ biznesowÄ… wynikÃ³w i rekomendacje, czyli to, czego oczekuje siÄ™ od starszego analityka.
Analiza PorÃ³wnawcza PoÅ‚Ä…czeÅ„ z InfoliniÄ… Rok do Roku (YoY)
Data: 16 wrzeÅ›nia 2025
Autor: Gemini - Analityk Danych
ğŸ¯ 1. Cel Analizy
GÅ‚Ã³wnym celem tej analizy jest przeprowadzenie szczegÃ³Å‚owego porÃ³wnania rocznego (Year-over-Year) kluczowych wskaÅºnikÃ³w wydajnoÅ›ci (KPI) infolinii. Skupimy siÄ™ na zrozumieniu zmian w wolumenie, efektywnoÅ›ci i charakterystyce interakcji klientÃ³w. Analiza ma dostarczyÄ‡ actionable insights, ktÃ³re pomogÄ… w optymalizacji procesÃ³w, alokacji zasobÃ³w i planowaniu strategicznym.
GÅ‚Ã³wne pytania badawcze:
 * Jak zmieniÅ‚ siÄ™ ogÃ³lny wolumen interakcji rok do roku?
 * KtÃ³re kanaÅ‚y kontaktu zyskaÅ‚y, a ktÃ³re straciÅ‚y na popularnoÅ›ci?
 * Jak ewoluowaÅ‚a efektywnoÅ›Ä‡ operacyjna (np. Å›redni czas rozmowy)?
 * Czy zmieniÅ‚ siÄ™ sposÃ³b, w jaki klienci trafiajÄ… na infoliniÄ™ (wejscie) i gdzie koÅ„czÄ… swojÄ… podrÃ³Å¼ (gdzie koniec)?
 * Czy obserwujemy zmiany w sezonowoÅ›ci lub trendach w ciÄ…gu roku?
ğŸ¤” 2. ZaÅ‚oÅ¼enia i Dodatkowe Pytania
Zanim przejdziemy do kodu, jako analityk muszÄ™ jasno okreÅ›liÄ‡ zaÅ‚oÅ¼enia i zidentyfikowaÄ‡ potencjalne braki w danych. Twoje pytanie "czy o wszystkim napisaÅ‚em" jest kluczowe.
ZaÅ‚oÅ¼enia:
 * ZakÅ‚adam, Å¼e tabela zawiera dane z co najmniej dwÃ³ch peÅ‚nych, porÃ³wnywalnych lat.
 * czas rozmowy to suma czasu w sekundach dla danej grupy.
 * Tabela, oprÃ³cz wymienionych kolumn, musi zawieraÄ‡ liczbÄ™ poÅ‚Ä…czeÅ„/interakcji dla kaÅ¼dego wiersza (np. w kolumnie liczba_polaczen). Bez tej metryki nie bÄ™dziemy w stanie policzyÄ‡ kluczowych wskaÅºnikÃ³w, jak Å›redni czas rozmowy (AHT). JeÅ›li jej nie ma, jest to krytyczny brak.
Pytania doprecyzowujÄ…ce (elementy, ktÃ³re warto dodaÄ‡ w przyszÅ‚oÅ›ci):
 * Kluczowa metryka biznesowa: Czy posiadamy dane o kosztach obsÅ‚ugi per kanaÅ‚? To pozwoliÅ‚oby na analizÄ™ Cost per Interaction.
 * JakoÅ›Ä‡ obsÅ‚ugi: Czy zbieramy dane CSAT/NPS (satysfakcja klienta)? PoÅ‚Ä…czenie danych operacyjnych z jakoÅ›ciowymi daje peÅ‚en obraz sytuacji.
 * FCR (First Contact Resolution): Czy mamy flagÄ™ okreÅ›lajÄ…cÄ…, czy problem zostaÅ‚ rozwiÄ…zany przy pierwszym kontakcie? To jeden z najwaÅ¼niejszych wskaÅºnikÃ³w efektywnoÅ›ci infolinii.
 * SzczegÃ³Å‚owoÅ›Ä‡ danych: Obecne dane sÄ… zagregowane. DostÄ™p do danych surowych (kaÅ¼dy wiersz = jedna interakcja) pozwoliÅ‚by na gÅ‚Ä™bszÄ… analizÄ™, np. dystrybucji czasÃ³w rozmÃ³w, a nie tylko Å›redniej.
PrzystÄ™pujÄ™ do analizy, zakÅ‚adajÄ…c, Å¼e posiadamy kolumnÄ™ liczba_polaczen.
ğŸ 3. Przygotowanie Åšrodowiska i Wczytanie Danych
Zaczynamy od importu niezbÄ™dnych bibliotek i zdefiniowania poÅ‚Ä…czenia z bazÄ… danych MS SQL Server.
# Import bibliotek
import pandas as pd
import sqlalchemy as sa
import matplotlib.pyplot as plt
import seaborn as sns

# Ustawienia wizualizacji
sns.set_theme(style="whitegrid")
plt.rcParams['figure.figsize'] = (12, 6)
plt.rcParams['axes.titlesize'] = 16
plt.rcParams['axes.labelsize'] = 12

# --- Åadowanie danych z MS SQL Server ---
# WypeÅ‚nij poniÅ¼sze zmienne swoimi danymi dostÄ™powymi
server_name = "TWOJ_SERWER"
database_name = "TWOJA_BAZA_DANYCH"
table_name = "NAZWA_TWOJEJ_TABELI"
# UÅ¼yj uwierzytelniania Windows (Integrated Security) lub SQL Server Auth
# Dla Windows Auth:
connection_string = f"mssql+pyodbc://{server_name}/{database_name}?driver=ODBC+Driver+17+for+SQL+Server&trusted_connection=yes"

# Stworzenie "silnika" poÅ‚Ä…czenia
try:
    engine = sa.create_engine(connection_string)
    
    # Zapytanie SQL do wczytania danych
    query = f"SELECT * FROM {table_name}"
    
    # Wczytanie danych do ramki danych Pandas
    df = pd.read_sql(query, engine)
    
    print("âœ… PomyÅ›lnie poÅ‚Ä…czono i wczytano dane.")
    print("PrÃ³bka danych:")
    display(df.head())

except Exception as e:
    print(f"âŒ BÅ‚Ä…d podczas poÅ‚Ä…czenia z bazÄ… danych: {e}")
    # W przypadku bÅ‚Ä™du, tworzÄ™ przykÅ‚adowÄ… ramkÄ™ danych, aby kontynuowaÄ‡ analizÄ™
    data = {'Data': ['2023-01-05', '2023-01-05', '2024-01-06', '2024-01-06', '2023-02-10', '2024-02-11'],
            'Kanal_kontakt': ['voice', 'czat', 'voice', 'czat', 'voice', 'wideo'],
            'Typ_interakcji': ['telefon', 'aplikacja mobilna', 'telefon', 'aplikacja mobilna', 'telefon', 'aplikacja desktopowa'],
            'czy_odebrane': [1, 1, 1, 0, 1, 1],
            'wejscie': ['ivr', 'bot', 'ivr', 'bot', 'ivr', 'vendor'],
            'gdzie_koniec': ['konsultant', 'konsultant', 'konsultant', 'bot', 'transfer', 'konsultant'],
            'czas_rozmowy': [18000, 5400, 22000, 0, 15000, 7200],
            'liczba_polaczen': [100, 60, 110, 50, 90, 30]}
    df = pd.DataFrame(data)
    print("âš ï¸ Utworzono przykÅ‚adowy zbiÃ³r danych do dalszej analizy.")
    display(df.head())


ğŸ› ï¸ 4. Przygotowanie Danych (Data Preprocessing & Feature Engineering)
Dane w stanie surowym rzadko nadajÄ… siÄ™ do bezpoÅ›redniej analizy. Musimy je oczyÅ›ciÄ‡ i wzbogaciÄ‡ o dodatkowe, uÅ¼yteczne cechy.
# Konwersja kolumny 'Data' na typ daty
df['Data'] = pd.to_datetime(df['Data'])

# InÅ¼ynieria cech - wyciÄ…gniÄ™cie roku, miesiÄ…ca i dnia tygodnia
df['Rok'] = df['Data'].dt.year
df['Miesiac'] = df['Data'].dt.month
df['Nazwa_Miesiaca'] = df['Data'].dt.strftime('%B')
df['Dzien_Tygodnia'] = df['Data'].dt.day_name()

# Obliczenie kluczowych metryk
# AHT - Average Handle Time (Åšredni Czas ObsÅ‚ugi) w sekundach
# UÅ¼ywamy .div() i .fillna(0) aby uniknÄ…Ä‡ dzielenia przez zero, jeÅ›li dla jakiejÅ› grupy odebrane poÅ‚Ä…czenia majÄ… sumaryczny czas 0
df['AHT_s'] = (df['czas_rozmowy'] / df['liczba_polaczen'].where(df['czy_odebrane'] == 1, 0)).fillna(0)

# OkreÅ›lenie lat do analizy
current_year = df['Rok'].max()
previous_year = current_year - 1

df_cy = df[df['Rok'] == current_year]
df_py = df[df['Rok'] == previous_year]

print(f"Analiza porÃ³wnawcza dla lat: {current_year} (CY) vs {previous_year} (PY)")
print("Nowe kolumny i AHT zostaÅ‚y obliczone.")

ğŸ“Š 5. Analiza PorÃ³wnawcza i Wizualizacja Danych
Teraz przechodzimy do serca analizy â€“ porÃ³wnania wynikÃ³w rok do roku.
5.1. OgÃ³lny Wolumen Interakcji
SprawdÅºmy, jak zmieniÅ‚a siÄ™ caÅ‚kowita liczba obsÅ‚ugiwanych interakcji.
# Agregacja roczna
total_volume = df.groupby('Rok')['liczba_polaczen'].sum().reset_index()
total_volume_cy = total_volume[total_volume['Rok'] == current_year]['liczba_polaczen'].sum()
total_volume_py = total_volume[total_volume['Rok'] == previous_year]['liczba_polaczen'].sum()

# Obliczenie zmiany YoY
yoy_change = ((total_volume_cy - total_volume_py) / total_volume_py) * 100

# Wizualizacja
plt.figure(figsize=(8, 5))
ax = sns.barplot(data=total_volume, x='Rok', y='liczba_polaczen', palette='viridis')
ax.set_title(f'CaÅ‚kowity Wolumen Interakcji YoY\nZmiana: {yoy_change:.2f}%')
for p in ax.patches:
    ax.annotate(f'{int(p.get_height()):,}', (p.get_x() + p.get_width() / 2., p.get_height()),
                ha='center', va='center', fontsize=12, color='black', xytext=(0, 5),
                textcoords='offset points')
plt.ylabel('Liczba PoÅ‚Ä…czeÅ„')
plt.xlabel('Rok')
plt.show()

Wnioski:
 * Na podstawie wykresu widaÄ‡ [trend wzrostowy/spadkowy].
 * CaÅ‚kowity wolumen interakcji zmieniÅ‚ siÄ™ o yoy_change%. Taka zmiana moÅ¼e wynikaÄ‡ ze wzrostu bazy klientÃ³w, problemÃ³w z produktem lub skutecznoÅ›ci kampanii marketingowych. NaleÅ¼y to skorelowaÄ‡ z dziaÅ‚aniami biznesowymi firmy w analizowanym okresie.
5.2. Analiza Wolumenu w Podziale na KanaÅ‚y
KtÃ³re kanaÅ‚y napÄ™dzajÄ… zmianÄ™ w wolumenie?
# Agregacja po roku i kanale
channel_volume = df.groupby(['Rok', 'Kanal_kontakt'])['liczba_polaczen'].sum().reset_index()

# Wizualizacja
plt.figure(figsize=(14, 7))
sns.barplot(data=channel_volume, x='Kanal_kontakt', y='liczba_polaczen', hue='Rok', palette='mako')
plt.title('Wolumen Interakcji w Podziale na KanaÅ‚y (YoY)')
plt.ylabel('Liczba PoÅ‚Ä…czeÅ„')
plt.xlabel('KanaÅ‚ Kontaktu')
plt.legend(title='Rok')
plt.show()

Wnioski:
 * Ten wykres pokazuje, ktÃ³re kanaÅ‚y zyskujÄ… na popularnoÅ›ci. Widzimy wyraÅºny wzrost/spadek dla kanaÅ‚u X, podczas gdy kanaÅ‚ Y pozostaje stabilny/traci.
 * Rekomendacja: JeÅ›li obserwujemy silny wzrost na kanale czat, warto zainwestowaÄ‡ w rozwÃ³j bota lub zwiÄ™kszyÄ‡ liczbÄ™ agentÃ³w obsÅ‚ugujÄ…cych ten kanaÅ‚. JeÅ›li kanaÅ‚ voice maleje, moÅ¼na rozwaÅ¼yÄ‡ optymalizacjÄ™ zasobÃ³w w tym obszarze.
5.3. Analiza Åšredniego Czasu ObsÅ‚ugi (AHT)
Czy nasza efektywnoÅ›Ä‡ roÅ›nie czy maleje? AHT jest kluczowym wskaÅºnikiem.
# Agregacja AHT dla poÅ‚Ä…czeÅ„ odebranych
aht_analysis = df[df['czy_odebrane'] == 1].copy()
# Obliczamy Å›redniÄ… waÅ¼onÄ… AHT
aht_yearly = aht_analysis.groupby('Rok').apply(lambda x: (x['czas_rozmowy']).sum() / x['liczba_polaczen'].sum()).reset_index(name='Sredni_AHT_s')


# Wizualizacja AHT
plt.figure(figsize=(8, 5))
ax = sns.barplot(data=aht_yearly, x='Rok', y='Sredni_AHT_s', palette='coolwarm')
ax.set_title('Åšredni Czas ObsÅ‚ugi (AHT) YoY')
for p in ax.patches:
    ax.annotate(f'{p.get_height():.1f}s', (p.get_x() + p.get_width() / 2., p.get_height()),
                ha='center', va='center', fontsize=12, color='black', xytext=(0, 5),
                textcoords='offset points')
plt.ylabel('AHT (w sekundach)')
plt.xlabel('Rok')
plt.show()

Wnioski:
 * Wzrost AHT moÅ¼e Å›wiadczyÄ‡ o bardziej skomplikowanych problemach zgÅ‚aszanych przez klientÃ³w, niedostatecznym szkoleniu agentÃ³w lub problemach systemowych.
 * Spadek AHT to generalnie dobry znak, o ile nie odbywa siÄ™ kosztem jakoÅ›ci (dlatego potrzebne sÄ… dane CSAT!). MoÅ¼e byÄ‡ wynikiem lepszych narzÄ™dzi dla konsultantÃ³w lub skuteczniejszego sortowania zapytaÅ„ przez IVR/bota.
5.4. Analiza ÅšcieÅ¼ki Klienta: WejÅ›cie i ZakoÅ„czenie Interakcji
Gdzie klienci zaczynajÄ… i koÅ„czÄ… swojÄ… podrÃ³Å¼? Czy bot/IVR skutecznie filtruje poÅ‚Ä…czenia?
fig, axes = plt.subplots(1, 2, figsize=(18, 7))

# Analiza punktÃ³w wejÅ›cia
entry_points = df.groupby(['Rok', 'wejscie'])['liczba_polaczen'].sum().reset_index()
sns.barplot(ax=axes[0], data=entry_points, x='wejscie', y='liczba_polaczen', hue='Rok', palette='viridis')
axes[0].set_title('Punkty WejÅ›cia Interakcji (YoY)')
axes[0].set_xlabel('Punkt WejÅ›cia')
axes[0].set_ylabel('Liczba PoÅ‚Ä…czeÅ„')

# Analiza punktÃ³w zakoÅ„czenia
exit_points = df.groupby(['Rok', 'gdzie_koniec'])['liczba_polaczen'].sum().reset_index()
sns.barplot(ax=axes[1], data=exit_points, x='gdzie_koniec', y='liczba_polaczen', hue='Rok', palette='plasma')
axes[1].set_title('Punkty ZakoÅ„czenia Interakcji (YoY)')
axes[1].set_xlabel('Punkt ZakoÅ„czenia')
axes[1].set_ylabel('Liczba PoÅ‚Ä…czeÅ„')

plt.tight_layout()
plt.show()

Wnioski:
 * Po lewej (WejÅ›cia): Analizujemy, czy np. wiÄ™cej klientÃ³w korzysta z bota jako pierwszego punktu kontaktu.
 * Po prawej (ZakoÅ„czenia): Kluczowe jest tu porÃ³wnanie liczby interakcji koÅ„czÄ…cych siÄ™ na bocie/IVR w stosunku do tych trafiajÄ…cych do konsultanta. JeÅ›li rok do roku roÅ›nie liczba spraw zaÅ‚atwianych w peÅ‚ni automatycznie, to jest to duÅ¼y sukces i oszczÄ™dnoÅ›Ä‡ kosztÃ³w. JeÅ›li roÅ›nie liczba transferÃ³w (transfer), moÅ¼e to wskazywaÄ‡ na zÅ‚Ä… konfiguracjÄ™ IVR lub bota.
5.5. Analiza SezonowoÅ›ci i TrendÃ³w MiesiÄ™cznych
Jak rozkÅ‚ada siÄ™ ruch w ciÄ…gu roku? Czy wystÄ™pujÄ… podobne piki w obu latach?
# Agregacja miesiÄ™czna
monthly_trends = df.groupby(['Rok', 'Miesiac'])['liczba_polaczen'].sum().reset_index()

# Wizualizacja
plt.figure(figsize=(14, 7))
sns.lineplot(data=monthly_trends, x='Miesiac', y='liczba_polaczen', hue='Rok', palette='Set1', marker='o', linewidth=2.5)
plt.title('MiesiÄ™czne Trendy Wolumenu PoÅ‚Ä…czeÅ„ (YoY)')
plt.xlabel('MiesiÄ…c')
plt.ylabel('Liczba PoÅ‚Ä…czeÅ„')
plt.xticks(ticks=range(1, 13), labels=['Sty', 'Lut', 'Mar', 'Kwi', 'Maj', 'Cze', 'Lip', 'Sie', 'Wrz', 'PaÅº', 'Lis', 'Gru'])
plt.legend(title='Rok')
plt.show()

Wnioski:
 * Wykres liniowy doskonale uwidacznia sezonowoÅ›Ä‡. MoÅ¼emy zidentyfikowaÄ‡ miesiÄ…ce o najwiÄ™kszym obciÄ…Å¼eniu (np. okresy Å›wiÄ…teczne, poczÄ…tek/koniec roku, daty zwiÄ…zane z cyklem Å¼ycia produktu).
 * PorÃ³wnanie linii dla obu lat pozwala sprawdziÄ‡, czy piki sezonowe siÄ™ powtarzajÄ… i czy rÃ³Å¼nica w wolumenie miÄ™dzy latami jest staÅ‚a, czy moÅ¼e roÅ›nie w okreÅ›lonych miesiÄ…cach.
 * Rekomendacja: Wiedza o sezonowoÅ›ci jest kluczowa dla planowania grafikÃ³w pracy konsultantÃ³w (Workforce Management).
ğŸ’¡ 6. Podsumowanie i Rekomendacje Biznesowe
Na podstawie przeprowadzonej analizy wyÅ‚aniajÄ… siÄ™ nastÄ™pujÄ…ce kluczowe wnioski:
 * OgÃ³lny Trend: W roku {current_year} zaobserwowaliÅ›my [wzrost/spadek] caÅ‚kowitego wolumenu interakcji o yoy_change% w stosunku do roku {previous_year}.
 * GÅ‚Ã³wny Motor Zmian: NajwiÄ™kszy wpÅ‚yw na tÄ™ zmianÄ™ miaÅ‚ kanaÅ‚ [nazwa kanaÅ‚u], ktÃ³rego popularnoÅ›Ä‡ [wzrosÅ‚a/zmalaÅ‚a]. Wskazuje to na zmieniajÄ…ce siÄ™ preferencje klientÃ³w w sposobie kontaktu z nami.
 * EfektywnoÅ›Ä‡ Operacyjna: Åšredni czas obsÅ‚ugi (AHT) [wzrÃ³sÅ‚/zmniejszyÅ‚ siÄ™], co sugeruje, Å¼e interakcje stajÄ… siÄ™ [bardziej/mniej] skomplikowane lub nasza efektywnoÅ›Ä‡ ulegÅ‚a zmianie. NaleÅ¼y to zbadaÄ‡ w kontekÅ›cie konkretnych typÃ³w zgÅ‚oszeÅ„.
 * Automatyzacja i Self-Service: Analiza Å›cieÅ¼ki klienta pokazaÅ‚a, Å¼e odsetek interakcji koÅ„czÄ…cych siÄ™ w kanaÅ‚ach automatycznych (bot, IVR) [wzrÃ³sÅ‚/zmniejszyÅ‚ siÄ™]. To kluczowy wskaÅºnik sukcesu naszej strategii automatyzacji.
Rekomendacje:
 * Inwestycja w kanaÅ‚y rosnÄ…ce: ZwiÄ™kszyÄ‡ zasoby (ludzkie i technologiczne) dla kanaÅ‚u [nazwa rosnÄ…cego kanaÅ‚u], aby utrzymaÄ‡ wysokÄ… jakoÅ›Ä‡ obsÅ‚ugi przy rosnÄ…cym wolumenie.
 * DogÅ‚Ä™bna analiza AHT: PrzeprowadziÄ‡ analizÄ™ "drill-down" dla interakcji z rosnÄ…cym AHT. ZidentyfikowaÄ‡ konkretne przyczyny (np. typy zgÅ‚oszeÅ„) i zorganizowaÄ‡ dodatkowe szkolenia dla agentÃ³w lub usprawniÄ‡ bazÄ™ wiedzy.
 * Optymalizacja Å›cieÅ¼ki klienta: JeÅ›li zbyt wiele interakcji z bota/IVR trafia do konsultanta, naleÅ¼y przeanalizowaÄ‡ logi i zidentyfikowaÄ‡ miejsca, w ktÃ³rych proces siÄ™ "zrywa". Celem jest zwiÄ™kszenie wskaÅºnika FCR w kanaÅ‚ach automatycznych.
 * Prognozowanie i planowanie: WykorzystaÄ‡ zidentyfikowane trendy miesiÄ™czne do stworzenia bardziej dokÅ‚adnego modelu prognozowania wolumenu, co pozwoli na lepszÄ… optymalizacjÄ™ grafikÃ³w pracy.

Doskonale, to bardzo waÅ¼na i czÄ™sta sytuacja w analizie danych! Praca na danych surowych (per poÅ‚Ä…czenie) daje nam znacznie wiÄ™ksze moÅ¼liwoÅ›ci. PorÃ³wnanie niepeÅ‚nego roku do adekwatnego okresu w przeszÅ‚oÅ›ci to standard "best practice".
PrzygotowaÅ‚em zaktualizowanÄ… wersjÄ™ notatnika, ktÃ³ra uwzglÄ™dnia nowÄ… strukturÄ™ danych i logikÄ™ porÃ³wnawczÄ… "rok do dziÅ›" (Year-to-Date, YTD).
Analiza PorÃ³wnawcza PoÅ‚Ä…czeÅ„ z InfoliniÄ… - Wersja YTD (Year-to-Date)
Data: 16 wrzeÅ›nia 2025
Autor: Gemini - Analityk Danych
ğŸ¯ 1. Cel Analizy (Bez Zmian)
GÅ‚Ã³wnym celem tej analizy jest przeprowadzenie szczegÃ³Å‚owego porÃ³wnania rocznego (Year-over-Year) kluczowych wskaÅºnikÃ³w wydajnoÅ›ci (KPI) infolinii dla porÃ³wnywalnych okresÃ³w. Skupimy siÄ™ na zrozumieniu zmian w wolumenie, efektywnoÅ›ci i charakterystyce interakcji klientÃ³w.
ğŸ¤” 2. ZaÅ‚oÅ¼enia i Dane
Kluczowa zmiana: Pracujemy na danych granularnych, gdzie kaÅ¼dy wiersz to jedna, unikalna interakcja identyfikowana przez callid. Tabela nie jest juÅ¼ pogrupowana.
Struktura danych:
 * callid: Unikalny identyfikator kaÅ¼dej interakcji.
 * Data: Data interakcji (zakÅ‚adam, Å¼e zawiera rÃ³wnieÅ¼ czas, jeÅ›li nie, analiza godzinowa bÄ™dzie niemoÅ¼liwa).
 * PozostaÅ‚e kolumny bez zmian: Kanal_kontakt, Typ_interakcji, czy_odebrane, wejscie, gdzie_koniec, czas_rozmowy.
Logika porÃ³wnawcza:
Analiza bÄ™dzie porÃ³wnywaÄ‡ okres od poczÄ…tku roku do ostatniej dostÄ™pnej daty w bieÅ¼Ä…cym roku z dokÅ‚adnie tym samym okresem w roku poprzednim. Na przykÅ‚ad, jeÅ›li najnowsze dane sÄ… z 15 wrzeÅ›nia 2024, porÃ³wnamy okres 01.01.2024 - 15.09.2024 z 01.01.2023 - 15.09.2023.
ğŸ 3. Przygotowanie Åšrodowiska i Wczytanie Danych
Kod do poÅ‚Ä…czenia pozostaje ten sam, ale tworzÄ™ nowy, bardziej realistyczny przykÅ‚ad danych.
# Import bibliotek
import pandas as pd
import sqlalchemy as sa
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np # Dodajemy numpy do obliczeÅ„

# Ustawienia wizualizacji
sns.set_theme(style="whitegrid")
plt.rcParams['figure.figsize'] = (12, 6)

# --- Åadowanie danych z MS SQL Server ---
# WypeÅ‚nij poniÅ¼sze zmienne swoimi danymi dostÄ™powymi
server_name = "TWOJ_SERWER"
database_name = "TWOJA_BAZA_DANYCH"
table_name = "NAZWA_TWOJEJ_TABELI_RAW"

try:
    # ... (kod poÅ‚Ä…czenia taki sam jak poprzednio) ...
    query = f"SELECT * FROM {table_name}"
    df_raw = pd.read_sql(query, engine)
    print("âœ… PomyÅ›lnie wczytano dane granularne.")

except Exception as e:
    print(f"âŒ BÅ‚Ä…d: {e}")
    # Nowy, przykÅ‚adowy zbiÃ³r danych granularnych
    data = {'callid': range(1000),
            'Data': pd.to_datetime(pd.date_range(start='2023-01-01', periods=500, freq='D').tolist() + 
                                   pd.date_range(start='2024-01-01', periods=500, freq='D').tolist()),
            'Kanal_kontakt': np.random.choice(['voice', 'czat', 'wideo'], 1000),
            'czy_odebrane': np.random.choice([1, 0], 1000, p=[0.8, 0.2]),
            'wejscie': np.random.choice(['ivr', 'bot', 'vendor'], 1000),
            'gdzie_koniec': np.random.choice(['konsultant', 'bot', 'transfer'], 1000),
            'czas_rozmowy': np.random.randint(30, 600, 1000)}
    df_raw = pd.DataFrame(data)
    # Ustawiamy niektÃ³re czasy na 0 dla nieodebranych
    df_raw.loc[df_raw['czy_odebrane'] == 0, 'czas_rozmowy'] = 0
    print("âš ï¸ Utworzono przykÅ‚adowy, granularny zbiÃ³r danych.")
    
display(df_raw.head())

ğŸ› ï¸ 4. Przygotowanie Danych (Logika YTD)
To jest kluczowy, nowy krok. Tworzymy porÃ³wnywalne zbiory danych.
# Konwersja kolumny 'Data' i tworzenie cech
df_raw['Data'] = pd.to_datetime(df_raw['Data'])
df_raw['Rok'] = df_raw['Data'].dt.year
df_raw['Miesiac'] = df_raw['Data'].dt.month
df_raw['Dzien_Roku'] = df_raw['Data'].dt.dayofyear # DzieÅ„ roku (1-366) jest idealny do porÃ³wnaÅ„ YTD

# --- Implementacja logiki Year-to-Date (YTD) ---

# 1. ZnajdÅº ostatniÄ… datÄ™ w bieÅ¼Ä…cym roku
current_year = df_raw['Rok'].max()
latest_date_cy = df_raw[df_raw['Rok'] == current_year]['Data'].max()
latest_day_of_year = latest_date_cy.dayofyear

print(f"Najnowsze dane pochodzÄ… z: {latest_date_cy.strftime('%Y-%m-%d')}")
print(f"Analiza zostanie przeprowadzona do {latest_day_of_year}. dnia roku.")

# 2. Odfiltruj dane z obu lat, aby obejmowaÅ‚y ten sam okres
df_ytd = df_raw[df_raw['Dzien_Roku'] <= latest_day_of_year].copy()

# 3. Sprawdzenie
print("\nZakres dat w analizowanym zbiorze:")
print(f"BieÅ¼Ä…cy rok: {df_ytd[df_ytd['Rok'] == current_year]['Data'].min().date()} - {df_ytd[df_ytd['Rok'] == current_year]['Data'].max().date()}")
print(f"Poprzedni rok: {df_ytd[df_ytd['Rok'] == current_year-1]['Data'].min().date()} - {df_ytd[df_ytd['Rok'] == current_year-1]['Data'].max().date()}")


ğŸ“Š 5. Analiza PorÃ³wnawcza i Wizualizacja Danych (YTD)
Wszystkie poniÅ¼sze analizy uÅ¼ywajÄ… juÅ¼ przefiltrowanego zbioru df_ytd.
5.1. OgÃ³lny Wolumen Interakcji (YTD)
# Agregacja YTD - liczymy callid
total_volume_ytd = df_ytd.groupby('Rok')['callid'].count().reset_index().rename(columns={'callid': 'liczba_polaczen'})

# Obliczenia i wizualizacja (kod wizualizacji pozostaje bardzo podobny)
# ... (uÅ¼yj kodu z poprzedniej odpowiedzi, ale na ramce total_volume_ytd) ...
# PamiÄ™taj o zmianie tytuÅ‚u na 'CaÅ‚kowity Wolumen Interakcji (YTD)'

Wnioski (YTD):
 * PorÃ³wnujÄ…c adekwatne okresy, widzimy [wzrost/spadek] wolumenu. DziÄ™ki temu podejÅ›ciu eliminujemy wpÅ‚yw sezonowoÅ›ci z pozostaÅ‚ej czÄ™Å›ci roku, dajÄ…c bardziej rzetelny obraz sytuacji.
5.2. Analiza Wolumenu w Podziale na KanaÅ‚y (YTD)
# Agregacja YTD po kanaÅ‚ach
channel_volume_ytd = df_ytd.groupby(['Rok', 'Kanal_kontakt'])['callid'].count().reset_index().rename(columns={'callid': 'liczba_polaczen'})

# Wizualizacja (kod podobny, zmieÅ„ tytuÅ‚ na '... (YTD)')
# ...

Wnioski (YTD):
 * Analiza YTD potwierdza/zmienia obraz z analizy caÅ‚orocznej. ByÄ‡ moÅ¼e wzrost na kanale czat nastÄ…piÅ‚ dopiero w drugiej poÅ‚owie poprzedniego roku, a porÃ³wnanie YTD pokazuje bardziej wyrÃ³wnany poziom.
5.3. Analiza Åšredniego Czasu ObsÅ‚ugi (AHT) (YTD)
Teraz AHT liczymy jako prostÄ… Å›redniÄ… z czas_rozmowy dla poÅ‚Ä…czeÅ„ odebranych.
# Filtrujemy tylko odebrane poÅ‚Ä…czenia
df_answered_ytd = df_ytd[df_ytd['czy_odebrane'] == 1]

# Agregacja YTD AHT
aht_ytd = df_answered_ytd.groupby('Rok')['czas_rozmowy'].mean().reset_index().rename(columns={'czas_rozmowy': 'Sredni_AHT_s'})

# Wizualizacja (kod podobny, zmieÅ„ tytuÅ‚ na '... (YTD)')
# ...

Wnioski (YTD):
 * Analiza AHT w okresach porÃ³wnywalnych jest kluczowa. ByÄ‡ moÅ¼e w poprzednim roku pod koniec roku mieliÅ›my seriÄ™ trudnych zgÅ‚oszeÅ„, ktÃ³re zawyÅ¼yÅ‚y Å›redniÄ… rocznÄ…, a analiza YTD pokazuje, Å¼e nasza efektywnoÅ›Ä‡ faktycznie siÄ™ poprawiÅ‚a.
(PozostaÅ‚e analizy 5.4 i 5.5 wykonuje siÄ™ analogicznie, zawsze grupujÄ…c dane z df_ytd i liczÄ…c callid za pomocÄ… .count())
ğŸ’ 6. GÅ‚Ä™bsza Analiza DziÄ™ki Danym Granularnym (Bonus)
Praca na surowych danych otwiera drzwi do analiz, ktÃ³re wczeÅ›niej byÅ‚y niemoÅ¼liwe.
6.1. Dystrybucja Czasu Trwania RozmÃ³w
Åšrednia (AHT) to nie wszystko. Czy wiÄ™kszoÅ›Ä‡ rozmÃ³w jest krÃ³tka, a kilka ekstremalnie dÅ‚ugich zawyÅ¼a Å›redniÄ…?
plt.figure(figsize=(14, 7))
# UÅ¼ywamy danych z bieÅ¼Ä…cego roku jako przykÅ‚ad
sns.histplot(data=df_answered_ytd[df_answered_ytd['Rok'] == current_year], x='czas_rozmowy', bins=50, kde=True)
plt.title(f'Dystrybucja Czasu Trwania RozmÃ³w (Histogram) w {current_year} (YTD)')
plt.xlabel('Czas rozmowy (sekundy)')
plt.ylabel('Liczba poÅ‚Ä…czeÅ„')
plt.axvline(df_answered_ytd[df_answered_ytd['Rok'] == current_year]['czas_rozmowy'].mean(), color='red', linestyle='--', label='Åšrednia (AHT)')
plt.legend()
plt.show()

Wnioski:
 * Histogram pokazuje faktyczny rozkÅ‚ad czasÃ³w rozmÃ³w. JeÅ›li jest on prawostronnie skoÅ›ny (co jest typowe), oznacza to, Å¼e wiÄ™kszoÅ›Ä‡ rozmÃ³w jest krÃ³tsza niÅ¼ Å›rednia, ale mamy "ogon" bardzo dÅ‚ugich rozmÃ³w.
 * Rekomendacja: Zamiast skupiaÄ‡ siÄ™ tylko na obniÅ¼aniu Å›redniej, warto zidentyfikowaÄ‡ te najdÅ‚uÅ¼sze rozmowy (callid z top 5% czas_rozmowy) i zbadaÄ‡ ich przyczyny. ByÄ‡ moÅ¼e sÄ… to zÅ‚oÅ¼one problemy techniczne lub nowi agenci, ktÃ³rzy potrzebujÄ… wsparcia.
6.2. Analiza obciÄ…Å¼enia w ciÄ…gu dnia (Peak Hour Analysis)
JeÅ›li kolumna Data zawiera czas, moÅ¼emy sprawdziÄ‡, o ktÃ³rej godzinie mamy najwiÄ™cej poÅ‚Ä…czeÅ„.
# Wzbogacenie danych o godzinÄ™
df_ytd['Godzina'] = df_ytd['Data'].dt.hour

# Agregacja godzinowa dla bieÅ¼Ä…cego roku
hourly_volume = df_ytd[df_ytd['Rok'] == current_year].groupby('Godzina')['callid'].count().reset_index()

plt.figure(figsize=(14, 7))
sns.barplot(data=hourly_volume, x='Godzina', y='callid', color='skyblue')
plt.title(f'RozkÅ‚ad PoÅ‚Ä…czeÅ„ w CiÄ…gu Dnia w {current_year} (YTD)')
plt.xlabel('Godzina Dnia')
plt.ylabel('Liczba PoÅ‚Ä…czeÅ„')
plt.show()

Wnioski:
 * Ten wykres jest absolutnie kluczowy dla Workforce Managementu. Pozwala zidentyfikowaÄ‡ godziny szczytu (np. 10:00-12:00) oraz okresy mniejszego ruchu.
 * Rekomendacja: DopasowaÄ‡ grafiki konsultantÃ³w do faktycznego obciÄ…Å¼enia. W godzinach szczytu zapewniÄ‡ peÅ‚nÄ… obsadÄ™, a w godzinach o mniejszym ruchu zaplanowaÄ‡ czas na szkolenia, spotkania czy odpisywanie na maile.
ğŸ’¡ 7. Podsumowanie i Rekomendacje (Wersja YTD)
Ta zaktualizowana analiza, oparta na danych granularnych i porÃ³wnaniu YTD, daje znacznie dokÅ‚adniejszy i bardziej wiarygodny obraz sytuacji.
Kluczowe zmiany w stosunku do poprzedniej analizy:
 * WiarygodnoÅ›Ä‡: PorÃ³wnujemy te same, adekwatne okresy, co eliminuje bÅ‚Ä™dy wynikajÄ…ce z sezonowoÅ›ci w pÃ³Åºniejszych miesiÄ…cach.
 * GÅ‚Ä™bia: Analiza dystrybucji AHT i obciÄ…Å¼enia godzinowego dostarcza nowych, praktycznych wnioskÃ³w, ktÃ³re byÅ‚y niemoÅ¼liwe do uzyskania na danych zagregowanych.
Rekomendacje z poprzedniej analizy pozostajÄ… w mocy, ale teraz sÄ… poparte solidniejszymi danymi i wzbogacone o nowe, bardziej szczegÃ³Å‚owe sugestie dotyczÄ…ce zarzÄ…dzania najdÅ‚uÅ¼szymi rozmowami i planowania grafikÃ³w pracy.

Jasne, oto kompletny kod analizy w jednym pliku, gotowy do wklejenia i uruchomienia w notatniku Jupyter. Plik zawiera wszystkie kroki: od poÅ‚Ä…czenia z danymi, przez ich przygotowanie z logikÄ… YTD, aÅ¼ po analizÄ™, wizualizacjÄ™ i wnioski biznesowe.
# ==============================================================================
# KROK 1: IMPORT BIBLIOTEK I USTAWIENIA WIZUALIZACJI
# ==============================================================================
import pandas as pd
import sqlalchemy as sa
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# Ustawienia dla wykresÃ³w, aby byÅ‚y czytelne i estetyczne
sns.set_theme(style="whitegrid")
plt.rcParams['figure.figsize'] = (14, 7)
plt.rcParams['axes.titlesize'] = 18
plt.rcParams['axes.labelsize'] = 14
plt.rcParams['xtick.labelsize'] = 12
plt.rcParams['ytick.labelsize'] = 12
print("âœ… Biblioteki zaÅ‚adowane, styl wykresÃ³w ustawiony.")


# ==============================================================================
# KROK 2: WCZYTANIE DANYCH Z BAZY MS SQL SERVER
# ==============================================================================
# WypeÅ‚nij poniÅ¼sze zmienne swoimi danymi dostÄ™powymi
server_name = "TWOJ_SERWER"
database_name = "TWOJA_BAZA_DANYCH"
table_name = "NAZWA_TWOJEJ_TABELI_RAW"  # Tabela z danymi granularnymi (niezagregowanymi)

try:
    # Tworzenie connection stringa dla uwierzytelniania Windows
    connection_string = f"mssql+pyodbc://{server_name}/{database_name}?driver=ODBC+Driver+17+for+SQL+Server&trusted_connection=yes"
    engine = sa.create_engine(connection_string)
    
    query = f"SELECT * FROM {table_name}"
    df_raw = pd.read_sql(query, engine)
    
    print(f"âœ… PomyÅ›lnie poÅ‚Ä…czono i wczytano {len(df_raw)} rekordÃ³w z tabeli {table_name}.")

except Exception as e:
    print(f"âŒ BÅ‚Ä…d podczas poÅ‚Ä…czenia z bazÄ… danych: {e}")
    print("âš ï¸ TworzÄ™ przykÅ‚adowy, granularny zbiÃ³r danych, aby kontynuowaÄ‡ analizÄ™.")
    # Generowanie realistycznych danych przykÅ‚adowych
    date_rng_2024 = pd.to_datetime(pd.date_range(start='2024-01-01', end='2024-09-15', freq='10min'))
    date_rng_2023 = pd.to_datetime(pd.date_range(start='2023-01-01', end='2023-12-31', freq='9min'))
    all_dates = date_rng_2024.union(date_rng_2023)
    
    data = {
        'callid': range(len(all_dates)),
        'Data': all_dates,
        'Kanal_kontakt': np.random.choice(['voice', 'czat', 'wideo'], len(all_dates), p=[0.7, 0.25, 0.05]),
        'czy_odebrane': np.random.choice([1, 0], len(all_dates), p=[0.85, 0.15]),
        'wejscie': np.random.choice(['ivr', 'bot', 'vendor'], len(all_dates), p=[0.5, 0.4, 0.1]),
        'gdzie_koniec': np.random.choice(['konsultant', 'bot', 'transfer', 'ivr'], len(all_dates), p=[0.7, 0.15, 0.1, 0.05]),
        'czas_rozmowy': np.random.gamma(2, 150, len(all_dates)).astype(int)
    }
    df_raw = pd.DataFrame(data)
    df_raw.loc[df_raw['czy_odebrane'] == 0, 'czas_rozmowy'] = 0

print("\n--- PrÃ³bka danych (5 pierwszych wierszy) ---")
display(df_raw.head())


# ==============================================================================
# KROK 3: PRZYGOTOWANIE DANYCH I IMPLEMENTACJA LOGIKI YTD
# ==============================================================================
print("\n--- RozpoczÄ™to przygotowanie danych ---")
# Konwersja kolumny 'Data' na typ daty i tworzenie dodatkowych cech czasowych
df_raw['Data'] = pd.to_datetime(df_raw['Data'])
df_raw['Rok'] = df_raw['Data'].dt.year
df_raw['Miesiac'] = df_raw['Data'].dt.month
df_raw['Dzien_Roku'] = df_raw['Data'].dt.dayofyear # Klucz do porÃ³wnaÅ„ YTD
df_raw['Godzina'] = df_raw['Data'].dt.hour
df_raw['Nazwa_Miesiaca'] = df_raw['Data'].dt.strftime('%B')

# --- Implementacja logiki Year-to-Date (YTD) ---
# 1. ZnajdÅº ostatniÄ… datÄ™ i dzieÅ„ roku w bieÅ¼Ä…cym roku
current_year = df_raw['Rok'].max()
previous_year = current_year - 1
latest_date_cy = df_raw[df_raw['Rok'] == current_year]['Data'].max()
latest_day_of_year = latest_date_cy.dayofyear

print(f"BieÅ¼Ä…cy rok w analizie: {current_year}")
print(f"Poprzedni rok w analizie: {previous_year}")
print(f"Najnowsze dane pochodzÄ… z: {latest_date_cy.strftime('%Y-%m-%d')} (to {latest_day_of_year}. dzieÅ„ roku)")

# 2. Odfiltruj dane, aby obejmowaÅ‚y ten sam okres w obu latach
df_ytd = df_raw[df_raw['Dzien_Roku'] <= latest_day_of_year].copy()
print(f"âœ… Dane odfiltrowane. Analiza zostanie przeprowadzona dla okresu od 1 stycznia do {latest_day_of_year}. dnia roku.")

# ==============================================================================
# KROK 4: ANALIZA PORÃ“WNAWCZA I WIZUALIZACJA DANYCH (YTD)
# ==============================================================================
print("\n--- RozpoczÄ™to gÅ‚Ã³wnÄ… analizÄ™ porÃ³wnawczÄ… (YTD) ---")

# --- 4.1. OgÃ³lny Wolumen Interakcji (YTD) ---
total_volume_ytd = df_ytd.groupby('Rok')['callid'].count().reset_index().rename(columns={'callid': 'liczba_polaczen'})
vol_cy = total_volume_ytd.loc[total_volume_ytd['Rok'] == current_year, 'liczba_polaczen'].iloc[0]
vol_py = total_volume_ytd.loc[total_volume_ytd['Rok'] == previous_year, 'liczba_polaczen'].iloc[0]
yoy_change = ((vol_cy - vol_py) / vol_py) * 100

plt.figure(figsize=(10, 6))
ax = sns.barplot(data=total_volume_ytd, x='Rok', y='liczba_polaczen', palette='viridis')
ax.set_title(f'CaÅ‚kowity Wolumen Interakcji (YTD)\nZmiana: {yoy_change:.2f}%', fontsize=20)
for p in ax.patches:
    ax.annotate(f'{int(p.get_height()):,}', (p.get_x() + p.get_width() / 2., p.get_height()),
                ha='center', va='center', fontsize=14, color='black', xytext=(0, 10),
                textcoords='offset points')
plt.ylabel('Liczba PoÅ‚Ä…czeÅ„')
plt.xlabel('Rok')
plt.show()

# --- 4.2. Analiza Wolumenu w Podziale na KanaÅ‚y (YTD) ---
channel_volume_ytd = df_ytd.groupby(['Rok', 'Kanal_kontakt'])['callid'].count().reset_index().rename(columns={'callid': 'liczba_polaczen'})
sns.barplot(data=channel_volume_ytd, x='Kanal_kontakt', y='liczba_polaczen', hue='Rok', palette='mako')
plt.title('Wolumen Interakcji w Podziale na KanaÅ‚y (YTD)')
plt.ylabel('Liczba PoÅ‚Ä…czeÅ„')
plt.xlabel('KanaÅ‚ Kontaktu')
plt.legend(title='Rok')
plt.show()

# --- 4.3. Analiza Åšredniego Czasu ObsÅ‚ugi (AHT) (YTD) ---
df_answered_ytd = df_ytd[df_ytd['czy_odebrane'] == 1]
aht_ytd = df_answered_ytd.groupby('Rok')['czas_rozmowy'].mean().reset_index().rename(columns={'czas_rozmowy': 'Sredni_AHT_s'})
plt.figure(figsize=(10, 6))
ax = sns.barplot(data=aht_ytd, x='Rok', y='Sredni_AHT_s', palette='coolwarm')
ax.set_title('Åšredni Czas ObsÅ‚ugi - AHT (YTD)')
for p in ax.patches:
    ax.annotate(f'{p.get_height():.1f}s', (p.get_x() + p.get_width() / 2., p.get_height()),
                ha='center', va='center', fontsize=14, color='black', xytext=(0, 10),
                textcoords='offset points')
plt.ylabel('AHT (w sekundach)')
plt.xlabel('Rok')
plt.show()

# --- 4.4. Analiza ÅšcieÅ¼ki Klienta: WejÅ›cie i ZakoÅ„czenie (YTD) ---
fig, axes = plt.subplots(1, 2, figsize=(20, 8))
entry_points_ytd = df_ytd.groupby(['Rok', 'wejscie'])['callid'].count().reset_index()
exit_points_ytd = df_ytd.groupby(['Rok', 'gdzie_koniec'])['callid'].count().reset_index()

sns.barplot(ax=axes[0], data=entry_points_ytd, x='wejscie', y='callid', hue='Rok', palette='viridis')
axes[0].set_title('Punkty WejÅ›cia Interakcji (YTD)')
axes[0].set_ylabel('Liczba PoÅ‚Ä…czeÅ„')

sns.barplot(ax=axes[1], data=exit_points_ytd, x='gdzie_koniec', y='callid', hue='Rok', palette='plasma')
axes[1].set_title('Punkty ZakoÅ„czenia Interakcji (YTD)')
axes[1].set_ylabel('Liczba PoÅ‚Ä…czeÅ„')
plt.tight_layout()
plt.show()

# --- 4.5. Analiza SezonowoÅ›ci i TrendÃ³w MiesiÄ™cznych (YTD) ---
monthly_trends_ytd = df_ytd.groupby(['Rok', 'Miesiac'])['callid'].count().reset_index()
sns.lineplot(data=monthly_trends_ytd, x='Miesiac', y='callid', hue='Rok', palette='Set1', marker='o', linewidth=2.5)
plt.title('MiesiÄ™czne Trendy Wolumenu PoÅ‚Ä…czeÅ„ (YTD)')
plt.xlabel('MiesiÄ…c')
plt.ylabel('Liczba PoÅ‚Ä…czeÅ„')
plt.xticks(ticks=range(1, 13))
plt.legend(title='Rok')
plt.grid(True, which='both', linestyle='--')
plt.show()

# ==============================================================================
# KROK 5: GÅÄ˜BSZA ANALIZA DZIÄ˜KI DANYM GRANULARNYM (BONUS)
# ==============================================================================
print("\n--- RozpoczÄ™to analizy dodatkowe (bonus) ---")

# --- 5.1. Dystrybucja Czasu Trwania RozmÃ³w ---
fig, axes = plt.subplots(1, 2, figsize=(20, 8), sharey=True)
sns.histplot(ax=axes[0], data=df_answered_ytd[df_answered_ytd['Rok'] == previous_year], x='czas_rozmowy', bins=50, kde=True)
axes[0].set_title(f'Dystrybucja Czasu RozmÃ³w w {previous_year} (YTD)')
axes[0].axvline(aht_ytd.loc[aht_ytd['Rok'] == previous_year, 'Sredni_AHT_s'].iloc[0], color='red', linestyle='--', label='Åšrednia (AHT)')
axes[0].legend()

sns.histplot(ax=axes[1], data=df_answered_ytd[df_answered_ytd['Rok'] == current_year], x='czas_rozmowy', bins=50, kde=True, color='orange')
axes[1].set_title(f'Dystrybucja Czasu RozmÃ³w w {current_year} (YTD)')
axes[1].axvline(aht_ytd.loc[aht_ytd['Rok'] == current_year, 'Sredni_AHT_s'].iloc[0], color='red', linestyle='--', label='Åšrednia (AHT)')
axes[1].legend()
plt.suptitle('PorÃ³wnanie Dystrybucji Czasu RozmÃ³w (YTD)', fontsize=22)
plt.show()

# --- 5.2. Analiza obciÄ…Å¼enia w ciÄ…gu dnia (Peak Hour Analysis) ---
hourly_volume_ytd = df_ytd.groupby(['Rok', 'Godzina'])['callid'].count().reset_index()
g = sns.FacetGrid(hourly_volume_ytd, col="Rok", height=6, aspect=1.5)
g.map(sns.barplot, "Godzina", "callid", order=range(24), palette=['skyblue', 'lightcoral'])
g.set_axis_labels("Godzina Dnia", "Liczba PoÅ‚Ä…czeÅ„")
g.set_titles(col_template="Rok {col_name}")
g.fig.suptitle('RozkÅ‚ad PoÅ‚Ä…czeÅ„ w CiÄ…gu Dnia (YTD)', y=1.03, fontsize=20)
plt.show()

# ==============================================================================
# KROK 6: PODSUMOWANIE I REKOMENDACJE BIZNESOWE
# ==============================================================================
print("\n\n" + "="*80)
print("ğŸ’¡ PODSUMOWANIE WNIOSKÃ“W I REKOMENDACJE BIZNESOWE ğŸ’¡")
print("="*80)
print(f"""
Analiza porÃ³wnawcza okresu od 1 stycznia do {latest_date_cy.strftime('%d %B')} dla lat {previous_year} i {current_year} wykazaÅ‚a nastÄ™pujÄ…ce trendy:

1.  **OgÃ³lny Wolumen:** ZaobserwowaliÅ›my {'wzrost' if yoy_change > 0 else 'spadek'} caÅ‚kowitego wolumenu interakcji o {yoy_change:.2f}%. 
    Jest to kluczowa informacja dla planowania budÅ¼etu i zasobÃ³w na kolejne okresy.

2.  **Struktura KanaÅ‚Ã³w:** Analiza pokazaÅ‚a, Å¼e gÅ‚Ã³wnym motorem zmian byÅ‚ kanaÅ‚ [tutaj wpisz nazwÄ™ kanaÅ‚u z najwiÄ™kszÄ… zmianÄ…].
    Rekomendacja: NaleÅ¼y dostosowaÄ‡ strategiÄ™ obsÅ‚ugi do zmieniajÄ…cych siÄ™ preferencji klientÃ³w, potencjalnie inwestujÄ…c wiÄ™cej w rozwÃ³j kanaÅ‚Ã³w cyfrowych jak 'czat' lub optymalizujÄ…c obsÅ‚ugÄ™ 'voice'.

3.  **EfektywnoÅ›Ä‡ Operacyjna (AHT):** Åšredni czas obsÅ‚ugi (AHT) zmieniÅ‚ siÄ™ z {aht_ytd.loc[aht_ytd['Rok'] == previous_year, 'Sredni_AHT_s'].iloc[0]:.1f}s do {aht_ytd.loc[aht_ytd['Rok'] == current_year, 'Sredni_AHT_s'].iloc[0]:.1f}s.
    Rekomendacja: Warto zbadaÄ‡ przyczyny tej zmiany. JeÅ›li AHT roÅ›nie, naleÅ¼y zidentyfikowaÄ‡ najbardziej czasochÅ‚onne typy zgÅ‚oszeÅ„ i zorganizowaÄ‡ szkolenia. JeÅ›li maleje, upewniÄ‡ siÄ™, Å¼e nie cierpi na tym jakoÅ›Ä‡ (CSAT).

4.  **Automatyzacja (ÅšcieÅ¼ka Klienta):** PorÃ³wnanie punktÃ³w wejÅ›cia i zakoÅ„czenia interakcji wskazuje na [wzrost/spadek] skutecznoÅ›ci naszych systemÃ³w automatycznych (IVR/Bot).
    Rekomendacja: NaleÅ¼y dÄ…Å¼yÄ‡ do tego, aby jak najwiÄ™cej prostych zapytaÅ„ byÅ‚o rozwiÄ…zywanych automatycznie. Analiza interakcji zakoÅ„czonych transferem do konsultanta moÅ¼e wskazaÄ‡ sÅ‚abe punkty w konfiguracji bota/IVR.
    
5.  **ObciÄ…Å¼enie w CiÄ…gu Dnia:** Godziny szczytu w obu latach przypadajÄ… na [wpisz godziny szczytu, np. 10:00-14:00].
    Rekomendacja: Ta informacja jest krytyczna dla dziaÅ‚u Workforce Management. NaleÅ¼y zoptymalizowaÄ‡ grafiki pracy konsultantÃ³w, aby zapewniÄ‡ odpowiedniÄ… obsadÄ™ w godzinach najwiÄ™kszego ruchu i uniknÄ…Ä‡ przepracowania zespoÅ‚u lub dÅ‚ugiego czasu oczekiwania dla klientÃ³w.

Analiza ta stanowi solidnÄ… podstawÄ™ do podejmowania dalszych, Å›wiadomych decyzji biznesowych w celu optymalizacji pracy infolinii.
""")
print("="*80)


