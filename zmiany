Oczywiście. Rozszerzenie analizy o dodatkowy rok w przeszłość to świetny pomysł, który pozwala na głębsze zrozumienie trendów i odróżnienie jednorazowych wahań od długofalowych zmian.
Poniżej znajduje się zaktualizowany, kompletny kod do notatnika Jupyter, który porównuje dane z bieżącego roku (YTD) z adekwatnymi okresami w dwóch poprzednich latach.
# ==============================================================================
# KROK 1: IMPORT BIBLIOTEK I USTAWIENIA WIZUALIZACJI
# ==============================================================================
import pandas as pd
import sqlalchemy as sa
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# Ustawienia dla wykresów, aby były czytelne i estetyczne
sns.set_theme(style="whitegrid")
plt.rcParams['figure.figsize'] = (14, 7)
plt.rcParams['axes.titlesize'] = 18
plt.rcParams['axes.labelsize'] = 14
plt.rcParams['xtick.labelsize'] = 12
plt.rcParams['ytick.labelsize'] = 12
print("✅ Biblioteki załadowane, styl wykresów ustawiony.")


# ==============================================================================
# KROK 2: WCZYTANIE DANYCH Z BAZY MS SQL SERVER
# ==============================================================================
# Wypełnij poniższe zmienne swoimi danymi dostępowymi
server_name = "TWOJ_SERWER"
database_name = "TWOJA_BAZA_DANYCH"
table_name = "NAZWA_TWOJEJ_TABELI_RAW"  # Tabela z danymi granularnymi (niezagregowanymi)

try:
    # Tworzenie connection stringa dla uwierzytelniania Windows
    connection_string = f"mssql+pyodbc://{server_name}/{database_name}?driver=ODBC+Driver+17+for+SQL+Server&trusted_connection=yes"
    engine = sa.create_engine(connection_string)
    
    query = f"SELECT * FROM {table_name}"
    df_raw = pd.read_sql(query, engine)
    
    print(f"✅ Pomyślnie połączono i wczytano {len(df_raw)} rekordów z tabeli {table_name}.")

except Exception as e:
    print(f"❌ Błąd podczas połączenia z bazą danych: {e}")
    print("⚠️ Tworzę przykładowy, granularny zbiór danych, aby kontynuować analizę.")
    # Generowanie danych przykładowych dla TRZECH lat
    date_rng_2025 = pd.to_datetime(pd.date_range(start='2025-01-01', end='2025-09-17', freq='10min'))
    date_rng_2024 = pd.to_datetime(pd.date_range(start='2024-01-01', end='2024-12-31', freq='9min'))
    date_rng_2023 = pd.to_datetime(pd.date_range(start='2023-01-01', end='2023-12-31', freq='11min'))
    all_dates = date_rng_2025.union(date_rng_2024).union(date_rng_2023)
    
    data = {
        'callid': range(len(all_dates)),
        'Data': all_dates,
        'Kanal_kontakt': np.random.choice(['voice', 'czat', 'wideo'], len(all_dates), p=[0.7, 0.25, 0.05]),
        'czy_odebrane': np.random.choice([1, 0], len(all_dates), p=[0.85, 0.15]),
        'wejscie': np.random.choice(['ivr', 'bot', 'vendor'], len(all_dates), p=[0.5, 0.4, 0.1]),
        'gdzie_koniec': np.random.choice(['konsultant', 'bot', 'transfer', 'ivr'], len(all_dates), p=[0.7, 0.15, 0.1, 0.05]),
        'czas_rozmowy': np.random.gamma(2, 150, len(all_dates)).astype(int)
    }
    df_raw = pd.DataFrame(data)
    df_raw.loc[df_raw['czy_odebrane'] == 0, 'czas_rozmowy'] = 0

print("\n--- Próbka danych (5 pierwszych wierszy) ---")
display(df_raw.head())


# ==============================================================================
# KROK 3: PRZYGOTOWANIE DANYCH I IMPLEMENTACJA LOGIKI YTD DLA 3 LAT
# ==============================================================================
print("\n--- Rozpoczęto przygotowanie danych ---")
# Konwersja kolumny 'Data' i tworzenie cech
df_raw['Data'] = pd.to_datetime(df_raw['Data'])
df_raw['Rok'] = df_raw['Data'].dt.year
df_raw['Dzien_Roku'] = df_raw['Data'].dt.dayofyear # Klucz do porównań YTD

# --- Implementacja logiki Year-to-Date (YTD) dla 3 lat ---
# 1. Zdefiniuj lata do analizy
current_year = df_raw['Rok'].max()
previous_year = current_year - 1
two_years_ago = current_year - 2

# 2. Znajdź ostatni dzień roku w bieżącym roku
latest_date_cy = df_raw[df_raw['Rok'] == current_year]['Data'].max()
latest_day_of_year = latest_date_cy.dayofyear

print(f"Lata w analizie: {current_year}, {previous_year}, {two_years_ago}")
print(f"Najnowsze dane pochodzą z: {latest_date_cy.strftime('%Y-%m-%d')} (to {latest_day_of_year}. dzień roku)")

# 3. Odfiltruj dane, aby obejmowały ten sam okres we wszystkich latach
years_to_analyze = [current_year, previous_year, two_years_ago]
df_ytd = df_raw[(df_raw['Dzien_Roku'] <= latest_day_of_year) & (df_raw['Rok'].isin(years_to_analyze))].copy()

# Dodatkowe kolumny czasowe (po filtrowaniu dla wydajności)
df_ytd['Miesiac'] = df_ytd['Data'].dt.month
df_ytd['Godzina'] = df_ytd['Data'].dt.hour

print(f"✅ Dane odfiltrowane. Analiza zostanie przeprowadzona dla okresu od 1 stycznia do {latest_day_of_year}. dnia roku dla lat {years_to_analyze}.")

# ==============================================================================
# KROK 4: ANALIZA PORÓWNAWCZA I WIZUALIZACJA DANYCH (YTD dla 3 lat)
# ==============================================================================
print("\n--- Rozpoczęto główną analizę porównawczą (YTD) ---")

# --- 4.1. Ogólny Wolumen Interakcji (YTD) --- [WERSJA POPRAWIONA]

# Agregacja pozostaje bez zmian
total_volume_ytd = df_ytd.groupby('Rok')['callid'].count().reset_index().rename(columns={'callid': 'liczba_polaczen'})

# --- BEZPIECZNE POBIERANIE DANYCH ---
# Tworzymy słownik z wynikami, np. {2025: 15000, 2024: 12000}
volume_dict = pd.Series(total_volume_ytd.liczba_polaczen.values, index=total_volume_ytd.Rok).to_dict()

# Używamy metody .get(rok, 0), która zwróci 0, jeśli dany rok nie istnieje w słowniku
vol_cy = volume_dict.get(current_year, 0)
vol_py = volume_dict.get(previous_year, 0)
vol_2ya = volume_dict.get(two_years_ago, 0)

# --- BEZPIECZNE OBLICZANIE PROCENTÓW (unikamy dzielenia przez zero) ---
yoy_change_1 = ((vol_cy - vol_py) / vol_py) * 100 if vol_py > 0 else float('inf')
yoy_change_2 = ((vol_py - vol_2ya) / vol_2ya) * 100 if vol_2ya > 0 else float('inf')

# Wizualizacja
plt.figure(figsize=(12, 7))
ax = sns.barplot(data=total_volume_ytd, x='Rok', y='liczba_polaczen', palette='viridis', order=years_to_analyze)

# Tworzymy dynamiczny tytuł, który pokaże zmiany tylko jeśli miały sens
title_cy_vs_py = f'{current_year} vs {previous_year}: {yoy_change_1:.2f}%' if vol_py > 0 else f'{current_year} vs {previous_year}: Brak danych z {previous_year}'
title_py_vs_2ya = f'{previous_year} vs {two_years_ago}: {yoy_change_2:.2f}%' if vol_2ya > 0 else f'{previous_year} vs {two_years_ago}: Brak danych z {two_years_ago}'

ax.set_title(f'Całkowity Wolumen Interakcji (YTD)\n{title_cy_vs_py} | {title_py_vs_2ya}', fontsize=18)

for p in ax.patches:
    ax.annotate(f'{int(p.get_height()):,}', (p.get_x() + p.get_width() / 2., p.get_height()),
                ha='center', va='center', fontsize=14, color='black', xytext=(0, 10),
                textcoords='offset points')
plt.ylabel('Liczba Połączeń')
plt.xlabel('Rok')
plt.show()



# --- 4.2. Analiza Wolumenu w Podziale na Kanały (YTD) ---
channel_volume_ytd = df_ytd.groupby(['Rok', 'Kanal_kontakt'])['callid'].count().reset_index().rename(columns={'callid': 'liczba_polaczen'})
sns.barplot(data=channel_volume_ytd, x='Kanal_kontakt', y='liczba_polaczen', hue='Rok', palette='mako', hue_order=years_to_analyze)
plt.title('Wolumen Interakcji w Podziale na Kanały (YTD)')
plt.ylabel('Liczba Połączeń')
plt.xlabel('Kanał Kontaktu')
plt.legend(title='Rok')
plt.show()

# --- 4.3. Analiza Średniego Czasu Obsługi (AHT) (YTD) ---
df_answered_ytd = df_ytd[df_ytd['czy_odebrane'] == 1]
aht_ytd = df_answered_ytd.groupby('Rok')['czas_rozmowy'].mean().reset_index().rename(columns={'czas_rozmowy': 'Sredni_AHT_s'})
plt.figure(figsize=(12, 7))
ax = sns.barplot(data=aht_ytd, x='Rok', y='Sredni_AHT_s', palette='coolwarm', order=years_to_analyze)
ax.set_title('Średni Czas Obsługi - AHT (YTD)')
for p in ax.patches:
    ax.annotate(f'{p.get_height():.1f}s', (p.get_x() + p.get_width() / 2., p.get_height()),
                ha='center', va='center', fontsize=14, color='black', xytext=(0, 10),
                textcoords='offset points')
plt.ylabel('AHT (w sekundach)')
plt.xlabel('Rok')
plt.show()

# --- 4.4. Analiza Ścieżki Klienta: Wejście i Zakończenie (YTD) ---
fig, axes = plt.subplots(1, 2, figsize=(22, 8))
entry_points_ytd = df_ytd.groupby(['Rok', 'wejscie'])['callid'].count().reset_index()
exit_points_ytd = df_ytd.groupby(['Rok', 'gdzie_koniec'])['callid'].count().reset_index()

sns.barplot(ax=axes[0], data=entry_points_ytd, x='wejscie', y='callid', hue='Rok', palette='viridis', hue_order=years_to_analyze)
axes[0].set_title('Punkty Wejścia Interakcji (YTD)')
axes[0].set_ylabel('Liczba Połączeń')

sns.barplot(ax=axes[1], data=exit_points_ytd, x='gdzie_koniec', y='callid', hue='Rok', palette='plasma', hue_order=years_to_analyze)
axes[1].set_title('Punkty Zakończenia Interakcji (YTD)')
axes[1].set_ylabel('Liczba Połączeń')
plt.tight_layout()
plt.show()

# --- 4.5. Analiza Sezonowości i Trendów Miesięcznych (YTD) ---
monthly_trends_ytd = df_ytd.groupby(['Rok', 'Miesiac'])['callid'].count().reset_index()
sns.lineplot(data=monthly_trends_ytd, x='Miesiac', y='callid', hue='Rok', palette='Set1', marker='o', linewidth=2.5, hue_order=years_to_analyze)
plt.title('Miesięczne Trendy Wolumenu Połączeń (YTD)')
plt.xlabel('Miesiąc')
plt.ylabel('Liczba Połączeń')
plt.xticks(ticks=range(1, 13))
plt.legend(title='Rok')
plt.grid(True, which='both', linestyle='--')
plt.show()

# ==============================================================================
# KROK 5: GŁĘBSZA ANALIZA DZIĘKI DANYM GRANULARNYM (BONUS)
# ==============================================================================
print("\n--- Rozpoczęto analizy dodatkowe (bonus) ---")

# --- 5.1. Analiza obciążenia w ciągu dnia (Peak Hour Analysis) ---
hourly_volume_ytd = df_ytd.groupby(['Rok', 'Godzina'])['callid'].count().reset_index()
g = sns.FacetGrid(hourly_volume_ytd, col="Rok", col_order=years_to_analyze, height=6, aspect=1.2)
g.map(sns.barplot, "Godzina", "callid", order=range(24), palette='rocket')
g.set_axis_labels("Godzina Dnia", "Liczba Połączeń")
g.set_titles(col_template="Rok {col_name}")
g.fig.suptitle('Rozkład Połączeń w Ciągu Dnia (YTD)', y=1.03, fontsize=20)
plt.show()

# ==============================================================================
# KROK 6: PODSUMOWANIE I REKOMENDACJE BIZNESOWE
# ==============================================================================
print("\n\n" + "="*80)
print("💡 PODSUMOWANIE WNIOSKÓW I REKOMENDACJE BIZNESOWE (ANALIZA 3-LETNIA) 💡")
print("="*80)
print(f"""
Analiza porównawcza okresu od 1 stycznia do {latest_date_cy.strftime('%d %B')} dla lat {two_years_ago}, {previous_year} i {current_year} dostarcza bogatego kontekstu historycznego:

1.  **Długofalowy Trend Wolumenu:**
    - Zmiana {previous_year} vs {two_years_ago}: Wolumen {'wzrósł' if yoy_change_2 > 0 else 'spadł'} o {yoy_change_2:.2f}%.
    - Zmiana {current_year} vs {previous_year}: Wolumen {'wzrósł' if yoy_change_1 > 0 else 'spadł'} o {yoy_change_1:.2f}%.
    - Wniosek: Porównując obie zmiany, widzimy, że trend [np. wzrostowy] [np. przyspiesza / zwalnia / odwraca się]. To pozwala lepiej prognozować przyszłe zapotrzebowanie.

2.  **Ewolucja Preferencji Kanałów:** Analiza trzech lat wyraźnie pokazuje, które kanały [np. czat i wideo] systematycznie zyskują na popularności kosztem [np. kanału voice].
    Rekomendacja: Ten długofalowy trend to silny sygnał, aby strategicznie inwestować w rozwój i skalowanie kanałów cyfrowych.

3.  **Efektywność Operacyjna (AHT):** Obserwujemy trend AHT na przestrzeni trzech lat:
    - AHT w {two_years_ago}: {aht_ytd.loc[aht_ytd['Rok'] == two_years_ago, 'Sredni_AHT_s'].iloc[0]:.1f}s
    - AHT w {previous_year}: {aht_ytd.loc[aht_ytd['Rok'] == previous_year, 'Sredni_AHT_s'].iloc[0]:.1f}s
    - AHT w {current_year}: {aht_ytd.loc[aht_ytd['Rok'] == current_year, 'Sredni_AHT_s'].iloc[0]:.1f}s
    - Wniosek: Trend ten może wskazywać na [np. rosnącą złożoność problemów klientów] lub [np. efekty wdrożonych usprawnień systemowych].
    
4.  **Dojrzałość Automatyzacji:** Porównanie ścieżki klienta w trzech okresach pozwala ocenić, czy nasze inwestycje w bota i IVR przynoszą długofalowe rezultaty w postaci większej liczby interakcji rozwiązywanych bez udziału konsultanta.

5.  **Stabilność Wzorców Godzinowych:** Analiza rozkładu połączeń w ciągu dnia dla trzech lat pozwala sprawdzić, czy godziny szczytu są stabilne, czy też ulegają przesunięciu.
    Rekomendacja: Jeśli wzorce są stabilne, możemy z dużą pewnością planować grafiki. Jeśli się zmieniają, należy dostosować modele prognozowania Workforce Management.

Dodanie trzeciego roku do analizy pozwala odróżnić krótkoterminowe anomalie od trwałych, strategicznych zmian w zachowaniu klientów i wydajności operacyjnej.
""")
print("="*80)


